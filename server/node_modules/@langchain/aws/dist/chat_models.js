import { AIMessageChunk } from "@langchain/core/messages";
import { BaseChatModel, } from "@langchain/core/language_models/chat_models";
import { BedrockRuntimeClient, ConverseCommand, ConverseStreamCommand, } from "@aws-sdk/client-bedrock-runtime";
import { ChatGenerationChunk } from "@langchain/core/outputs";
import { getEnvironmentVariable } from "@langchain/core/utils/env";
import { defaultProvider, } from "@aws-sdk/credential-provider-node";
import { convertToConverseTools, convertToBedrockToolChoice, convertToConverseMessages, convertConverseMessageToLangChainMessage, handleConverseStreamContentBlockDelta, handleConverseStreamMetadata, handleConverseStreamContentBlockStart, } from "./common.js";
/**
 * Integration with AWS Bedrock Converse API.
 *
 * @example
 * ```typescript
 * import { ChatBedrockConverse } from "@langchain/aws";
 *
 * const model = new ChatBedrockConverse({
 *   region: process.env.BEDROCK_AWS_REGION ?? "us-east-1",
 *   credentials: {
 *     secretAccessKey: process.env.BEDROCK_AWS_SECRET_ACCESS_KEY!,
 *     accessKeyId: process.env.BEDROCK_AWS_ACCESS_KEY_ID!,
 *   },
 * });
 *
 * const res = await model.invoke([new HumanMessage("Print hello world")]);
 * ```
 */
export class ChatBedrockConverse extends BaseChatModel {
    // Used for tracing, replace with the same name as your class
    static lc_name() {
        return "ChatBedrockConverse";
    }
    /**
     * Replace with any secrets this class passes to `super`.
     * See {@link ../../langchain-cohere/src/chat_model.ts} for
     * an example.
     */
    get lc_secrets() {
        return {
            apiKey: "API_KEY_NAME",
        };
    }
    get lc_aliases() {
        return {
            apiKey: "API_KEY_NAME",
        };
    }
    constructor(fields) {
        super(fields ?? {});
        Object.defineProperty(this, "model", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "anthropic.claude-3-haiku-20240307-v1:0"
        });
        Object.defineProperty(this, "streaming", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "region", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "temperature", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: undefined
        });
        Object.defineProperty(this, "maxTokens", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: undefined
        });
        Object.defineProperty(this, "endpointHost", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "topP", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "additionalModelRequestFields", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "streamUsage", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        Object.defineProperty(this, "guardrailConfig", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "client", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        const { profile, filepath, configFilepath, ignoreCache, mfaCodeProvider, roleAssumer, roleArn, webIdentityTokenFile, roleAssumerWithWebIdentity, ...rest } = fields ?? {};
        const credentials = rest?.credentials ??
            defaultProvider({
                profile,
                filepath,
                configFilepath,
                ignoreCache,
                mfaCodeProvider,
                roleAssumer,
                roleArn,
                webIdentityTokenFile,
                roleAssumerWithWebIdentity,
            });
        const region = rest?.region ?? getEnvironmentVariable("AWS_DEFAULT_REGION");
        if (!region) {
            throw new Error("Please set the AWS_DEFAULT_REGION environment variable or pass it to the constructor as the region field.");
        }
        this.client = new BedrockRuntimeClient({
            region,
            credentials,
        });
        this.region = region;
        this.model = rest?.model ?? this.model;
        this.streaming = rest?.streaming ?? this.streaming;
        this.temperature = rest?.temperature;
        this.maxTokens = rest?.maxTokens;
        this.endpointHost = rest?.endpointHost;
        this.topP = rest?.topP;
        this.additionalModelRequestFields = rest?.additionalModelRequestFields;
        this.streamUsage = rest?.streamUsage ?? this.streamUsage;
        this.guardrailConfig = rest?.guardrailConfig;
    }
    getLsParams(options) {
        const params = this.invocationParams(options);
        return {
            ls_provider: "amazon_bedrock",
            ls_model_name: this.model,
            ls_model_type: "chat",
            ls_temperature: params.inferenceConfig?.temperature ?? this.temperature,
            ls_max_tokens: params.inferenceConfig?.maxTokens ?? undefined,
            ls_stop: options.stop,
        };
    }
    bindTools(tools, kwargs) {
        return this.bind({ tools: convertToConverseTools(tools), ...kwargs });
    }
    // Replace
    _llmType() {
        return "chat_bedrock_converse";
    }
    invocationParams(options) {
        let toolConfig;
        if (options?.tools && options.tools.length) {
            const tools = convertToConverseTools(options.tools);
            toolConfig = {
                tools,
                toolChoice: options.tool_choice
                    ? convertToBedrockToolChoice(options.tool_choice, tools)
                    : undefined,
            };
        }
        return {
            inferenceConfig: {
                maxTokens: this.maxTokens,
                temperature: this.temperature,
                topP: this.topP,
                stopSequences: options?.stop,
            },
            toolConfig,
            additionalModelRequestFields: this.additionalModelRequestFields ??
                options?.additionalModelRequestFields,
            guardrailConfig: this.guardrailConfig,
        };
    }
    async _generate(messages, options, runManager) {
        if (this.streaming) {
            const stream = this._streamResponseChunks(messages, options, runManager);
            let finalResult;
            for await (const chunk of stream) {
                if (finalResult === undefined) {
                    finalResult = chunk;
                }
                else {
                    finalResult = finalResult.concat(chunk);
                }
            }
            if (finalResult === undefined) {
                throw new Error("Could not parse final output from Bedrock streaming call.");
            }
            return {
                generations: [finalResult],
                llmOutput: finalResult.generationInfo,
            };
        }
        return this._generateNonStreaming(messages, options, runManager);
    }
    async _generateNonStreaming(messages, options, _runManager) {
        const { converseMessages, converseSystem } = convertToConverseMessages(messages);
        const params = this.invocationParams(options);
        const command = new ConverseCommand({
            modelId: this.model,
            messages: converseMessages,
            system: converseSystem,
            ...params,
        });
        const response = await this.client.send(command);
        const { output, ...responseMetadata } = response;
        if (!output?.message) {
            throw new Error("No message found in Bedrock response.");
        }
        const message = convertConverseMessageToLangChainMessage(output.message, responseMetadata);
        return {
            generations: [
                {
                    text: typeof message.content === "string" ? message.content : "",
                    message,
                },
            ],
        };
    }
    async *_streamResponseChunks(messages, options, runManager) {
        const { converseMessages, converseSystem } = convertToConverseMessages(messages);
        const params = this.invocationParams(options);
        let { streamUsage } = this;
        if (options.streamUsage !== undefined) {
            streamUsage = options.streamUsage;
        }
        const command = new ConverseStreamCommand({
            modelId: this.model,
            messages: converseMessages,
            system: converseSystem,
            ...params,
        });
        const response = await this.client.send(command);
        if (response.stream) {
            for await (const chunk of response.stream) {
                if (chunk.contentBlockStart) {
                    yield handleConverseStreamContentBlockStart(chunk.contentBlockStart);
                }
                else if (chunk.contentBlockDelta) {
                    const textChatGeneration = handleConverseStreamContentBlockDelta(chunk.contentBlockDelta);
                    yield textChatGeneration;
                    await runManager?.handleLLMNewToken(textChatGeneration.text);
                }
                else if (chunk.metadata) {
                    yield handleConverseStreamMetadata(chunk.metadata, {
                        streamUsage,
                    });
                }
                else {
                    yield new ChatGenerationChunk({
                        text: "",
                        message: new AIMessageChunk({
                            content: "",
                            response_metadata: chunk,
                        }),
                    });
                }
            }
        }
    }
}
