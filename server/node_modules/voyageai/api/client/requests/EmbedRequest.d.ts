/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as VoyageAI from "../../index";
/**
 * @example
 *     {
 *         input: "input",
 *         model: "model"
 *     }
 */
export interface EmbedRequest {
    /**
     * A single text string, or a list of texts as a list of strings. Currently, we have two constraints on the list: <ul>  <li> The maximum length of the list is 128. </li>  <li> The total number of tokens in the list is at most 320K for `voyage-2`, and 120K for `voyage-large-2`, `voyage-finance-2`, `voyage-multilingual-2`, `voyage-law-2`, and `voyage-code-2`. </li> <ul>
     *
     */
    input: VoyageAI.EmbedRequestInput;
    /**
     * Name of the model. Recommended options: `voyage-2`, `voyage-large-2`, `voyage-finance-2`, `voyage-multilingual-2`, `voyage-law-2`, `voyage-code-2`.
     *
     */
    model: string;
    /**
     * Type of the input text. Defaults to `null`. Other options: `query`, `document`.
     *
     */
    inputType?: VoyageAI.EmbedRequestInputType;
    /**
     * Whether to truncate the input texts to fit within the context length. Defaults to `true`. <ul>  <li> If `true`, over-length input texts will be truncated to fit within the context length, before vectorized by the embedding model. </li>  <li> If `false`, an error will be raised if any given text exceeds the context length. </li>  </ul>
     *
     */
    truncation?: boolean;
    /**
     * Format in which the embeddings are encoded. We support two options:  <ul> <li> If not specified (defaults to `null`): the embeddings are represented as lists of floating-point numbers; </li>  <li> `base64`: the embeddings are compressed to [base64](https://docs.python.org/3/library/base64.html) encodings. </li>  </ul>
     *
     */
    encodingFormat?: "base64";
}
