{"version":3,"sources":["../../../node_modules/.pnpm/ms@2.1.3/node_modules/ms/index.js","../../../node_modules/.pnpm/humanize-ms@1.2.1/node_modules/humanize-ms/index.js","../../../node_modules/.pnpm/agentkeepalive@4.5.0/node_modules/agentkeepalive/lib/constants.js","../../../node_modules/.pnpm/agentkeepalive@4.5.0/node_modules/agentkeepalive/lib/agent.js","../../../node_modules/.pnpm/agentkeepalive@4.5.0/node_modules/agentkeepalive/lib/https_agent.js","../../../node_modules/.pnpm/agentkeepalive@4.5.0/node_modules/agentkeepalive/index.js","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/utils.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/helpers/miscellaneous.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/helpers/webidl.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/simple-queue.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abstract-ops/internal-methods.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/generic-reader.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/stub/number-isfinite.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/stub/math-trunc.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/basic.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/readable-stream.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/default-reader.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/target/es2018/stub/async-iterator-prototype.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/async-iterator.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/stub/number-isnan.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abstract-ops/ecmascript.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abstract-ops/miscellaneous.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abstract-ops/queue-with-sizes.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/helpers/array-buffer-view.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/byte-stream-controller.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/reader-options.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/byob-reader.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abstract-ops/queuing-strategy.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/queuing-strategy.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/underlying-sink.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/writable-stream.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/abort-signal.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/writable-stream.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/globals.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/stub/dom-exception.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/pipe.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/default-controller.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/tee.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/readable-stream-like.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream/from.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/underlying-source.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/iterator-options.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/pipe-options.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/readable-writable-pair.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/readable-stream.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/queuing-strategy-init.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/byte-length-queuing-strategy.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/count-queuing-strategy.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/validators/transformer.ts","../../../node_modules/.pnpm/web-streams-polyfill@3.3.3/node_modules/web-streams-polyfill/src/lib/transform-stream.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/_shims/registry.ts","../../../node_modules/.pnpm/formdata-node@4.4.1/node_modules/formdata-node/lib/esm/FormData.js","../../../node_modules/.pnpm/formdata-node@4.4.1/node_modules/formdata-node/lib/esm/isBlob.js","../../../node_modules/.pnpm/formdata-node@4.4.1/node_modules/formdata-node/lib/esm/deprecateConstructorEntries.js","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/_shims/node-runtime.ts","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/createBoundary.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/isPlainObject.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/normalizeValue.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/escapeName.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/isFunction.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/isFileLike.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/util/isFormData.js","../../../node_modules/.pnpm/form-data-encoder@1.7.2/node_modules/form-data-encoder/lib/esm/FormDataEncoder.js","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/_shims/MultipartBody.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/_shims/index.mjs","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/error.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/streaming.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/uploads.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/core.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/pagination.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resource.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/chat/completions.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/chat/chat.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/audio/speech.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/audio/transcriptions.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/audio/translations.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/audio/audio.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/batches.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/assistants.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/RunnableFunction.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/chatCompletionUtils.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/AbstractChatCompletionRunner.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/ChatCompletionRunner.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/ChatCompletionStream.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/chat/completions.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/chat/chat.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/AbstractAssistantStreamRunner.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/AssistantStream.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/threads/messages.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/threads/runs/steps.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/threads/runs/runs.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/threads/threads.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/lib/Util.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/vector-stores/files.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/vector-stores/file-batches.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/vector-stores/vector-stores.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/beta/beta.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/completions.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/embeddings.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/files.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/fine-tuning/fine-tuning.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/images.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/models.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/resources/moderations.ts","../../../node_modules/.pnpm/openai@4.51.0/node_modules/openai/src/index.ts"],"sourcesContent":["/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n","/*!\n * humanize-ms - index.js\n * Copyright(c) 2014 dead_horse <dead_horse@qq.com>\n * MIT Licensed\n */\n\n'use strict';\n\n/**\n * Module dependencies.\n */\n\nvar util = require('util');\nvar ms = require('ms');\n\nmodule.exports = function (t) {\n  if (typeof t === 'number') return t;\n  var r = ms(t);\n  if (r === undefined) {\n    var err = new Error(util.format('humanize-ms(%j) result undefined', t));\n    console.warn(err.stack);\n  }\n  return r;\n};\n","'use strict';\n\nmodule.exports = {\n  // agent\n  CURRENT_ID: Symbol('agentkeepalive#currentId'),\n  CREATE_ID: Symbol('agentkeepalive#createId'),\n  INIT_SOCKET: Symbol('agentkeepalive#initSocket'),\n  CREATE_HTTPS_CONNECTION: Symbol('agentkeepalive#createHttpsConnection'),\n  // socket\n  SOCKET_CREATED_TIME: Symbol('agentkeepalive#socketCreatedTime'),\n  SOCKET_NAME: Symbol('agentkeepalive#socketName'),\n  SOCKET_REQUEST_COUNT: Symbol('agentkeepalive#socketRequestCount'),\n  SOCKET_REQUEST_FINISHED_COUNT: Symbol('agentkeepalive#socketRequestFinishedCount'),\n};\n","'use strict';\n\nconst OriginalAgent = require('http').Agent;\nconst ms = require('humanize-ms');\nconst debug = require('util').debuglog('agentkeepalive');\nconst {\n  INIT_SOCKET,\n  CURRENT_ID,\n  CREATE_ID,\n  SOCKET_CREATED_TIME,\n  SOCKET_NAME,\n  SOCKET_REQUEST_COUNT,\n  SOCKET_REQUEST_FINISHED_COUNT,\n} = require('./constants');\n\n// OriginalAgent come from\n// - https://github.com/nodejs/node/blob/v8.12.0/lib/_http_agent.js\n// - https://github.com/nodejs/node/blob/v10.12.0/lib/_http_agent.js\n\n// node <= 10\nlet defaultTimeoutListenerCount = 1;\nconst majorVersion = parseInt(process.version.split('.', 1)[0].substring(1));\nif (majorVersion >= 11 && majorVersion <= 12) {\n  defaultTimeoutListenerCount = 2;\n} else if (majorVersion >= 13) {\n  defaultTimeoutListenerCount = 3;\n}\n\nfunction deprecate(message) {\n  console.log('[agentkeepalive:deprecated] %s', message);\n}\n\nclass Agent extends OriginalAgent {\n  constructor(options) {\n    options = options || {};\n    options.keepAlive = options.keepAlive !== false;\n    // default is keep-alive and 4s free socket timeout\n    // see https://medium.com/ssense-tech/reduce-networking-errors-in-nodejs-23b4eb9f2d83\n    if (options.freeSocketTimeout === undefined) {\n      options.freeSocketTimeout = 4000;\n    }\n    // Legacy API: keepAliveTimeout should be rename to `freeSocketTimeout`\n    if (options.keepAliveTimeout) {\n      deprecate('options.keepAliveTimeout is deprecated, please use options.freeSocketTimeout instead');\n      options.freeSocketTimeout = options.keepAliveTimeout;\n      delete options.keepAliveTimeout;\n    }\n    // Legacy API: freeSocketKeepAliveTimeout should be rename to `freeSocketTimeout`\n    if (options.freeSocketKeepAliveTimeout) {\n      deprecate('options.freeSocketKeepAliveTimeout is deprecated, please use options.freeSocketTimeout instead');\n      options.freeSocketTimeout = options.freeSocketKeepAliveTimeout;\n      delete options.freeSocketKeepAliveTimeout;\n    }\n\n    // Sets the socket to timeout after timeout milliseconds of inactivity on the socket.\n    // By default is double free socket timeout.\n    if (options.timeout === undefined) {\n      // make sure socket default inactivity timeout >= 8s\n      options.timeout = Math.max(options.freeSocketTimeout * 2, 8000);\n    }\n\n    // support humanize format\n    options.timeout = ms(options.timeout);\n    options.freeSocketTimeout = ms(options.freeSocketTimeout);\n    options.socketActiveTTL = options.socketActiveTTL ? ms(options.socketActiveTTL) : 0;\n\n    super(options);\n\n    this[CURRENT_ID] = 0;\n\n    // create socket success counter\n    this.createSocketCount = 0;\n    this.createSocketCountLastCheck = 0;\n\n    this.createSocketErrorCount = 0;\n    this.createSocketErrorCountLastCheck = 0;\n\n    this.closeSocketCount = 0;\n    this.closeSocketCountLastCheck = 0;\n\n    // socket error event count\n    this.errorSocketCount = 0;\n    this.errorSocketCountLastCheck = 0;\n\n    // request finished counter\n    this.requestCount = 0;\n    this.requestCountLastCheck = 0;\n\n    // including free socket timeout counter\n    this.timeoutSocketCount = 0;\n    this.timeoutSocketCountLastCheck = 0;\n\n    this.on('free', socket => {\n      // https://github.com/nodejs/node/pull/32000\n      // Node.js native agent will check socket timeout eqs agent.options.timeout.\n      // Use the ttl or freeSocketTimeout to overwrite.\n      const timeout = this.calcSocketTimeout(socket);\n      if (timeout > 0 && socket.timeout !== timeout) {\n        socket.setTimeout(timeout);\n      }\n    });\n  }\n\n  get freeSocketKeepAliveTimeout() {\n    deprecate('agent.freeSocketKeepAliveTimeout is deprecated, please use agent.options.freeSocketTimeout instead');\n    return this.options.freeSocketTimeout;\n  }\n\n  get timeout() {\n    deprecate('agent.timeout is deprecated, please use agent.options.timeout instead');\n    return this.options.timeout;\n  }\n\n  get socketActiveTTL() {\n    deprecate('agent.socketActiveTTL is deprecated, please use agent.options.socketActiveTTL instead');\n    return this.options.socketActiveTTL;\n  }\n\n  calcSocketTimeout(socket) {\n    /**\n     * return <= 0: should free socket\n     * return > 0: should update socket timeout\n     * return undefined: not find custom timeout\n     */\n    let freeSocketTimeout = this.options.freeSocketTimeout;\n    const socketActiveTTL = this.options.socketActiveTTL;\n    if (socketActiveTTL) {\n      // check socketActiveTTL\n      const aliveTime = Date.now() - socket[SOCKET_CREATED_TIME];\n      const diff = socketActiveTTL - aliveTime;\n      if (diff <= 0) {\n        return diff;\n      }\n      if (freeSocketTimeout && diff < freeSocketTimeout) {\n        freeSocketTimeout = diff;\n      }\n    }\n    // set freeSocketTimeout\n    if (freeSocketTimeout) {\n      // set free keepalive timer\n      // try to use socket custom freeSocketTimeout first, support headers['keep-alive']\n      // https://github.com/node-modules/urllib/blob/b76053020923f4d99a1c93cf2e16e0c5ba10bacf/lib/urllib.js#L498\n      const customFreeSocketTimeout = socket.freeSocketTimeout || socket.freeSocketKeepAliveTimeout;\n      return customFreeSocketTimeout || freeSocketTimeout;\n    }\n  }\n\n  keepSocketAlive(socket) {\n    const result = super.keepSocketAlive(socket);\n    // should not keepAlive, do nothing\n    if (!result) return result;\n\n    const customTimeout = this.calcSocketTimeout(socket);\n    if (typeof customTimeout === 'undefined') {\n      return true;\n    }\n    if (customTimeout <= 0) {\n      debug('%s(requests: %s, finished: %s) free but need to destroy by TTL, request count %s, diff is %s',\n        socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT], customTimeout);\n      return false;\n    }\n    if (socket.timeout !== customTimeout) {\n      socket.setTimeout(customTimeout);\n    }\n    return true;\n  }\n\n  // only call on addRequest\n  reuseSocket(...args) {\n    // reuseSocket(socket, req)\n    super.reuseSocket(...args);\n    const socket = args[0];\n    const req = args[1];\n    req.reusedSocket = true;\n    const agentTimeout = this.options.timeout;\n    if (getSocketTimeout(socket) !== agentTimeout) {\n      // reset timeout before use\n      socket.setTimeout(agentTimeout);\n      debug('%s reset timeout to %sms', socket[SOCKET_NAME], agentTimeout);\n    }\n    socket[SOCKET_REQUEST_COUNT]++;\n    debug('%s(requests: %s, finished: %s) reuse on addRequest, timeout %sms',\n      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],\n      getSocketTimeout(socket));\n  }\n\n  [CREATE_ID]() {\n    const id = this[CURRENT_ID]++;\n    if (this[CURRENT_ID] === Number.MAX_SAFE_INTEGER) this[CURRENT_ID] = 0;\n    return id;\n  }\n\n  [INIT_SOCKET](socket, options) {\n    // bugfix here.\n    // https on node 8, 10 won't set agent.options.timeout by default\n    // TODO: need to fix on node itself\n    if (options.timeout) {\n      const timeout = getSocketTimeout(socket);\n      if (!timeout) {\n        socket.setTimeout(options.timeout);\n      }\n    }\n\n    if (this.options.keepAlive) {\n      // Disable Nagle's algorithm: http://blog.caustik.com/2012/04/08/scaling-node-js-to-100k-concurrent-connections/\n      // https://fengmk2.com/benchmark/nagle-algorithm-delayed-ack-mock.html\n      socket.setNoDelay(true);\n    }\n    this.createSocketCount++;\n    if (this.options.socketActiveTTL) {\n      socket[SOCKET_CREATED_TIME] = Date.now();\n    }\n    // don't show the hole '-----BEGIN CERTIFICATE----' key string\n    socket[SOCKET_NAME] = `sock[${this[CREATE_ID]()}#${options._agentKey}]`.split('-----BEGIN', 1)[0];\n    socket[SOCKET_REQUEST_COUNT] = 1;\n    socket[SOCKET_REQUEST_FINISHED_COUNT] = 0;\n    installListeners(this, socket, options);\n  }\n\n  createConnection(options, oncreate) {\n    let called = false;\n    const onNewCreate = (err, socket) => {\n      if (called) return;\n      called = true;\n\n      if (err) {\n        this.createSocketErrorCount++;\n        return oncreate(err);\n      }\n      this[INIT_SOCKET](socket, options);\n      oncreate(err, socket);\n    };\n\n    const newSocket = super.createConnection(options, onNewCreate);\n    if (newSocket) onNewCreate(null, newSocket);\n    return newSocket;\n  }\n\n  get statusChanged() {\n    const changed = this.createSocketCount !== this.createSocketCountLastCheck ||\n      this.createSocketErrorCount !== this.createSocketErrorCountLastCheck ||\n      this.closeSocketCount !== this.closeSocketCountLastCheck ||\n      this.errorSocketCount !== this.errorSocketCountLastCheck ||\n      this.timeoutSocketCount !== this.timeoutSocketCountLastCheck ||\n      this.requestCount !== this.requestCountLastCheck;\n    if (changed) {\n      this.createSocketCountLastCheck = this.createSocketCount;\n      this.createSocketErrorCountLastCheck = this.createSocketErrorCount;\n      this.closeSocketCountLastCheck = this.closeSocketCount;\n      this.errorSocketCountLastCheck = this.errorSocketCount;\n      this.timeoutSocketCountLastCheck = this.timeoutSocketCount;\n      this.requestCountLastCheck = this.requestCount;\n    }\n    return changed;\n  }\n\n  getCurrentStatus() {\n    return {\n      createSocketCount: this.createSocketCount,\n      createSocketErrorCount: this.createSocketErrorCount,\n      closeSocketCount: this.closeSocketCount,\n      errorSocketCount: this.errorSocketCount,\n      timeoutSocketCount: this.timeoutSocketCount,\n      requestCount: this.requestCount,\n      freeSockets: inspect(this.freeSockets),\n      sockets: inspect(this.sockets),\n      requests: inspect(this.requests),\n    };\n  }\n}\n\n// node 8 don't has timeout attribute on socket\n// https://github.com/nodejs/node/pull/21204/files#diff-e6ef024c3775d787c38487a6309e491dR408\nfunction getSocketTimeout(socket) {\n  return socket.timeout || socket._idleTimeout;\n}\n\nfunction installListeners(agent, socket, options) {\n  debug('%s create, timeout %sms', socket[SOCKET_NAME], getSocketTimeout(socket));\n\n  // listener socket events: close, timeout, error, free\n  function onFree() {\n    // create and socket.emit('free') logic\n    // https://github.com/nodejs/node/blob/master/lib/_http_agent.js#L311\n    // no req on the socket, it should be the new socket\n    if (!socket._httpMessage && socket[SOCKET_REQUEST_COUNT] === 1) return;\n\n    socket[SOCKET_REQUEST_FINISHED_COUNT]++;\n    agent.requestCount++;\n    debug('%s(requests: %s, finished: %s) free',\n      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);\n\n    // should reuse on pedding requests?\n    const name = agent.getName(options);\n    if (socket.writable && agent.requests[name] && agent.requests[name].length) {\n      // will be reuse on agent free listener\n      socket[SOCKET_REQUEST_COUNT]++;\n      debug('%s(requests: %s, finished: %s) will be reuse on agent free event',\n        socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);\n    }\n  }\n  socket.on('free', onFree);\n\n  function onClose(isError) {\n    debug('%s(requests: %s, finished: %s) close, isError: %s',\n      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT], isError);\n    agent.closeSocketCount++;\n  }\n  socket.on('close', onClose);\n\n  // start socket timeout handler\n  function onTimeout() {\n    // onTimeout and emitRequestTimeout(_http_client.js)\n    // https://github.com/nodejs/node/blob/v12.x/lib/_http_client.js#L711\n    const listenerCount = socket.listeners('timeout').length;\n    // node <= 10, default listenerCount is 1, onTimeout\n    // 11 < node <= 12, default listenerCount is 2, onTimeout and emitRequestTimeout\n    // node >= 13, default listenerCount is 3, onTimeout,\n    //   onTimeout(https://github.com/nodejs/node/pull/32000/files#diff-5f7fb0850412c6be189faeddea6c5359R333)\n    //   and emitRequestTimeout\n    const timeout = getSocketTimeout(socket);\n    const req = socket._httpMessage;\n    const reqTimeoutListenerCount = req && req.listeners('timeout').length || 0;\n    debug('%s(requests: %s, finished: %s) timeout after %sms, listeners %s, defaultTimeoutListenerCount %s, hasHttpRequest %s, HttpRequest timeoutListenerCount %s',\n      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],\n      timeout, listenerCount, defaultTimeoutListenerCount, !!req, reqTimeoutListenerCount);\n    if (debug.enabled) {\n      debug('timeout listeners: %s', socket.listeners('timeout').map(f => f.name).join(', '));\n    }\n    agent.timeoutSocketCount++;\n    const name = agent.getName(options);\n    if (agent.freeSockets[name] && agent.freeSockets[name].indexOf(socket) !== -1) {\n      // free socket timeout, destroy quietly\n      socket.destroy();\n      // Remove it from freeSockets list immediately to prevent new requests\n      // from being sent through this socket.\n      agent.removeSocket(socket, options);\n      debug('%s is free, destroy quietly', socket[SOCKET_NAME]);\n    } else {\n      // if there is no any request socket timeout handler,\n      // agent need to handle socket timeout itself.\n      //\n      // custom request socket timeout handle logic must follow these rules:\n      //  1. Destroy socket first\n      //  2. Must emit socket 'agentRemove' event tell agent remove socket\n      //     from freeSockets list immediately.\n      //     Otherise you may be get 'socket hang up' error when reuse\n      //     free socket and timeout happen in the same time.\n      if (reqTimeoutListenerCount === 0) {\n        const error = new Error('Socket timeout');\n        error.code = 'ERR_SOCKET_TIMEOUT';\n        error.timeout = timeout;\n        // must manually call socket.end() or socket.destroy() to end the connection.\n        // https://nodejs.org/dist/latest-v10.x/docs/api/net.html#net_socket_settimeout_timeout_callback\n        socket.destroy(error);\n        agent.removeSocket(socket, options);\n        debug('%s destroy with timeout error', socket[SOCKET_NAME]);\n      }\n    }\n  }\n  socket.on('timeout', onTimeout);\n\n  function onError(err) {\n    const listenerCount = socket.listeners('error').length;\n    debug('%s(requests: %s, finished: %s) error: %s, listenerCount: %s',\n      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],\n      err, listenerCount);\n    agent.errorSocketCount++;\n    if (listenerCount === 1) {\n      // if socket don't contain error event handler, don't catch it, emit it again\n      debug('%s emit uncaught error event', socket[SOCKET_NAME]);\n      socket.removeListener('error', onError);\n      socket.emit('error', err);\n    }\n  }\n  socket.on('error', onError);\n\n  function onRemove() {\n    debug('%s(requests: %s, finished: %s) agentRemove',\n      socket[SOCKET_NAME],\n      socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);\n    // We need this function for cases like HTTP 'upgrade'\n    // (defined by WebSockets) where we need to remove a socket from the\n    // pool because it'll be locked up indefinitely\n    socket.removeListener('close', onClose);\n    socket.removeListener('error', onError);\n    socket.removeListener('free', onFree);\n    socket.removeListener('timeout', onTimeout);\n    socket.removeListener('agentRemove', onRemove);\n  }\n  socket.on('agentRemove', onRemove);\n}\n\nmodule.exports = Agent;\n\nfunction inspect(obj) {\n  const res = {};\n  for (const key in obj) {\n    res[key] = obj[key].length;\n  }\n  return res;\n}\n","'use strict';\n\nconst OriginalHttpsAgent = require('https').Agent;\nconst HttpAgent = require('./agent');\nconst {\n  INIT_SOCKET,\n  CREATE_HTTPS_CONNECTION,\n} = require('./constants');\n\nclass HttpsAgent extends HttpAgent {\n  constructor(options) {\n    super(options);\n\n    this.defaultPort = 443;\n    this.protocol = 'https:';\n    this.maxCachedSessions = this.options.maxCachedSessions;\n    /* istanbul ignore next */\n    if (this.maxCachedSessions === undefined) {\n      this.maxCachedSessions = 100;\n    }\n\n    this._sessionCache = {\n      map: {},\n      list: [],\n    };\n  }\n\n  createConnection(options, oncreate) {\n    const socket = this[CREATE_HTTPS_CONNECTION](options, oncreate);\n    this[INIT_SOCKET](socket, options);\n    return socket;\n  }\n}\n\n// https://github.com/nodejs/node/blob/master/lib/https.js#L89\nHttpsAgent.prototype[CREATE_HTTPS_CONNECTION] = OriginalHttpsAgent.prototype.createConnection;\n\n[\n  'getName',\n  '_getSession',\n  '_cacheSession',\n  // https://github.com/nodejs/node/pull/4982\n  '_evictSession',\n].forEach(function(method) {\n  /* istanbul ignore next */\n  if (typeof OriginalHttpsAgent.prototype[method] === 'function') {\n    HttpsAgent.prototype[method] = OriginalHttpsAgent.prototype[method];\n  }\n});\n\nmodule.exports = HttpsAgent;\n","'use strict';\n\nmodule.exports = require('./lib/agent');\nmodule.exports.HttpsAgent = require('./lib/https_agent');\nmodule.exports.constants = require('./lib/constants');\n","export function noop(): undefined {\n  return undefined;\n}\n","import { noop } from '../../utils';\nimport { AssertionError } from '../../stub/assert';\n\nexport function typeIsObject(x: any): x is object {\n  return (typeof x === 'object' && x !== null) || typeof x === 'function';\n}\n\nexport const rethrowAssertionErrorRejection: (e: any) => void =\n  DEBUG ? e => {\n    // Used throughout the reference implementation, as `.catch(rethrowAssertionErrorRejection)`, to ensure any errors\n    // get shown. There are places in the spec where we do promise transformations and purposefully ignore or don't\n    // expect any errors, but assertion errors are always problematic.\n    if (e && e instanceof AssertionError) {\n      setTimeout(() => {\n        throw e;\n      }, 0);\n    }\n  } : noop;\n\nexport function setFunctionName(fn: Function, name: string): void {\n  try {\n    Object.defineProperty(fn, 'name', {\n      value: name,\n      configurable: true\n    });\n  } catch {\n    // This property is non-configurable in older browsers, so ignore if this throws.\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name#browser_compatibility\n  }\n}\n","import { rethrowAssertionErrorRejection } from './miscellaneous';\nimport assert from '../../stub/assert';\n\nconst originalPromise = Promise;\nconst originalPromiseThen = Promise.prototype.then;\nconst originalPromiseReject = Promise.reject.bind(originalPromise);\n\n// https://webidl.spec.whatwg.org/#a-new-promise\nexport function newPromise<T>(executor: (\n  resolve: (value: T | PromiseLike<T>) => void,\n  reject: (reason?: any) => void\n) => void): Promise<T> {\n  return new originalPromise(executor);\n}\n\n// https://webidl.spec.whatwg.org/#a-promise-resolved-with\nexport function promiseResolvedWith<T>(value: T | PromiseLike<T>): Promise<T> {\n  return newPromise(resolve => resolve(value));\n}\n\n// https://webidl.spec.whatwg.org/#a-promise-rejected-with\nexport function promiseRejectedWith<T = never>(reason: any): Promise<T> {\n  return originalPromiseReject(reason);\n}\n\nexport function PerformPromiseThen<T, TResult1 = T, TResult2 = never>(\n  promise: Promise<T>,\n  onFulfilled?: (value: T) => TResult1 | PromiseLike<TResult1>,\n  onRejected?: (reason: any) => TResult2 | PromiseLike<TResult2>): Promise<TResult1 | TResult2> {\n  // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n  // approximation.\n  return originalPromiseThen.call(promise, onFulfilled, onRejected) as Promise<TResult1 | TResult2>;\n}\n\n// Bluebird logs a warning when a promise is created within a fulfillment handler, but then isn't returned\n// from that handler. To prevent this, return null instead of void from all handlers.\n// http://bluebirdjs.com/docs/warning-explanations.html#warning-a-promise-was-created-in-a-handler-but-was-not-returned-from-it\nexport function uponPromise<T>(\n  promise: Promise<T>,\n  onFulfilled?: (value: T) => null | PromiseLike<null>,\n  onRejected?: (reason: any) => null | PromiseLike<null>): void {\n  PerformPromiseThen(\n    PerformPromiseThen(promise, onFulfilled, onRejected),\n    undefined,\n    rethrowAssertionErrorRejection\n  );\n}\n\nexport function uponFulfillment<T>(promise: Promise<T>, onFulfilled: (value: T) => null | PromiseLike<null>): void {\n  uponPromise(promise, onFulfilled);\n}\n\nexport function uponRejection(promise: Promise<unknown>, onRejected: (reason: any) => null | PromiseLike<null>): void {\n  uponPromise(promise, undefined, onRejected);\n}\n\nexport function transformPromiseWith<T, TResult1 = T, TResult2 = never>(\n  promise: Promise<T>,\n  fulfillmentHandler?: (value: T) => TResult1 | PromiseLike<TResult1>,\n  rejectionHandler?: (reason: any) => TResult2 | PromiseLike<TResult2>): Promise<TResult1 | TResult2> {\n  return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n}\n\nexport function setPromiseIsHandledToTrue(promise: Promise<unknown>): void {\n  PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n}\n\nlet _queueMicrotask: (callback: () => void) => void = callback => {\n  if (typeof queueMicrotask === 'function') {\n    _queueMicrotask = queueMicrotask;\n  } else {\n    const resolvedPromise = promiseResolvedWith(undefined);\n    _queueMicrotask = cb => PerformPromiseThen(resolvedPromise, cb);\n  }\n  return _queueMicrotask(callback);\n};\n\nexport { _queueMicrotask as queueMicrotask };\n\nexport function reflectCall<T, A extends any[], R>(F: (this: T, ...fnArgs: A) => R, V: T, args: A): R {\n  if (typeof F !== 'function') {\n    throw new TypeError('Argument is not a function');\n  }\n  return Function.prototype.apply.call(F, V, args);\n}\n\nexport function promiseCall<T, A extends any[], R>(F: (this: T, ...fnArgs: A) => R | PromiseLike<R>,\n                                                   V: T,\n                                                   args: A): Promise<R> {\n  assert(typeof F === 'function');\n  assert(V !== undefined);\n  assert(Array.isArray(args));\n  try {\n    return promiseResolvedWith(reflectCall(F, V, args));\n  } catch (value) {\n    return promiseRejectedWith(value);\n  }\n}\n","import assert from '../stub/assert';\n\n// Original from Chromium\n// https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\n\nconst QUEUE_MAX_ARRAY_SIZE = 16384;\n\ninterface Node<T> {\n  _elements: T[];\n  _next: Node<T> | undefined;\n}\n\n/**\n * Simple queue structure.\n *\n * Avoids scalability issues with using a packed array directly by using\n * multiple arrays in a linked list and keeping the array size bounded.\n */\nexport class SimpleQueue<T> {\n  private _front: Node<T>;\n  private _back: Node<T>;\n  private _cursor = 0;\n  private _size = 0;\n\n  constructor() {\n    // _front and _back are always defined.\n    this._front = {\n      _elements: [],\n      _next: undefined\n    };\n    this._back = this._front;\n    // The cursor is used to avoid calling Array.shift().\n    // It contains the index of the front element of the array inside the\n    // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n    this._cursor = 0;\n    // When there is only one node, size === elements.length - cursor.\n    this._size = 0;\n  }\n\n  get length(): number {\n    return this._size;\n  }\n\n  // For exception safety, this method is structured in order:\n  // 1. Read state\n  // 2. Calculate required state mutations\n  // 3. Perform state mutations\n  push(element: T): void {\n    const oldBack = this._back;\n    let newBack = oldBack;\n    assert(oldBack._next === undefined);\n    if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n      newBack = {\n        _elements: [],\n        _next: undefined\n      };\n    }\n\n    // push() is the mutation most likely to throw an exception, so it\n    // goes first.\n    oldBack._elements.push(element);\n    if (newBack !== oldBack) {\n      this._back = newBack;\n      oldBack._next = newBack;\n    }\n    ++this._size;\n  }\n\n  // Like push(), shift() follows the read -> calculate -> mutate pattern for\n  // exception safety.\n  shift(): T {\n    assert(this._size > 0); // must not be called on an empty queue\n\n    const oldFront = this._front;\n    let newFront = oldFront;\n    const oldCursor = this._cursor;\n    let newCursor = oldCursor + 1;\n\n    const elements = oldFront._elements;\n    const element = elements[oldCursor];\n\n    if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n      assert(elements.length === QUEUE_MAX_ARRAY_SIZE);\n      assert(oldFront._next !== undefined);\n      newFront = oldFront._next!;\n      newCursor = 0;\n    }\n\n    // No mutations before this point.\n    --this._size;\n    this._cursor = newCursor;\n    if (oldFront !== newFront) {\n      this._front = newFront;\n    }\n\n    // Permit shifted element to be garbage collected.\n    elements[oldCursor] = undefined!;\n\n    return element;\n  }\n\n  // The tricky thing about forEach() is that it can be called\n  // re-entrantly. The queue may be mutated inside the callback. It is easy to\n  // see that push() within the callback has no negative effects since the end\n  // of the queue is checked for on every iteration. If shift() is called\n  // repeatedly within the callback then the next iteration may return an\n  // element that has been removed. In this case the callback will be called\n  // with undefined values until we either \"catch up\" with elements that still\n  // exist or reach the back of the queue.\n  forEach(callback: (element: T) => void): void {\n    let i = this._cursor;\n    let node = this._front;\n    let elements = node._elements;\n    while (i !== elements.length || node._next !== undefined) {\n      if (i === elements.length) {\n        assert(node._next !== undefined);\n        assert(i === QUEUE_MAX_ARRAY_SIZE);\n        node = node._next!;\n        elements = node._elements;\n        i = 0;\n        if (elements.length === 0) {\n          break;\n        }\n      }\n      callback(elements[i]);\n      ++i;\n    }\n  }\n\n  // Return the element that would be returned if shift() was called now,\n  // without modifying the queue.\n  peek(): T {\n    assert(this._size > 0); // must not be called on an empty queue\n\n    const front = this._front;\n    const cursor = this._cursor;\n    return front._elements[cursor];\n  }\n}\n","export const AbortSteps = Symbol('[[AbortSteps]]');\nexport const ErrorSteps = Symbol('[[ErrorSteps]]');\nexport const CancelSteps = Symbol('[[CancelSteps]]');\nexport const PullSteps = Symbol('[[PullSteps]]');\nexport const ReleaseSteps = Symbol('[[ReleaseSteps]]');\n","import assert from '../../stub/assert';\nimport { ReadableStream, ReadableStreamCancel, type ReadableStreamReader } from '../readable-stream';\nimport { newPromise, setPromiseIsHandledToTrue } from '../helpers/webidl';\nimport { ReleaseSteps } from '../abstract-ops/internal-methods';\n\nexport function ReadableStreamReaderGenericInitialize<R>(reader: ReadableStreamReader<R>, stream: ReadableStream<R>) {\n  reader._ownerReadableStream = stream;\n  stream._reader = reader;\n\n  if (stream._state === 'readable') {\n    defaultReaderClosedPromiseInitialize(reader);\n  } else if (stream._state === 'closed') {\n    defaultReaderClosedPromiseInitializeAsResolved(reader);\n  } else {\n    assert(stream._state === 'errored');\n\n    defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n  }\n}\n\n// A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n// check.\n\nexport function ReadableStreamReaderGenericCancel(reader: ReadableStreamReader<any>, reason: any): Promise<undefined> {\n  const stream = reader._ownerReadableStream;\n  assert(stream !== undefined);\n  return ReadableStreamCancel(stream, reason);\n}\n\nexport function ReadableStreamReaderGenericRelease(reader: ReadableStreamReader<any>) {\n  const stream = reader._ownerReadableStream;\n  assert(stream !== undefined);\n  assert(stream._reader === reader);\n\n  if (stream._state === 'readable') {\n    defaultReaderClosedPromiseReject(\n      reader,\n      new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n  } else {\n    defaultReaderClosedPromiseResetToRejected(\n      reader,\n      new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n  }\n\n  stream._readableStreamController[ReleaseSteps]();\n\n  stream._reader = undefined;\n  reader._ownerReadableStream = undefined!;\n}\n\n// Helper functions for the readers.\n\nexport function readerLockException(name: string): TypeError {\n  return new TypeError('Cannot ' + name + ' a stream using a released reader');\n}\n\n// Helper functions for the ReadableStreamDefaultReader.\n\nexport function defaultReaderClosedPromiseInitialize(reader: ReadableStreamReader<any>) {\n  reader._closedPromise = newPromise((resolve, reject) => {\n    reader._closedPromise_resolve = resolve;\n    reader._closedPromise_reject = reject;\n  });\n}\n\nexport function defaultReaderClosedPromiseInitializeAsRejected(reader: ReadableStreamReader<any>, reason: any) {\n  defaultReaderClosedPromiseInitialize(reader);\n  defaultReaderClosedPromiseReject(reader, reason);\n}\n\nexport function defaultReaderClosedPromiseInitializeAsResolved(reader: ReadableStreamReader<any>) {\n  defaultReaderClosedPromiseInitialize(reader);\n  defaultReaderClosedPromiseResolve(reader);\n}\n\nexport function defaultReaderClosedPromiseReject(reader: ReadableStreamReader<any>, reason: any) {\n  if (reader._closedPromise_reject === undefined) {\n    return;\n  }\n\n  setPromiseIsHandledToTrue(reader._closedPromise);\n  reader._closedPromise_reject(reason);\n  reader._closedPromise_resolve = undefined;\n  reader._closedPromise_reject = undefined;\n}\n\nexport function defaultReaderClosedPromiseResetToRejected(reader: ReadableStreamReader<any>, reason: any) {\n  assert(reader._closedPromise_resolve === undefined);\n  assert(reader._closedPromise_reject === undefined);\n\n  defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n}\n\nexport function defaultReaderClosedPromiseResolve(reader: ReadableStreamReader<any>) {\n  if (reader._closedPromise_resolve === undefined) {\n    return;\n  }\n\n  reader._closedPromise_resolve(undefined);\n  reader._closedPromise_resolve = undefined;\n  reader._closedPromise_reject = undefined;\n}\n","/// <reference lib=\"es2015.core\" />\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\nconst NumberIsFinite: typeof Number.isFinite = Number.isFinite || function (x) {\n  return typeof x === 'number' && isFinite(x);\n};\n\nexport default NumberIsFinite;\n","/// <reference lib=\"es2015.core\" />\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\nconst MathTrunc: typeof Math.trunc = Math.trunc || function (v) {\n  return v < 0 ? Math.ceil(v) : Math.floor(v);\n};\n\nexport default MathTrunc;\n","import NumberIsFinite from '../../stub/number-isfinite';\nimport MathTrunc from '../../stub/math-trunc';\n\n// https://heycam.github.io/webidl/#idl-dictionaries\nexport function isDictionary(x: any): x is object | null {\n  return typeof x === 'object' || typeof x === 'function';\n}\n\nexport function assertDictionary(obj: unknown,\n                                 context: string): asserts obj is object | null | undefined {\n  if (obj !== undefined && !isDictionary(obj)) {\n    throw new TypeError(`${context} is not an object.`);\n  }\n}\n\nexport type AnyFunction = (...args: any[]) => any;\n\n// https://heycam.github.io/webidl/#idl-callback-functions\nexport function assertFunction(x: unknown, context: string): asserts x is AnyFunction {\n  if (typeof x !== 'function') {\n    throw new TypeError(`${context} is not a function.`);\n  }\n}\n\n// https://heycam.github.io/webidl/#idl-object\nexport function isObject(x: any): x is object {\n  return (typeof x === 'object' && x !== null) || typeof x === 'function';\n}\n\nexport function assertObject(x: unknown,\n                             context: string): asserts x is object {\n  if (!isObject(x)) {\n    throw new TypeError(`${context} is not an object.`);\n  }\n}\n\nexport function assertRequiredArgument<T>(x: T | undefined,\n                                          position: number,\n                                          context: string): asserts x is T {\n  if (x === undefined) {\n    throw new TypeError(`Parameter ${position} is required in '${context}'.`);\n  }\n}\n\nexport function assertRequiredField<T>(x: T | undefined,\n                                       field: string,\n                                       context: string): asserts x is T {\n  if (x === undefined) {\n    throw new TypeError(`${field} is required in '${context}'.`);\n  }\n}\n\n// https://heycam.github.io/webidl/#idl-unrestricted-double\nexport function convertUnrestrictedDouble(value: unknown): number {\n  return Number(value);\n}\n\nfunction censorNegativeZero(x: number): number {\n  return x === 0 ? 0 : x;\n}\n\nfunction integerPart(x: number): number {\n  return censorNegativeZero(MathTrunc(x));\n}\n\n// https://heycam.github.io/webidl/#idl-unsigned-long-long\nexport function convertUnsignedLongLongWithEnforceRange(value: unknown, context: string): number {\n  const lowerBound = 0;\n  const upperBound = Number.MAX_SAFE_INTEGER;\n\n  let x = Number(value);\n  x = censorNegativeZero(x);\n\n  if (!NumberIsFinite(x)) {\n    throw new TypeError(`${context} is not a finite number`);\n  }\n\n  x = integerPart(x);\n\n  if (x < lowerBound || x > upperBound) {\n    throw new TypeError(`${context} is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`);\n  }\n\n  if (!NumberIsFinite(x) || x === 0) {\n    return 0;\n  }\n\n  // TODO Use BigInt if supported?\n  // let xBigInt = BigInt(integerPart(x));\n  // xBigInt = BigInt.asUintN(64, xBigInt);\n  // return Number(xBigInt);\n\n  return x;\n}\n","import { IsReadableStream, ReadableStream } from '../readable-stream';\n\nexport function assertReadableStream(x: unknown, context: string): asserts x is ReadableStream {\n  if (!IsReadableStream(x)) {\n    throw new TypeError(`${context} is not a ReadableStream.`);\n  }\n}\n","import assert from '../../stub/assert';\nimport { SimpleQueue } from '../simple-queue';\nimport {\n  ReadableStreamReaderGenericCancel,\n  ReadableStreamReaderGenericInitialize,\n  ReadableStreamReaderGenericRelease,\n  readerLockException\n} from './generic-reader';\nimport { IsReadableStreamLocked, ReadableStream } from '../readable-stream';\nimport { setFunctionName, typeIsObject } from '../helpers/miscellaneous';\nimport { PullSteps } from '../abstract-ops/internal-methods';\nimport { newPromise, promiseRejectedWith } from '../helpers/webidl';\nimport { assertRequiredArgument } from '../validators/basic';\nimport { assertReadableStream } from '../validators/readable-stream';\n\n/**\n * A result returned by {@link ReadableStreamDefaultReader.read}.\n *\n * @public\n */\nexport type ReadableStreamDefaultReadResult<T> = {\n  done: false;\n  value: T;\n} | {\n  done: true;\n  value?: undefined;\n}\n\n// Abstract operations for the ReadableStream.\n\nexport function AcquireReadableStreamDefaultReader<R>(stream: ReadableStream): ReadableStreamDefaultReader<R> {\n  return new ReadableStreamDefaultReader(stream);\n}\n\n// ReadableStream API exposed for controllers.\n\nexport function ReadableStreamAddReadRequest<R>(stream: ReadableStream<R>,\n                                                readRequest: ReadRequest<R>): void {\n  assert(IsReadableStreamDefaultReader(stream._reader));\n  assert(stream._state === 'readable');\n\n  (stream._reader! as ReadableStreamDefaultReader<R>)._readRequests.push(readRequest);\n}\n\nexport function ReadableStreamFulfillReadRequest<R>(stream: ReadableStream<R>, chunk: R | undefined, done: boolean) {\n  const reader = stream._reader as ReadableStreamDefaultReader<R>;\n\n  assert(reader._readRequests.length > 0);\n\n  const readRequest = reader._readRequests.shift()!;\n  if (done) {\n    readRequest._closeSteps();\n  } else {\n    readRequest._chunkSteps(chunk!);\n  }\n}\n\nexport function ReadableStreamGetNumReadRequests<R>(stream: ReadableStream<R>): number {\n  return (stream._reader as ReadableStreamDefaultReader<R>)._readRequests.length;\n}\n\nexport function ReadableStreamHasDefaultReader(stream: ReadableStream): boolean {\n  const reader = stream._reader;\n\n  if (reader === undefined) {\n    return false;\n  }\n\n  if (!IsReadableStreamDefaultReader(reader)) {\n    return false;\n  }\n\n  return true;\n}\n\n// Readers\n\nexport interface ReadRequest<R> {\n  _chunkSteps(chunk: R): void;\n\n  _closeSteps(): void;\n\n  _errorSteps(e: any): void;\n}\n\n/**\n * A default reader vended by a {@link ReadableStream}.\n *\n * @public\n */\nexport class ReadableStreamDefaultReader<R = any> {\n  /** @internal */\n  _ownerReadableStream!: ReadableStream<R>;\n  /** @internal */\n  _closedPromise!: Promise<undefined>;\n  /** @internal */\n  _closedPromise_resolve?: (value?: undefined) => void;\n  /** @internal */\n  _closedPromise_reject?: (reason: any) => void;\n  /** @internal */\n  _readRequests: SimpleQueue<ReadRequest<R>>;\n\n  constructor(stream: ReadableStream<R>) {\n    assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n    assertReadableStream(stream, 'First parameter');\n\n    if (IsReadableStreamLocked(stream)) {\n      throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n    }\n\n    ReadableStreamReaderGenericInitialize(this, stream);\n\n    this._readRequests = new SimpleQueue();\n  }\n\n  /**\n   * Returns a promise that will be fulfilled when the stream becomes closed,\n   * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n   */\n  get closed(): Promise<undefined> {\n    if (!IsReadableStreamDefaultReader(this)) {\n      return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n    }\n\n    return this._closedPromise;\n  }\n\n  /**\n   * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n   */\n  cancel(reason: any = undefined): Promise<void> {\n    if (!IsReadableStreamDefaultReader(this)) {\n      return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return promiseRejectedWith(readerLockException('cancel'));\n    }\n\n    return ReadableStreamReaderGenericCancel(this, reason);\n  }\n\n  /**\n   * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n   *\n   * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n   */\n  read(): Promise<ReadableStreamDefaultReadResult<R>> {\n    if (!IsReadableStreamDefaultReader(this)) {\n      return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return promiseRejectedWith(readerLockException('read from'));\n    }\n\n    let resolvePromise!: (result: ReadableStreamDefaultReadResult<R>) => void;\n    let rejectPromise!: (reason: any) => void;\n    const promise = newPromise<ReadableStreamDefaultReadResult<R>>((resolve, reject) => {\n      resolvePromise = resolve;\n      rejectPromise = reject;\n    });\n    const readRequest: ReadRequest<R> = {\n      _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n      _closeSteps: () => resolvePromise({ value: undefined, done: true }),\n      _errorSteps: e => rejectPromise(e)\n    };\n    ReadableStreamDefaultReaderRead(this, readRequest);\n    return promise;\n  }\n\n  /**\n   * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n   * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n   * from now on; otherwise, the reader will appear closed.\n   *\n   * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n   * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n   * do so will throw a `TypeError` and leave the reader locked to the stream.\n   */\n  releaseLock(): void {\n    if (!IsReadableStreamDefaultReader(this)) {\n      throw defaultReaderBrandCheckException('releaseLock');\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return;\n    }\n\n    ReadableStreamDefaultReaderRelease(this);\n  }\n}\n\nObject.defineProperties(ReadableStreamDefaultReader.prototype, {\n  cancel: { enumerable: true },\n  read: { enumerable: true },\n  releaseLock: { enumerable: true },\n  closed: { enumerable: true }\n});\nsetFunctionName(ReadableStreamDefaultReader.prototype.cancel, 'cancel');\nsetFunctionName(ReadableStreamDefaultReader.prototype.read, 'read');\nsetFunctionName(ReadableStreamDefaultReader.prototype.releaseLock, 'releaseLock');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableStreamDefaultReader.prototype, Symbol.toStringTag, {\n    value: 'ReadableStreamDefaultReader',\n    configurable: true\n  });\n}\n\n// Abstract operations for the readers.\n\nexport function IsReadableStreamDefaultReader<R = any>(x: any): x is ReadableStreamDefaultReader<R> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n    return false;\n  }\n\n  return x instanceof ReadableStreamDefaultReader;\n}\n\nexport function ReadableStreamDefaultReaderRead<R>(reader: ReadableStreamDefaultReader<R>,\n                                                   readRequest: ReadRequest<R>): void {\n  const stream = reader._ownerReadableStream;\n\n  assert(stream !== undefined);\n\n  stream._disturbed = true;\n\n  if (stream._state === 'closed') {\n    readRequest._closeSteps();\n  } else if (stream._state === 'errored') {\n    readRequest._errorSteps(stream._storedError);\n  } else {\n    assert(stream._state === 'readable');\n    stream._readableStreamController[PullSteps](readRequest as ReadRequest<any>);\n  }\n}\n\nexport function ReadableStreamDefaultReaderRelease(reader: ReadableStreamDefaultReader) {\n  ReadableStreamReaderGenericRelease(reader);\n  const e = new TypeError('Reader was released');\n  ReadableStreamDefaultReaderErrorReadRequests(reader, e);\n}\n\nexport function ReadableStreamDefaultReaderErrorReadRequests(reader: ReadableStreamDefaultReader, e: any) {\n  const readRequests = reader._readRequests;\n  reader._readRequests = new SimpleQueue();\n  readRequests.forEach(readRequest => {\n    readRequest._errorSteps(e);\n  });\n}\n\n// Helper functions for the ReadableStreamDefaultReader.\n\nfunction defaultReaderBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `ReadableStreamDefaultReader.prototype.${name} can only be used on a ReadableStreamDefaultReader`);\n}\n","/// <reference lib=\"es2018.asynciterable\" />\n\n/* eslint-disable @typescript-eslint/no-empty-function */\nexport const AsyncIteratorPrototype: AsyncIterable<any> =\n  Object.getPrototypeOf(Object.getPrototypeOf(async function* (): AsyncIterableIterator<any> {}).prototype);\n","/// <reference lib=\"es2018.asynciterable\" />\n\nimport { ReadableStream } from '../readable-stream';\nimport {\n  AcquireReadableStreamDefaultReader,\n  ReadableStreamDefaultReader,\n  ReadableStreamDefaultReaderRead,\n  type ReadableStreamDefaultReadResult,\n  type ReadRequest\n} from './default-reader';\nimport { ReadableStreamReaderGenericCancel, ReadableStreamReaderGenericRelease } from './generic-reader';\nimport assert from '../../stub/assert';\nimport { AsyncIteratorPrototype } from '@@target/stub/async-iterator-prototype';\nimport { typeIsObject } from '../helpers/miscellaneous';\nimport {\n  newPromise,\n  promiseRejectedWith,\n  promiseResolvedWith,\n  queueMicrotask,\n  transformPromiseWith\n} from '../helpers/webidl';\n\n/**\n * An async iterator returned by {@link ReadableStream.values}.\n *\n * @public\n */\nexport interface ReadableStreamAsyncIterator<R> extends AsyncIterableIterator<R> {\n  next(): Promise<IteratorResult<R, undefined>>;\n\n  return(value?: any): Promise<IteratorResult<any>>;\n}\n\nexport class ReadableStreamAsyncIteratorImpl<R> {\n  private readonly _reader: ReadableStreamDefaultReader<R>;\n  private readonly _preventCancel: boolean;\n  private _ongoingPromise: Promise<ReadableStreamDefaultReadResult<R>> | undefined = undefined;\n  private _isFinished = false;\n\n  constructor(reader: ReadableStreamDefaultReader<R>, preventCancel: boolean) {\n    this._reader = reader;\n    this._preventCancel = preventCancel;\n  }\n\n  next(): Promise<ReadableStreamDefaultReadResult<R>> {\n    const nextSteps = () => this._nextSteps();\n    this._ongoingPromise = this._ongoingPromise ?\n      transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n      nextSteps();\n    return this._ongoingPromise;\n  }\n\n  return(value: any): Promise<ReadableStreamDefaultReadResult<any>> {\n    const returnSteps = () => this._returnSteps(value);\n    return this._ongoingPromise ?\n      transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n      returnSteps();\n  }\n\n  private _nextSteps(): Promise<ReadableStreamDefaultReadResult<R>> {\n    if (this._isFinished) {\n      return Promise.resolve({ value: undefined, done: true });\n    }\n\n    const reader = this._reader;\n    assert(reader._ownerReadableStream !== undefined);\n\n    let resolvePromise!: (result: ReadableStreamDefaultReadResult<R>) => void;\n    let rejectPromise!: (reason: any) => void;\n    const promise = newPromise<ReadableStreamDefaultReadResult<R>>((resolve, reject) => {\n      resolvePromise = resolve;\n      rejectPromise = reject;\n    });\n    const readRequest: ReadRequest<R> = {\n      _chunkSteps: chunk => {\n        this._ongoingPromise = undefined;\n        // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n        // FIXME Is this a bug in the specification, or in the test?\n        queueMicrotask(() => resolvePromise({ value: chunk, done: false }));\n      },\n      _closeSteps: () => {\n        this._ongoingPromise = undefined;\n        this._isFinished = true;\n        ReadableStreamReaderGenericRelease(reader);\n        resolvePromise({ value: undefined, done: true });\n      },\n      _errorSteps: reason => {\n        this._ongoingPromise = undefined;\n        this._isFinished = true;\n        ReadableStreamReaderGenericRelease(reader);\n        rejectPromise(reason);\n      }\n    };\n    ReadableStreamDefaultReaderRead(reader, readRequest);\n    return promise;\n  }\n\n  private _returnSteps(value: any): Promise<ReadableStreamDefaultReadResult<any>> {\n    if (this._isFinished) {\n      return Promise.resolve({ value, done: true });\n    }\n    this._isFinished = true;\n\n    const reader = this._reader;\n    assert(reader._ownerReadableStream !== undefined);\n    assert(reader._readRequests.length === 0);\n\n    if (!this._preventCancel) {\n      const result = ReadableStreamReaderGenericCancel(reader, value);\n      ReadableStreamReaderGenericRelease(reader);\n      return transformPromiseWith(result, () => ({ value, done: true }));\n    }\n\n    ReadableStreamReaderGenericRelease(reader);\n    return promiseResolvedWith({ value, done: true });\n  }\n}\n\ninterface ReadableStreamAsyncIteratorInstance<R> extends ReadableStreamAsyncIterator<R> {\n  /** @interal */\n  _asyncIteratorImpl: ReadableStreamAsyncIteratorImpl<R>;\n\n  next(): Promise<IteratorResult<R, undefined>>;\n\n  return(value?: any): Promise<IteratorResult<any>>;\n}\n\nconst ReadableStreamAsyncIteratorPrototype: ReadableStreamAsyncIteratorInstance<any> = {\n  next(this: ReadableStreamAsyncIteratorInstance<any>): Promise<ReadableStreamDefaultReadResult<any>> {\n    if (!IsReadableStreamAsyncIterator(this)) {\n      return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n    }\n    return this._asyncIteratorImpl.next();\n  },\n\n  return(this: ReadableStreamAsyncIteratorInstance<any>, value: any): Promise<ReadableStreamDefaultReadResult<any>> {\n    if (!IsReadableStreamAsyncIterator(this)) {\n      return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n    }\n    return this._asyncIteratorImpl.return(value);\n  }\n} as any;\nObject.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n\n// Abstract operations for the ReadableStream.\n\nexport function AcquireReadableStreamAsyncIterator<R>(stream: ReadableStream<R>,\n                                                      preventCancel: boolean): ReadableStreamAsyncIterator<R> {\n  const reader = AcquireReadableStreamDefaultReader<R>(stream);\n  const impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n  const iterator: ReadableStreamAsyncIteratorInstance<R> = Object.create(ReadableStreamAsyncIteratorPrototype);\n  iterator._asyncIteratorImpl = impl;\n  return iterator;\n}\n\nfunction IsReadableStreamAsyncIterator<R = any>(x: any): x is ReadableStreamAsyncIterator<R> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n    return false;\n  }\n\n  try {\n    // noinspection SuspiciousTypeOfGuard\n    return (x as ReadableStreamAsyncIteratorInstance<any>)._asyncIteratorImpl instanceof\n      ReadableStreamAsyncIteratorImpl;\n  } catch {\n    return false;\n  }\n}\n\n// Helper functions for the ReadableStream.\n\nfunction streamAsyncIteratorBrandCheckException(name: string): TypeError {\n  return new TypeError(`ReadableStreamAsyncIterator.${name} can only be used on a ReadableSteamAsyncIterator`);\n}\n","/// <reference lib=\"es2015.core\" />\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\nconst NumberIsNaN: typeof Number.isNaN = Number.isNaN || function (x) {\n  // eslint-disable-next-line no-self-compare\n  return x !== x;\n};\n\nexport default NumberIsNaN;\n","import { reflectCall } from 'lib/helpers/webidl';\nimport { typeIsObject } from '../helpers/miscellaneous';\nimport assert from '../../stub/assert';\n\ndeclare global {\n  interface ArrayBuffer {\n    readonly detached: boolean;\n\n    transfer(): ArrayBuffer;\n  }\n\n  function structuredClone<T>(value: T, options: { transfer: ArrayBuffer[] }): T;\n}\n\nexport function CreateArrayFromList<T extends any[]>(elements: T): T {\n  // We use arrays to represent lists, so this is basically a no-op.\n  // Do a slice though just in case we happen to depend on the unique-ness.\n  return elements.slice() as T;\n}\n\nexport function CopyDataBlockBytes(dest: ArrayBuffer,\n                                   destOffset: number,\n                                   src: ArrayBuffer,\n                                   srcOffset: number,\n                                   n: number) {\n  new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n}\n\nexport let TransferArrayBuffer = (O: ArrayBuffer): ArrayBuffer => {\n  if (typeof O.transfer === 'function') {\n    TransferArrayBuffer = buffer => buffer.transfer();\n  } else if (typeof structuredClone === 'function') {\n    TransferArrayBuffer = buffer => structuredClone(buffer, { transfer: [buffer] });\n  } else {\n    // Not implemented correctly\n    TransferArrayBuffer = buffer => buffer;\n  }\n  return TransferArrayBuffer(O);\n};\n\nexport function CanTransferArrayBuffer(O: ArrayBuffer): boolean {\n  return !IsDetachedBuffer(O);\n}\n\nexport let IsDetachedBuffer = (O: ArrayBuffer): boolean => {\n  if (typeof O.detached === 'boolean') {\n    IsDetachedBuffer = buffer => buffer.detached;\n  } else {\n    // Not implemented correctly\n    IsDetachedBuffer = buffer => buffer.byteLength === 0;\n  }\n  return IsDetachedBuffer(O);\n};\n\nexport function ArrayBufferSlice(buffer: ArrayBuffer, begin: number, end: number): ArrayBuffer {\n  // ArrayBuffer.prototype.slice is not available on IE10\n  // https://www.caniuse.com/mdn-javascript_builtins_arraybuffer_slice\n  if (buffer.slice) {\n    return buffer.slice(begin, end);\n  }\n  const length = end - begin;\n  const slice = new ArrayBuffer(length);\n  CopyDataBlockBytes(slice, 0, buffer, begin, length);\n  return slice;\n}\n\nexport type MethodName<T> = {\n  [P in keyof T]: T[P] extends Function | undefined ? P : never;\n}[keyof T];\n\nexport function GetMethod<T, K extends MethodName<T>>(receiver: T, prop: K): T[K] | undefined {\n  const func = receiver[prop];\n  if (func === undefined || func === null) {\n    return undefined;\n  }\n  if (typeof func !== 'function') {\n    throw new TypeError(`${String(prop)} is not a function`);\n  }\n  return func;\n}\n\nexport interface SyncIteratorRecord<T> {\n  iterator: Iterator<T>,\n  nextMethod: Iterator<T>['next'],\n  done: boolean;\n}\n\nexport interface AsyncIteratorRecord<T> {\n  iterator: AsyncIterator<T>,\n  nextMethod: AsyncIterator<T>['next'],\n  done: boolean;\n}\n\nexport type SyncOrAsyncIteratorRecord<T> = SyncIteratorRecord<T> | AsyncIteratorRecord<T>;\n\nexport function CreateAsyncFromSyncIterator<T>(syncIteratorRecord: SyncIteratorRecord<T>): AsyncIteratorRecord<T> {\n  // Instead of re-implementing CreateAsyncFromSyncIterator and %AsyncFromSyncIteratorPrototype%,\n  // we use yield* inside an async generator function to achieve the same result.\n\n  // Wrap the sync iterator inside a sync iterable, so we can use it with yield*.\n  const syncIterable = {\n    [Symbol.iterator]: () => syncIteratorRecord.iterator\n  };\n  // Create an async generator function and immediately invoke it.\n  const asyncIterator = (async function* () {\n    return yield* syncIterable;\n  }());\n  // Return as an async iterator record.\n  const nextMethod = asyncIterator.next;\n  return { iterator: asyncIterator, nextMethod, done: false };\n}\n\n// Aligns with core-js/modules/es.symbol.async-iterator.js\nexport const SymbolAsyncIterator: (typeof Symbol)['asyncIterator'] =\n  Symbol.asyncIterator ??\n  Symbol.for?.('Symbol.asyncIterator') ??\n  '@@asyncIterator';\n\nexport type SyncOrAsyncIterable<T> = Iterable<T> | AsyncIterable<T>;\nexport type SyncOrAsyncIteratorMethod<T> = () => (Iterator<T> | AsyncIterator<T>);\n\nfunction GetIterator<T>(\n  obj: SyncOrAsyncIterable<T>,\n  hint: 'async',\n  method?: SyncOrAsyncIteratorMethod<T>\n): AsyncIteratorRecord<T>;\nfunction GetIterator<T>(\n  obj: Iterable<T>,\n  hint: 'sync',\n  method?: SyncOrAsyncIteratorMethod<T>\n): SyncIteratorRecord<T>;\nfunction GetIterator<T>(\n  obj: SyncOrAsyncIterable<T>,\n  hint = 'sync',\n  method?: SyncOrAsyncIteratorMethod<T>\n): SyncOrAsyncIteratorRecord<T> {\n  assert(hint === 'sync' || hint === 'async');\n  if (method === undefined) {\n    if (hint === 'async') {\n      method = GetMethod(obj as AsyncIterable<T>, SymbolAsyncIterator);\n      if (method === undefined) {\n        const syncMethod = GetMethod(obj as Iterable<T>, Symbol.iterator);\n        const syncIteratorRecord = GetIterator(obj as Iterable<T>, 'sync', syncMethod);\n        return CreateAsyncFromSyncIterator(syncIteratorRecord);\n      }\n    } else {\n      method = GetMethod(obj as Iterable<T>, Symbol.iterator);\n    }\n  }\n  if (method === undefined) {\n    throw new TypeError('The object is not iterable');\n  }\n  const iterator = reflectCall(method, obj, []);\n  if (!typeIsObject(iterator)) {\n    throw new TypeError('The iterator method must return an object');\n  }\n  const nextMethod = iterator.next;\n  return { iterator, nextMethod, done: false } as SyncOrAsyncIteratorRecord<T>;\n}\n\nexport { GetIterator };\n\nexport function IteratorNext<T>(iteratorRecord: AsyncIteratorRecord<T>): Promise<IteratorResult<T>> {\n  const result = reflectCall(iteratorRecord.nextMethod, iteratorRecord.iterator, []);\n  if (!typeIsObject(result)) {\n    throw new TypeError('The iterator.next() method must return an object');\n  }\n  return result;\n}\n\nexport function IteratorComplete<TReturn>(\n  iterResult: IteratorResult<unknown, TReturn>\n): iterResult is IteratorReturnResult<TReturn> {\n  assert(typeIsObject(iterResult));\n  return Boolean(iterResult.done);\n}\n\nexport function IteratorValue<T>(iterResult: IteratorYieldResult<T>): T {\n  assert(typeIsObject(iterResult));\n  return iterResult.value;\n}\n","import NumberIsNaN from '../../stub/number-isnan';\nimport { ArrayBufferSlice } from './ecmascript';\nimport type { NonShared } from '../helpers/array-buffer-view';\n\nexport function IsNonNegativeNumber(v: number): boolean {\n  if (typeof v !== 'number') {\n    return false;\n  }\n\n  if (NumberIsNaN(v)) {\n    return false;\n  }\n\n  if (v < 0) {\n    return false;\n  }\n\n  return true;\n}\n\nexport function CloneAsUint8Array(O: NonShared<ArrayBufferView>): NonShared<Uint8Array> {\n  const buffer = ArrayBufferSlice(O.buffer, O.byteOffset, O.byteOffset + O.byteLength);\n  return new Uint8Array(buffer) as NonShared<Uint8Array>;\n}\n","import assert from '../../stub/assert';\nimport { SimpleQueue } from '../simple-queue';\nimport { IsNonNegativeNumber } from './miscellaneous';\n\nexport interface QueueContainer<T> {\n  _queue: SimpleQueue<T>;\n  _queueTotalSize: number;\n}\n\nexport interface QueuePair<T> {\n  value: T;\n  size: number;\n}\n\nexport function DequeueValue<T>(container: QueueContainer<QueuePair<T>>): T {\n  assert('_queue' in container && '_queueTotalSize' in container);\n  assert(container._queue.length > 0);\n\n  const pair = container._queue.shift()!;\n  container._queueTotalSize -= pair.size;\n  if (container._queueTotalSize < 0) {\n    container._queueTotalSize = 0;\n  }\n\n  return pair.value;\n}\n\nexport function EnqueueValueWithSize<T>(container: QueueContainer<QueuePair<T>>, value: T, size: number) {\n  assert('_queue' in container && '_queueTotalSize' in container);\n\n  if (!IsNonNegativeNumber(size) || size === Infinity) {\n    throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n  }\n\n  container._queue.push({ value, size });\n  container._queueTotalSize += size;\n}\n\nexport function PeekQueueValue<T>(container: QueueContainer<QueuePair<T>>): T {\n  assert('_queue' in container && '_queueTotalSize' in container);\n  assert(container._queue.length > 0);\n\n  const pair = container._queue.peek();\n  return pair.value;\n}\n\nexport function ResetQueue<T>(container: QueueContainer<T>) {\n  assert('_queue' in container && '_queueTotalSize' in container);\n\n  container._queue = new SimpleQueue<T>();\n  container._queueTotalSize = 0;\n}\n","export type TypedArray =\n  | Int8Array\n  | Uint8Array\n  | Uint8ClampedArray\n  | Int16Array\n  | Uint16Array\n  | Int32Array\n  | Uint32Array\n  | Float32Array\n  | Float64Array;\n\nexport type NonShared<T extends ArrayBufferView> = T & {\n  buffer: ArrayBuffer;\n}\n\nexport interface ArrayBufferViewConstructor<T extends ArrayBufferView = ArrayBufferView> {\n  new(buffer: ArrayBuffer, byteOffset: number, length?: number): T;\n\n  readonly prototype: T;\n}\n\nexport interface TypedArrayConstructor<T extends TypedArray = TypedArray> extends ArrayBufferViewConstructor<T> {\n  readonly BYTES_PER_ELEMENT: number;\n}\n\nexport type DataViewConstructor = ArrayBufferViewConstructor<DataView>;\n\nfunction isDataViewConstructor(ctor: Function): ctor is DataViewConstructor {\n  return ctor === DataView;\n}\n\nexport function isDataView(view: ArrayBufferView): view is DataView {\n  return isDataViewConstructor(view.constructor);\n}\n\nexport function arrayBufferViewElementSize<T extends ArrayBufferView>(ctor: ArrayBufferViewConstructor<T>): number {\n  if (isDataViewConstructor(ctor)) {\n    return 1;\n  }\n  return (ctor as unknown as TypedArrayConstructor).BYTES_PER_ELEMENT;\n}\n","import assert from '../../stub/assert';\nimport { SimpleQueue } from '../simple-queue';\nimport { ResetQueue } from '../abstract-ops/queue-with-sizes';\nimport {\n  IsReadableStreamDefaultReader,\n  ReadableStreamAddReadRequest,\n  ReadableStreamFulfillReadRequest,\n  ReadableStreamGetNumReadRequests,\n  ReadableStreamHasDefaultReader,\n  type ReadRequest\n} from './default-reader';\nimport {\n  ReadableStreamAddReadIntoRequest,\n  ReadableStreamFulfillReadIntoRequest,\n  ReadableStreamGetNumReadIntoRequests,\n  ReadableStreamHasBYOBReader,\n  type ReadIntoRequest\n} from './byob-reader';\nimport NumberIsInteger from '../../stub/number-isinteger';\nimport {\n  IsReadableStreamLocked,\n  type ReadableByteStream,\n  ReadableStreamClose,\n  ReadableStreamError\n} from '../readable-stream';\nimport type { ValidatedUnderlyingByteSource } from './underlying-source';\nimport { setFunctionName, typeIsObject } from '../helpers/miscellaneous';\nimport {\n  ArrayBufferSlice,\n  CanTransferArrayBuffer,\n  CopyDataBlockBytes,\n  IsDetachedBuffer,\n  TransferArrayBuffer\n} from '../abstract-ops/ecmascript';\nimport { CancelSteps, PullSteps, ReleaseSteps } from '../abstract-ops/internal-methods';\nimport { promiseResolvedWith, uponPromise } from '../helpers/webidl';\nimport { assertRequiredArgument, convertUnsignedLongLongWithEnforceRange } from '../validators/basic';\nimport {\n  type ArrayBufferViewConstructor,\n  arrayBufferViewElementSize,\n  type NonShared,\n  type TypedArrayConstructor\n} from '../helpers/array-buffer-view';\n\n/**\n * A pull-into request in a {@link ReadableByteStreamController}.\n *\n * @public\n */\nexport class ReadableStreamBYOBRequest {\n  /** @internal */\n  _associatedReadableByteStreamController!: ReadableByteStreamController;\n  /** @internal */\n  _view!: NonShared<ArrayBufferView> | null;\n\n  private constructor() {\n    throw new TypeError('Illegal constructor');\n  }\n\n  /**\n   * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n   */\n  get view(): ArrayBufferView | null {\n    if (!IsReadableStreamBYOBRequest(this)) {\n      throw byobRequestBrandCheckException('view');\n    }\n\n    return this._view;\n  }\n\n  /**\n   * Indicates to the associated readable byte stream that `bytesWritten` bytes were written into\n   * {@link ReadableStreamBYOBRequest.view | view}, causing the result be surfaced to the consumer.\n   *\n   * After this method is called, {@link ReadableStreamBYOBRequest.view | view} will be transferred and no longer\n   * modifiable.\n   */\n  respond(bytesWritten: number): void;\n  respond(bytesWritten: number | undefined): void {\n    if (!IsReadableStreamBYOBRequest(this)) {\n      throw byobRequestBrandCheckException('respond');\n    }\n    assertRequiredArgument(bytesWritten, 1, 'respond');\n    bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n\n    if (this._associatedReadableByteStreamController === undefined) {\n      throw new TypeError('This BYOB request has been invalidated');\n    }\n\n    if (IsDetachedBuffer(this._view!.buffer)) {\n      throw new TypeError(`The BYOB request's buffer has been detached and so cannot be used as a response`);\n    }\n\n    assert(this._view!.byteLength > 0);\n    assert(this._view!.buffer.byteLength > 0);\n\n    ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n  }\n\n  /**\n   * Indicates to the associated readable byte stream that instead of writing into\n   * {@link ReadableStreamBYOBRequest.view | view}, the underlying byte source is providing a new `ArrayBufferView`,\n   * which will be given to the consumer of the readable byte stream.\n   *\n   * After this method is called, `view` will be transferred and no longer modifiable.\n   */\n  respondWithNewView(view: ArrayBufferView): void;\n  respondWithNewView(view: NonShared<ArrayBufferView>): void {\n    if (!IsReadableStreamBYOBRequest(this)) {\n      throw byobRequestBrandCheckException('respondWithNewView');\n    }\n    assertRequiredArgument(view, 1, 'respondWithNewView');\n\n    if (!ArrayBuffer.isView(view)) {\n      throw new TypeError('You can only respond with array buffer views');\n    }\n\n    if (this._associatedReadableByteStreamController === undefined) {\n      throw new TypeError('This BYOB request has been invalidated');\n    }\n\n    if (IsDetachedBuffer(view.buffer)) {\n      throw new TypeError('The given view\\'s buffer has been detached and so cannot be used as a response');\n    }\n\n    ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n  }\n}\n\nObject.defineProperties(ReadableStreamBYOBRequest.prototype, {\n  respond: { enumerable: true },\n  respondWithNewView: { enumerable: true },\n  view: { enumerable: true }\n});\nsetFunctionName(ReadableStreamBYOBRequest.prototype.respond, 'respond');\nsetFunctionName(ReadableStreamBYOBRequest.prototype.respondWithNewView, 'respondWithNewView');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableStreamBYOBRequest.prototype, Symbol.toStringTag, {\n    value: 'ReadableStreamBYOBRequest',\n    configurable: true\n  });\n}\n\ninterface ByteQueueElement {\n  buffer: ArrayBuffer;\n  byteOffset: number;\n  byteLength: number;\n}\n\ntype PullIntoDescriptor<T extends NonShared<ArrayBufferView> = NonShared<ArrayBufferView>> =\n  DefaultPullIntoDescriptor\n  | BYOBPullIntoDescriptor<T>;\n\ninterface DefaultPullIntoDescriptor {\n  buffer: ArrayBuffer;\n  bufferByteLength: number;\n  byteOffset: number;\n  byteLength: number;\n  bytesFilled: number;\n  minimumFill: number;\n  elementSize: number;\n  viewConstructor: TypedArrayConstructor<Uint8Array>;\n  readerType: 'default' | 'none';\n}\n\ninterface BYOBPullIntoDescriptor<T extends NonShared<ArrayBufferView> = NonShared<ArrayBufferView>> {\n  buffer: ArrayBuffer;\n  bufferByteLength: number;\n  byteOffset: number;\n  byteLength: number;\n  bytesFilled: number;\n  minimumFill: number;\n  elementSize: number;\n  viewConstructor: ArrayBufferViewConstructor<T>;\n  readerType: 'byob' | 'none';\n}\n\n/**\n * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n *\n * @public\n */\nexport class ReadableByteStreamController {\n  /** @internal */\n  _controlledReadableByteStream!: ReadableByteStream;\n  /** @internal */\n  _queue!: SimpleQueue<ByteQueueElement>;\n  /** @internal */\n  _queueTotalSize!: number;\n  /** @internal */\n  _started!: boolean;\n  /** @internal */\n  _closeRequested!: boolean;\n  /** @internal */\n  _pullAgain!: boolean;\n  /** @internal */\n  _pulling !: boolean;\n  /** @internal */\n  _strategyHWM!: number;\n  /** @internal */\n  _pullAlgorithm!: () => Promise<void>;\n  /** @internal */\n  _cancelAlgorithm!: (reason: any) => Promise<void>;\n  /** @internal */\n  _autoAllocateChunkSize: number | undefined;\n  /** @internal */\n  _byobRequest: ReadableStreamBYOBRequest | null;\n  /** @internal */\n  _pendingPullIntos!: SimpleQueue<PullIntoDescriptor>;\n\n  private constructor() {\n    throw new TypeError('Illegal constructor');\n  }\n\n  /**\n   * Returns the current BYOB pull request, or `null` if there isn't one.\n   */\n  get byobRequest(): ReadableStreamBYOBRequest | null {\n    if (!IsReadableByteStreamController(this)) {\n      throw byteStreamControllerBrandCheckException('byobRequest');\n    }\n\n    return ReadableByteStreamControllerGetBYOBRequest(this);\n  }\n\n  /**\n   * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n   * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n   */\n  get desiredSize(): number | null {\n    if (!IsReadableByteStreamController(this)) {\n      throw byteStreamControllerBrandCheckException('desiredSize');\n    }\n\n    return ReadableByteStreamControllerGetDesiredSize(this);\n  }\n\n  /**\n   * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n   * the stream, but once those are read, the stream will become closed.\n   */\n  close(): void {\n    if (!IsReadableByteStreamController(this)) {\n      throw byteStreamControllerBrandCheckException('close');\n    }\n\n    if (this._closeRequested) {\n      throw new TypeError('The stream has already been closed; do not close it again!');\n    }\n\n    const state = this._controlledReadableByteStream._state;\n    if (state !== 'readable') {\n      throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be closed`);\n    }\n\n    ReadableByteStreamControllerClose(this);\n  }\n\n  /**\n   * Enqueues the given chunk chunk in the controlled readable stream.\n   * The chunk has to be an `ArrayBufferView` instance, or else a `TypeError` will be thrown.\n   */\n  enqueue(chunk: ArrayBufferView): void;\n  enqueue(chunk: NonShared<ArrayBufferView>): void {\n    if (!IsReadableByteStreamController(this)) {\n      throw byteStreamControllerBrandCheckException('enqueue');\n    }\n\n    assertRequiredArgument(chunk, 1, 'enqueue');\n    if (!ArrayBuffer.isView(chunk)) {\n      throw new TypeError('chunk must be an array buffer view');\n    }\n    if (chunk.byteLength === 0) {\n      throw new TypeError('chunk must have non-zero byteLength');\n    }\n    if (chunk.buffer.byteLength === 0) {\n      throw new TypeError(`chunk's buffer must have non-zero byteLength`);\n    }\n\n    if (this._closeRequested) {\n      throw new TypeError('stream is closed or draining');\n    }\n\n    const state = this._controlledReadableByteStream._state;\n    if (state !== 'readable') {\n      throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be enqueued to`);\n    }\n\n    ReadableByteStreamControllerEnqueue(this, chunk);\n  }\n\n  /**\n   * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n   */\n  error(e: any = undefined): void {\n    if (!IsReadableByteStreamController(this)) {\n      throw byteStreamControllerBrandCheckException('error');\n    }\n\n    ReadableByteStreamControllerError(this, e);\n  }\n\n  /** @internal */\n  [CancelSteps](reason: any): Promise<void> {\n    ReadableByteStreamControllerClearPendingPullIntos(this);\n\n    ResetQueue(this);\n\n    const result = this._cancelAlgorithm(reason);\n    ReadableByteStreamControllerClearAlgorithms(this);\n    return result;\n  }\n\n  /** @internal */\n  [PullSteps](readRequest: ReadRequest<NonShared<Uint8Array>>): void {\n    const stream = this._controlledReadableByteStream;\n    assert(ReadableStreamHasDefaultReader(stream));\n\n    if (this._queueTotalSize > 0) {\n      assert(ReadableStreamGetNumReadRequests(stream) === 0);\n\n      ReadableByteStreamControllerFillReadRequestFromQueue(this, readRequest);\n      return;\n    }\n\n    const autoAllocateChunkSize = this._autoAllocateChunkSize;\n    if (autoAllocateChunkSize !== undefined) {\n      let buffer: ArrayBuffer;\n      try {\n        buffer = new ArrayBuffer(autoAllocateChunkSize);\n      } catch (bufferE) {\n        readRequest._errorSteps(bufferE);\n        return;\n      }\n\n      const pullIntoDescriptor: DefaultPullIntoDescriptor = {\n        buffer,\n        bufferByteLength: autoAllocateChunkSize,\n        byteOffset: 0,\n        byteLength: autoAllocateChunkSize,\n        bytesFilled: 0,\n        minimumFill: 1,\n        elementSize: 1,\n        viewConstructor: Uint8Array,\n        readerType: 'default'\n      };\n\n      this._pendingPullIntos.push(pullIntoDescriptor);\n    }\n\n    ReadableStreamAddReadRequest(stream, readRequest);\n    ReadableByteStreamControllerCallPullIfNeeded(this);\n  }\n\n  /** @internal */\n  [ReleaseSteps](): void {\n    if (this._pendingPullIntos.length > 0) {\n      const firstPullInto = this._pendingPullIntos.peek();\n      firstPullInto.readerType = 'none';\n\n      this._pendingPullIntos = new SimpleQueue();\n      this._pendingPullIntos.push(firstPullInto);\n    }\n  }\n}\n\nObject.defineProperties(ReadableByteStreamController.prototype, {\n  close: { enumerable: true },\n  enqueue: { enumerable: true },\n  error: { enumerable: true },\n  byobRequest: { enumerable: true },\n  desiredSize: { enumerable: true }\n});\nsetFunctionName(ReadableByteStreamController.prototype.close, 'close');\nsetFunctionName(ReadableByteStreamController.prototype.enqueue, 'enqueue');\nsetFunctionName(ReadableByteStreamController.prototype.error, 'error');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableByteStreamController.prototype, Symbol.toStringTag, {\n    value: 'ReadableByteStreamController',\n    configurable: true\n  });\n}\n\n// Abstract operations for the ReadableByteStreamController.\n\nexport function IsReadableByteStreamController(x: any): x is ReadableByteStreamController {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n    return false;\n  }\n\n  return x instanceof ReadableByteStreamController;\n}\n\nfunction IsReadableStreamBYOBRequest(x: any): x is ReadableStreamBYOBRequest {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n    return false;\n  }\n\n  return x instanceof ReadableStreamBYOBRequest;\n}\n\nfunction ReadableByteStreamControllerCallPullIfNeeded(controller: ReadableByteStreamController): void {\n  const shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n  if (!shouldPull) {\n    return;\n  }\n\n  if (controller._pulling) {\n    controller._pullAgain = true;\n    return;\n  }\n\n  assert(!controller._pullAgain);\n\n  controller._pulling = true;\n\n  // TODO: Test controller argument\n  const pullPromise = controller._pullAlgorithm();\n  uponPromise(\n    pullPromise,\n    () => {\n      controller._pulling = false;\n\n      if (controller._pullAgain) {\n        controller._pullAgain = false;\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n      }\n\n      return null;\n    },\n    e => {\n      ReadableByteStreamControllerError(controller, e);\n      return null;\n    }\n  );\n}\n\nfunction ReadableByteStreamControllerClearPendingPullIntos(controller: ReadableByteStreamController) {\n  ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n  controller._pendingPullIntos = new SimpleQueue();\n}\n\nfunction ReadableByteStreamControllerCommitPullIntoDescriptor<T extends NonShared<ArrayBufferView>>(\n  stream: ReadableByteStream,\n  pullIntoDescriptor: PullIntoDescriptor<T>\n) {\n  assert(stream._state !== 'errored');\n  assert(pullIntoDescriptor.readerType !== 'none');\n\n  let done = false;\n  if (stream._state === 'closed') {\n    assert(pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize === 0);\n    done = true;\n  }\n\n  const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor<T>(pullIntoDescriptor);\n  if (pullIntoDescriptor.readerType === 'default') {\n    ReadableStreamFulfillReadRequest(stream, filledView as unknown as NonShared<Uint8Array>, done);\n  } else {\n    assert(pullIntoDescriptor.readerType === 'byob');\n    ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n  }\n}\n\nfunction ReadableByteStreamControllerConvertPullIntoDescriptor<T extends NonShared<ArrayBufferView>>(\n  pullIntoDescriptor: PullIntoDescriptor<T>\n): T {\n  const bytesFilled = pullIntoDescriptor.bytesFilled;\n  const elementSize = pullIntoDescriptor.elementSize;\n\n  assert(bytesFilled <= pullIntoDescriptor.byteLength);\n  assert(bytesFilled % elementSize === 0);\n\n  return new pullIntoDescriptor.viewConstructor(\n    pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize) as T;\n}\n\nfunction ReadableByteStreamControllerEnqueueChunkToQueue(controller: ReadableByteStreamController,\n                                                         buffer: ArrayBuffer,\n                                                         byteOffset: number,\n                                                         byteLength: number) {\n  controller._queue.push({ buffer, byteOffset, byteLength });\n  controller._queueTotalSize += byteLength;\n}\n\nfunction ReadableByteStreamControllerEnqueueClonedChunkToQueue(controller: ReadableByteStreamController,\n                                                               buffer: ArrayBuffer,\n                                                               byteOffset: number,\n                                                               byteLength: number) {\n  let clonedChunk;\n  try {\n    clonedChunk = ArrayBufferSlice(buffer, byteOffset, byteOffset + byteLength);\n  } catch (cloneE) {\n    ReadableByteStreamControllerError(controller, cloneE);\n    throw cloneE;\n  }\n  ReadableByteStreamControllerEnqueueChunkToQueue(controller, clonedChunk, 0, byteLength);\n}\n\nfunction ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller: ReadableByteStreamController,\n                                                                    firstDescriptor: PullIntoDescriptor) {\n  assert(firstDescriptor.readerType === 'none');\n  if (firstDescriptor.bytesFilled > 0) {\n    ReadableByteStreamControllerEnqueueClonedChunkToQueue(\n      controller,\n      firstDescriptor.buffer,\n      firstDescriptor.byteOffset,\n      firstDescriptor.bytesFilled\n    );\n  }\n  ReadableByteStreamControllerShiftPendingPullInto(controller);\n}\n\nfunction ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller: ReadableByteStreamController,\n                                                                     pullIntoDescriptor: PullIntoDescriptor) {\n  const maxBytesToCopy = Math.min(controller._queueTotalSize,\n                                  pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n  const maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n\n  let totalBytesToCopyRemaining = maxBytesToCopy;\n  let ready = false;\n  assert(pullIntoDescriptor.bytesFilled < pullIntoDescriptor.minimumFill);\n  const remainderBytes = maxBytesFilled % pullIntoDescriptor.elementSize;\n  const maxAlignedBytes = maxBytesFilled - remainderBytes;\n  // A descriptor for a read() request that is not yet filled up to its minimum length will stay at the head\n  // of the queue, so the underlying source can keep filling it.\n  if (maxAlignedBytes >= pullIntoDescriptor.minimumFill) {\n    totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n    ready = true;\n  }\n\n  const queue = controller._queue;\n\n  while (totalBytesToCopyRemaining > 0) {\n    const headOfQueue = queue.peek();\n\n    const bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n\n    const destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n    CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n\n    if (headOfQueue.byteLength === bytesToCopy) {\n      queue.shift();\n    } else {\n      headOfQueue.byteOffset += bytesToCopy;\n      headOfQueue.byteLength -= bytesToCopy;\n    }\n    controller._queueTotalSize -= bytesToCopy;\n\n    ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n\n    totalBytesToCopyRemaining -= bytesToCopy;\n  }\n\n  if (!ready) {\n    assert(controller._queueTotalSize === 0);\n    assert(pullIntoDescriptor.bytesFilled > 0);\n    assert(pullIntoDescriptor.bytesFilled < pullIntoDescriptor.minimumFill);\n  }\n\n  return ready;\n}\n\nfunction ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller: ReadableByteStreamController,\n                                                                size: number,\n                                                                pullIntoDescriptor: PullIntoDescriptor) {\n  assert(controller._pendingPullIntos.length === 0 || controller._pendingPullIntos.peek() === pullIntoDescriptor);\n  assert(controller._byobRequest === null);\n  pullIntoDescriptor.bytesFilled += size;\n}\n\nfunction ReadableByteStreamControllerHandleQueueDrain(controller: ReadableByteStreamController) {\n  assert(controller._controlledReadableByteStream._state === 'readable');\n\n  if (controller._queueTotalSize === 0 && controller._closeRequested) {\n    ReadableByteStreamControllerClearAlgorithms(controller);\n    ReadableStreamClose(controller._controlledReadableByteStream);\n  } else {\n    ReadableByteStreamControllerCallPullIfNeeded(controller);\n  }\n}\n\nfunction ReadableByteStreamControllerInvalidateBYOBRequest(controller: ReadableByteStreamController) {\n  if (controller._byobRequest === null) {\n    return;\n  }\n\n  controller._byobRequest._associatedReadableByteStreamController = undefined!;\n  controller._byobRequest._view = null!;\n  controller._byobRequest = null;\n}\n\nfunction ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller: ReadableByteStreamController) {\n  assert(!controller._closeRequested);\n\n  while (controller._pendingPullIntos.length > 0) {\n    if (controller._queueTotalSize === 0) {\n      return;\n    }\n\n    const pullIntoDescriptor = controller._pendingPullIntos.peek();\n    assert(pullIntoDescriptor.readerType !== 'none');\n\n    if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n      ReadableByteStreamControllerShiftPendingPullInto(controller);\n\n      ReadableByteStreamControllerCommitPullIntoDescriptor(\n        controller._controlledReadableByteStream,\n        pullIntoDescriptor\n      );\n    }\n  }\n}\n\nfunction ReadableByteStreamControllerProcessReadRequestsUsingQueue(controller: ReadableByteStreamController) {\n  const reader = controller._controlledReadableByteStream._reader;\n  assert(IsReadableStreamDefaultReader(reader));\n  while (reader._readRequests.length > 0) {\n    if (controller._queueTotalSize === 0) {\n      return;\n    }\n    const readRequest = reader._readRequests.shift();\n    ReadableByteStreamControllerFillReadRequestFromQueue(controller, readRequest);\n  }\n}\n\nexport function ReadableByteStreamControllerPullInto<T extends NonShared<ArrayBufferView>>(\n  controller: ReadableByteStreamController,\n  view: T,\n  min: number,\n  readIntoRequest: ReadIntoRequest<T>\n): void {\n  const stream = controller._controlledReadableByteStream;\n\n  const ctor = view.constructor as ArrayBufferViewConstructor<T>;\n  const elementSize = arrayBufferViewElementSize(ctor);\n\n  const { byteOffset, byteLength } = view;\n\n  const minimumFill = min * elementSize;\n  assert(minimumFill >= elementSize && minimumFill <= byteLength);\n  assert(minimumFill % elementSize === 0);\n\n  let buffer: ArrayBuffer;\n  try {\n    buffer = TransferArrayBuffer(view.buffer);\n  } catch (e) {\n    readIntoRequest._errorSteps(e);\n    return;\n  }\n\n  const pullIntoDescriptor: BYOBPullIntoDescriptor<T> = {\n    buffer,\n    bufferByteLength: buffer.byteLength,\n    byteOffset,\n    byteLength,\n    bytesFilled: 0,\n    minimumFill,\n    elementSize,\n    viewConstructor: ctor,\n    readerType: 'byob'\n  };\n\n  if (controller._pendingPullIntos.length > 0) {\n    controller._pendingPullIntos.push(pullIntoDescriptor);\n\n    // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n    // - No change happens on desiredSize\n    // - The source has already been notified of that there's at least 1 pending read(view)\n\n    ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n    return;\n  }\n\n  if (stream._state === 'closed') {\n    const emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n    readIntoRequest._closeSteps(emptyView);\n    return;\n  }\n\n  if (controller._queueTotalSize > 0) {\n    if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n      const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor<T>(pullIntoDescriptor);\n\n      ReadableByteStreamControllerHandleQueueDrain(controller);\n\n      readIntoRequest._chunkSteps(filledView);\n      return;\n    }\n\n    if (controller._closeRequested) {\n      const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n      ReadableByteStreamControllerError(controller, e);\n\n      readIntoRequest._errorSteps(e);\n      return;\n    }\n  }\n\n  controller._pendingPullIntos.push(pullIntoDescriptor);\n\n  ReadableStreamAddReadIntoRequest<T>(stream, readIntoRequest);\n  ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\n\nfunction ReadableByteStreamControllerRespondInClosedState(controller: ReadableByteStreamController,\n                                                          firstDescriptor: PullIntoDescriptor) {\n  assert(firstDescriptor.bytesFilled % firstDescriptor.elementSize === 0);\n\n  if (firstDescriptor.readerType === 'none') {\n    ReadableByteStreamControllerShiftPendingPullInto(controller);\n  }\n\n  const stream = controller._controlledReadableByteStream;\n  if (ReadableStreamHasBYOBReader(stream)) {\n    while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n      const pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n      ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n    }\n  }\n}\n\nfunction ReadableByteStreamControllerRespondInReadableState(controller: ReadableByteStreamController,\n                                                            bytesWritten: number,\n                                                            pullIntoDescriptor: PullIntoDescriptor) {\n  assert(pullIntoDescriptor.bytesFilled + bytesWritten <= pullIntoDescriptor.byteLength);\n\n  ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n\n  if (pullIntoDescriptor.readerType === 'none') {\n    ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller, pullIntoDescriptor);\n    ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    return;\n  }\n\n  if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.minimumFill) {\n    // A descriptor for a read() request that is not yet filled up to its minimum length will stay at the head\n    // of the queue, so the underlying source can keep filling it.\n    return;\n  }\n\n  ReadableByteStreamControllerShiftPendingPullInto(controller);\n\n  const remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n  if (remainderSize > 0) {\n    const end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n    ReadableByteStreamControllerEnqueueClonedChunkToQueue(\n      controller,\n      pullIntoDescriptor.buffer,\n      end - remainderSize,\n      remainderSize\n    );\n  }\n\n  pullIntoDescriptor.bytesFilled -= remainderSize;\n  ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n\n  ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n}\n\nfunction ReadableByteStreamControllerRespondInternal(controller: ReadableByteStreamController, bytesWritten: number) {\n  const firstDescriptor = controller._pendingPullIntos.peek();\n  assert(CanTransferArrayBuffer(firstDescriptor.buffer));\n\n  ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n\n  const state = controller._controlledReadableByteStream._state;\n  if (state === 'closed') {\n    assert(bytesWritten === 0);\n    ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor);\n  } else {\n    assert(state === 'readable');\n    assert(bytesWritten > 0);\n    ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n  }\n\n  ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\n\nfunction ReadableByteStreamControllerShiftPendingPullInto(\n  controller: ReadableByteStreamController\n): PullIntoDescriptor {\n  assert(controller._byobRequest === null);\n  const descriptor = controller._pendingPullIntos.shift()!;\n  return descriptor;\n}\n\nfunction ReadableByteStreamControllerShouldCallPull(controller: ReadableByteStreamController): boolean {\n  const stream = controller._controlledReadableByteStream;\n\n  if (stream._state !== 'readable') {\n    return false;\n  }\n\n  if (controller._closeRequested) {\n    return false;\n  }\n\n  if (!controller._started) {\n    return false;\n  }\n\n  if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n    return true;\n  }\n\n  if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n    return true;\n  }\n\n  const desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n  assert(desiredSize !== null);\n  if (desiredSize! > 0) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction ReadableByteStreamControllerClearAlgorithms(controller: ReadableByteStreamController) {\n  controller._pullAlgorithm = undefined!;\n  controller._cancelAlgorithm = undefined!;\n}\n\n// A client of ReadableByteStreamController may use these functions directly to bypass state check.\n\nexport function ReadableByteStreamControllerClose(controller: ReadableByteStreamController) {\n  const stream = controller._controlledReadableByteStream;\n\n  if (controller._closeRequested || stream._state !== 'readable') {\n    return;\n  }\n\n  if (controller._queueTotalSize > 0) {\n    controller._closeRequested = true;\n\n    return;\n  }\n\n  if (controller._pendingPullIntos.length > 0) {\n    const firstPendingPullInto = controller._pendingPullIntos.peek();\n    if (firstPendingPullInto.bytesFilled % firstPendingPullInto.elementSize !== 0) {\n      const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n      ReadableByteStreamControllerError(controller, e);\n\n      throw e;\n    }\n  }\n\n  ReadableByteStreamControllerClearAlgorithms(controller);\n  ReadableStreamClose(stream);\n}\n\nexport function ReadableByteStreamControllerEnqueue(\n  controller: ReadableByteStreamController,\n  chunk: NonShared<ArrayBufferView>\n) {\n  const stream = controller._controlledReadableByteStream;\n\n  if (controller._closeRequested || stream._state !== 'readable') {\n    return;\n  }\n\n  const { buffer, byteOffset, byteLength } = chunk;\n  if (IsDetachedBuffer(buffer)) {\n    throw new TypeError('chunk\\'s buffer is detached and so cannot be enqueued');\n  }\n  const transferredBuffer = TransferArrayBuffer(buffer);\n\n  if (controller._pendingPullIntos.length > 0) {\n    const firstPendingPullInto = controller._pendingPullIntos.peek();\n    if (IsDetachedBuffer(firstPendingPullInto.buffer)) {\n      throw new TypeError(\n        'The BYOB request\\'s buffer has been detached and so cannot be filled with an enqueued chunk'\n      );\n    }\n    ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n    firstPendingPullInto.buffer = TransferArrayBuffer(firstPendingPullInto.buffer);\n    if (firstPendingPullInto.readerType === 'none') {\n      ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller, firstPendingPullInto);\n    }\n  }\n\n  if (ReadableStreamHasDefaultReader(stream)) {\n    ReadableByteStreamControllerProcessReadRequestsUsingQueue(controller);\n    if (ReadableStreamGetNumReadRequests(stream) === 0) {\n      assert(controller._pendingPullIntos.length === 0);\n      ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n    } else {\n      assert(controller._queue.length === 0);\n      if (controller._pendingPullIntos.length > 0) {\n        assert(controller._pendingPullIntos.peek().readerType === 'default');\n        ReadableByteStreamControllerShiftPendingPullInto(controller);\n      }\n      const transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n      ReadableStreamFulfillReadRequest(stream, transferredView as NonShared<Uint8Array>, false);\n    }\n  } else if (ReadableStreamHasBYOBReader(stream)) {\n    // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n    ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n    ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n  } else {\n    assert(!IsReadableStreamLocked(stream));\n    ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n  }\n\n  ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\n\nexport function ReadableByteStreamControllerError(controller: ReadableByteStreamController, e: any) {\n  const stream = controller._controlledReadableByteStream;\n\n  if (stream._state !== 'readable') {\n    return;\n  }\n\n  ReadableByteStreamControllerClearPendingPullIntos(controller);\n\n  ResetQueue(controller);\n  ReadableByteStreamControllerClearAlgorithms(controller);\n  ReadableStreamError(stream, e);\n}\n\nexport function ReadableByteStreamControllerFillReadRequestFromQueue(\n  controller: ReadableByteStreamController,\n  readRequest: ReadRequest<NonShared<Uint8Array>>\n) {\n  assert(controller._queueTotalSize > 0);\n\n  const entry = controller._queue.shift();\n  controller._queueTotalSize -= entry.byteLength;\n\n  ReadableByteStreamControllerHandleQueueDrain(controller);\n\n  const view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n  readRequest._chunkSteps(view as NonShared<Uint8Array>);\n}\n\nexport function ReadableByteStreamControllerGetBYOBRequest(\n  controller: ReadableByteStreamController\n): ReadableStreamBYOBRequest | null {\n  if (controller._byobRequest === null && controller._pendingPullIntos.length > 0) {\n    const firstDescriptor = controller._pendingPullIntos.peek();\n    const view = new Uint8Array(firstDescriptor.buffer,\n                                firstDescriptor.byteOffset + firstDescriptor.bytesFilled,\n                                firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n\n    const byobRequest: ReadableStreamBYOBRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n    SetUpReadableStreamBYOBRequest(byobRequest, controller, view as NonShared<Uint8Array>);\n    controller._byobRequest = byobRequest;\n  }\n  return controller._byobRequest;\n}\n\nfunction ReadableByteStreamControllerGetDesiredSize(controller: ReadableByteStreamController): number | null {\n  const state = controller._controlledReadableByteStream._state;\n\n  if (state === 'errored') {\n    return null;\n  }\n  if (state === 'closed') {\n    return 0;\n  }\n\n  return controller._strategyHWM - controller._queueTotalSize;\n}\n\nexport function ReadableByteStreamControllerRespond(controller: ReadableByteStreamController, bytesWritten: number) {\n  assert(controller._pendingPullIntos.length > 0);\n\n  const firstDescriptor = controller._pendingPullIntos.peek();\n  const state = controller._controlledReadableByteStream._state;\n\n  if (state === 'closed') {\n    if (bytesWritten !== 0) {\n      throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n    }\n  } else {\n    assert(state === 'readable');\n    if (bytesWritten === 0) {\n      throw new TypeError('bytesWritten must be greater than 0 when calling respond() on a readable stream');\n    }\n    if (firstDescriptor.bytesFilled + bytesWritten > firstDescriptor.byteLength) {\n      throw new RangeError('bytesWritten out of range');\n    }\n  }\n\n  firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n\n  ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n}\n\nexport function ReadableByteStreamControllerRespondWithNewView(controller: ReadableByteStreamController,\n                                                               view: NonShared<ArrayBufferView>) {\n  assert(controller._pendingPullIntos.length > 0);\n  assert(!IsDetachedBuffer(view.buffer));\n\n  const firstDescriptor = controller._pendingPullIntos.peek();\n  const state = controller._controlledReadableByteStream._state;\n\n  if (state === 'closed') {\n    if (view.byteLength !== 0) {\n      throw new TypeError('The view\\'s length must be 0 when calling respondWithNewView() on a closed stream');\n    }\n  } else {\n    assert(state === 'readable');\n    if (view.byteLength === 0) {\n      throw new TypeError(\n        'The view\\'s length must be greater than 0 when calling respondWithNewView() on a readable stream'\n      );\n    }\n  }\n\n  if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n    throw new RangeError('The region specified by view does not match byobRequest');\n  }\n  if (firstDescriptor.bufferByteLength !== view.buffer.byteLength) {\n    throw new RangeError('The buffer of view has different capacity than byobRequest');\n  }\n  if (firstDescriptor.bytesFilled + view.byteLength > firstDescriptor.byteLength) {\n    throw new RangeError('The region specified by view is larger than byobRequest');\n  }\n\n  const viewByteLength = view.byteLength;\n  firstDescriptor.buffer = TransferArrayBuffer(view.buffer);\n  ReadableByteStreamControllerRespondInternal(controller, viewByteLength);\n}\n\nexport function SetUpReadableByteStreamController(stream: ReadableByteStream,\n                                                  controller: ReadableByteStreamController,\n                                                  startAlgorithm: () => void | PromiseLike<void>,\n                                                  pullAlgorithm: () => Promise<void>,\n                                                  cancelAlgorithm: (reason: any) => Promise<void>,\n                                                  highWaterMark: number,\n                                                  autoAllocateChunkSize: number | undefined) {\n  assert(stream._readableStreamController === undefined);\n  if (autoAllocateChunkSize !== undefined) {\n    assert(NumberIsInteger(autoAllocateChunkSize));\n    assert(autoAllocateChunkSize > 0);\n  }\n\n  controller._controlledReadableByteStream = stream;\n\n  controller._pullAgain = false;\n  controller._pulling = false;\n\n  controller._byobRequest = null;\n\n  // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n  controller._queue = controller._queueTotalSize = undefined!;\n  ResetQueue(controller);\n\n  controller._closeRequested = false;\n  controller._started = false;\n\n  controller._strategyHWM = highWaterMark;\n\n  controller._pullAlgorithm = pullAlgorithm;\n  controller._cancelAlgorithm = cancelAlgorithm;\n\n  controller._autoAllocateChunkSize = autoAllocateChunkSize;\n\n  controller._pendingPullIntos = new SimpleQueue();\n\n  stream._readableStreamController = controller;\n\n  const startResult = startAlgorithm();\n  uponPromise(\n    promiseResolvedWith(startResult),\n    () => {\n      controller._started = true;\n\n      assert(!controller._pulling);\n      assert(!controller._pullAgain);\n\n      ReadableByteStreamControllerCallPullIfNeeded(controller);\n      return null;\n    },\n    r => {\n      ReadableByteStreamControllerError(controller, r);\n      return null;\n    }\n  );\n}\n\nexport function SetUpReadableByteStreamControllerFromUnderlyingSource(\n  stream: ReadableByteStream,\n  underlyingByteSource: ValidatedUnderlyingByteSource,\n  highWaterMark: number\n) {\n  const controller: ReadableByteStreamController = Object.create(ReadableByteStreamController.prototype);\n\n  let startAlgorithm: () => void | PromiseLike<void>;\n  let pullAlgorithm: () => Promise<void>;\n  let cancelAlgorithm: (reason: any) => Promise<void>;\n\n  if (underlyingByteSource.start !== undefined) {\n    startAlgorithm = () => underlyingByteSource.start!(controller);\n  } else {\n    startAlgorithm = () => undefined;\n  }\n  if (underlyingByteSource.pull !== undefined) {\n    pullAlgorithm = () => underlyingByteSource.pull!(controller);\n  } else {\n    pullAlgorithm = () => promiseResolvedWith(undefined);\n  }\n  if (underlyingByteSource.cancel !== undefined) {\n    cancelAlgorithm = reason => underlyingByteSource.cancel!(reason);\n  } else {\n    cancelAlgorithm = () => promiseResolvedWith(undefined);\n  }\n\n  const autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n  if (autoAllocateChunkSize === 0) {\n    throw new TypeError('autoAllocateChunkSize must be greater than 0');\n  }\n\n  SetUpReadableByteStreamController(\n    stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize\n  );\n}\n\nfunction SetUpReadableStreamBYOBRequest(request: ReadableStreamBYOBRequest,\n                                        controller: ReadableByteStreamController,\n                                        view: NonShared<ArrayBufferView>) {\n  assert(IsReadableByteStreamController(controller));\n  assert(typeof view === 'object');\n  assert(ArrayBuffer.isView(view));\n  assert(!IsDetachedBuffer(view.buffer));\n  request._associatedReadableByteStreamController = controller;\n  request._view = view;\n}\n\n// Helper functions for the ReadableStreamBYOBRequest.\n\nfunction byobRequestBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `ReadableStreamBYOBRequest.prototype.${name} can only be used on a ReadableStreamBYOBRequest`);\n}\n\n// Helper functions for the ReadableByteStreamController.\n\nfunction byteStreamControllerBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `ReadableByteStreamController.prototype.${name} can only be used on a ReadableByteStreamController`);\n}\n","import { assertDictionary, convertUnsignedLongLongWithEnforceRange } from './basic';\nimport type {\n  ReadableStreamBYOBReaderReadOptions,\n  ReadableStreamGetReaderOptions,\n  ValidatedReadableStreamBYOBReaderReadOptions\n} from '../readable-stream/reader-options';\n\nexport function convertReaderOptions(options: ReadableStreamGetReaderOptions | null | undefined,\n                                     context: string): ReadableStreamGetReaderOptions {\n  assertDictionary(options, context);\n  const mode = options?.mode;\n  return {\n    mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, `${context} has member 'mode' that`)\n  };\n}\n\nfunction convertReadableStreamReaderMode(mode: string, context: string): 'byob' {\n  mode = `${mode}`;\n  if (mode !== 'byob') {\n    throw new TypeError(`${context} '${mode}' is not a valid enumeration value for ReadableStreamReaderMode`);\n  }\n  return mode;\n}\n\nexport function convertByobReadOptions(\n  options: ReadableStreamBYOBReaderReadOptions | null | undefined,\n  context: string\n): ValidatedReadableStreamBYOBReaderReadOptions {\n  assertDictionary(options, context);\n  const min = options?.min ?? 1;\n  return {\n    min: convertUnsignedLongLongWithEnforceRange(\n      min,\n      `${context} has member 'min' that`\n    )\n  };\n}\n","import assert from '../../stub/assert';\nimport { SimpleQueue } from '../simple-queue';\nimport {\n  ReadableStreamReaderGenericCancel,\n  ReadableStreamReaderGenericInitialize,\n  ReadableStreamReaderGenericRelease,\n  readerLockException\n} from './generic-reader';\nimport { IsReadableStreamLocked, type ReadableByteStream, type ReadableStream } from '../readable-stream';\nimport {\n  IsReadableByteStreamController,\n  ReadableByteStreamController,\n  ReadableByteStreamControllerPullInto\n} from './byte-stream-controller';\nimport { setFunctionName, typeIsObject } from '../helpers/miscellaneous';\nimport { newPromise, promiseRejectedWith } from '../helpers/webidl';\nimport { assertRequiredArgument } from '../validators/basic';\nimport { assertReadableStream } from '../validators/readable-stream';\nimport { IsDetachedBuffer } from '../abstract-ops/ecmascript';\nimport type {\n  ReadableStreamBYOBReaderReadOptions,\n  ValidatedReadableStreamBYOBReaderReadOptions\n} from './reader-options';\nimport { convertByobReadOptions } from '../validators/reader-options';\nimport { isDataView, type NonShared, type TypedArray } from '../helpers/array-buffer-view';\n\n/**\n * A result returned by {@link ReadableStreamBYOBReader.read}.\n *\n * @public\n */\nexport type ReadableStreamBYOBReadResult<T extends ArrayBufferView> = {\n  done: false;\n  value: T;\n} | {\n  done: true;\n  value: T | undefined;\n};\n\n// Abstract operations for the ReadableStream.\n\nexport function AcquireReadableStreamBYOBReader(stream: ReadableByteStream): ReadableStreamBYOBReader {\n  return new ReadableStreamBYOBReader(stream as ReadableStream<Uint8Array>);\n}\n\n// ReadableStream API exposed for controllers.\n\nexport function ReadableStreamAddReadIntoRequest<T extends NonShared<ArrayBufferView>>(\n  stream: ReadableByteStream,\n  readIntoRequest: ReadIntoRequest<T>\n): void {\n  assert(IsReadableStreamBYOBReader(stream._reader));\n  assert(stream._state === 'readable' || stream._state === 'closed');\n\n  (stream._reader! as ReadableStreamBYOBReader)._readIntoRequests.push(readIntoRequest);\n}\n\nexport function ReadableStreamFulfillReadIntoRequest(stream: ReadableByteStream,\n                                                     chunk: ArrayBufferView,\n                                                     done: boolean) {\n  const reader = stream._reader as ReadableStreamBYOBReader;\n\n  assert(reader._readIntoRequests.length > 0);\n\n  const readIntoRequest = reader._readIntoRequests.shift()!;\n  if (done) {\n    readIntoRequest._closeSteps(chunk);\n  } else {\n    readIntoRequest._chunkSteps(chunk);\n  }\n}\n\nexport function ReadableStreamGetNumReadIntoRequests(stream: ReadableByteStream): number {\n  return (stream._reader as ReadableStreamBYOBReader)._readIntoRequests.length;\n}\n\nexport function ReadableStreamHasBYOBReader(stream: ReadableByteStream): boolean {\n  const reader = stream._reader;\n\n  if (reader === undefined) {\n    return false;\n  }\n\n  if (!IsReadableStreamBYOBReader(reader)) {\n    return false;\n  }\n\n  return true;\n}\n\n// Readers\n\nexport interface ReadIntoRequest<T extends NonShared<ArrayBufferView>> {\n  _chunkSteps(chunk: T): void;\n\n  _closeSteps(chunk: T | undefined): void;\n\n  _errorSteps(e: any): void;\n}\n\n/**\n * A BYOB reader vended by a {@link ReadableStream}.\n *\n * @public\n */\nexport class ReadableStreamBYOBReader {\n  /** @internal */\n  _ownerReadableStream!: ReadableByteStream;\n  /** @internal */\n  _closedPromise!: Promise<undefined>;\n  /** @internal */\n  _closedPromise_resolve?: (value?: undefined) => void;\n  /** @internal */\n  _closedPromise_reject?: (reason: any) => void;\n  /** @internal */\n  _readIntoRequests: SimpleQueue<ReadIntoRequest<any>>;\n\n  constructor(stream: ReadableStream<Uint8Array>) {\n    assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n    assertReadableStream(stream, 'First parameter');\n\n    if (IsReadableStreamLocked(stream)) {\n      throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n    }\n\n    if (!IsReadableByteStreamController(stream._readableStreamController)) {\n      throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n        'source');\n    }\n\n    ReadableStreamReaderGenericInitialize(this, stream);\n\n    this._readIntoRequests = new SimpleQueue();\n  }\n\n  /**\n   * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n   * the reader's lock is released before the stream finishes closing.\n   */\n  get closed(): Promise<undefined> {\n    if (!IsReadableStreamBYOBReader(this)) {\n      return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n    }\n\n    return this._closedPromise;\n  }\n\n  /**\n   * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n   */\n  cancel(reason: any = undefined): Promise<void> {\n    if (!IsReadableStreamBYOBReader(this)) {\n      return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return promiseRejectedWith(readerLockException('cancel'));\n    }\n\n    return ReadableStreamReaderGenericCancel(this, reason);\n  }\n\n  /**\n   * Attempts to reads bytes into view, and returns a promise resolved with the result.\n   *\n   * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n   */\n  read<T extends ArrayBufferView>(\n    view: T,\n    options?: ReadableStreamBYOBReaderReadOptions\n  ): Promise<ReadableStreamBYOBReadResult<T>>;\n  read<T extends NonShared<ArrayBufferView>>(\n    view: T,\n    rawOptions: ReadableStreamBYOBReaderReadOptions | null | undefined = {}\n  ): Promise<ReadableStreamBYOBReadResult<T>> {\n    if (!IsReadableStreamBYOBReader(this)) {\n      return promiseRejectedWith(byobReaderBrandCheckException('read'));\n    }\n\n    if (!ArrayBuffer.isView(view)) {\n      return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n    }\n    if (view.byteLength === 0) {\n      return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n    }\n    if (view.buffer.byteLength === 0) {\n      return promiseRejectedWith(new TypeError(`view's buffer must have non-zero byteLength`));\n    }\n    if (IsDetachedBuffer(view.buffer)) {\n      return promiseRejectedWith(new TypeError('view\\'s buffer has been detached'));\n    }\n\n    let options: ValidatedReadableStreamBYOBReaderReadOptions;\n    try {\n      options = convertByobReadOptions(rawOptions, 'options');\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n    const min = options.min;\n    if (min === 0) {\n      return promiseRejectedWith(new TypeError('options.min must be greater than 0'));\n    }\n    if (!isDataView(view)) {\n      if (min > (view as unknown as TypedArray).length) {\n        return promiseRejectedWith(new RangeError('options.min must be less than or equal to view\\'s length'));\n      }\n    } else if (min > view.byteLength) {\n      return promiseRejectedWith(new RangeError('options.min must be less than or equal to view\\'s byteLength'));\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return promiseRejectedWith(readerLockException('read from'));\n    }\n\n    let resolvePromise!: (result: ReadableStreamBYOBReadResult<T>) => void;\n    let rejectPromise!: (reason: any) => void;\n    const promise = newPromise<ReadableStreamBYOBReadResult<T>>((resolve, reject) => {\n      resolvePromise = resolve;\n      rejectPromise = reject;\n    });\n    const readIntoRequest: ReadIntoRequest<T> = {\n      _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n      _closeSteps: chunk => resolvePromise({ value: chunk, done: true }),\n      _errorSteps: e => rejectPromise(e)\n    };\n    ReadableStreamBYOBReaderRead(this, view, min, readIntoRequest);\n    return promise;\n  }\n\n  /**\n   * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n   * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n   * from now on; otherwise, the reader will appear closed.\n   *\n   * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n   * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n   * do so will throw a `TypeError` and leave the reader locked to the stream.\n   */\n  releaseLock(): void {\n    if (!IsReadableStreamBYOBReader(this)) {\n      throw byobReaderBrandCheckException('releaseLock');\n    }\n\n    if (this._ownerReadableStream === undefined) {\n      return;\n    }\n\n    ReadableStreamBYOBReaderRelease(this);\n  }\n}\n\nObject.defineProperties(ReadableStreamBYOBReader.prototype, {\n  cancel: { enumerable: true },\n  read: { enumerable: true },\n  releaseLock: { enumerable: true },\n  closed: { enumerable: true }\n});\nsetFunctionName(ReadableStreamBYOBReader.prototype.cancel, 'cancel');\nsetFunctionName(ReadableStreamBYOBReader.prototype.read, 'read');\nsetFunctionName(ReadableStreamBYOBReader.prototype.releaseLock, 'releaseLock');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableStreamBYOBReader.prototype, Symbol.toStringTag, {\n    value: 'ReadableStreamBYOBReader',\n    configurable: true\n  });\n}\n\n// Abstract operations for the readers.\n\nexport function IsReadableStreamBYOBReader(x: any): x is ReadableStreamBYOBReader {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n    return false;\n  }\n\n  return x instanceof ReadableStreamBYOBReader;\n}\n\nexport function ReadableStreamBYOBReaderRead<T extends NonShared<ArrayBufferView>>(\n  reader: ReadableStreamBYOBReader,\n  view: T,\n  min: number,\n  readIntoRequest: ReadIntoRequest<T>\n): void {\n  const stream = reader._ownerReadableStream;\n\n  assert(stream !== undefined);\n\n  stream._disturbed = true;\n\n  if (stream._state === 'errored') {\n    readIntoRequest._errorSteps(stream._storedError);\n  } else {\n    ReadableByteStreamControllerPullInto(\n      stream._readableStreamController as ReadableByteStreamController,\n      view,\n      min,\n      readIntoRequest\n    );\n  }\n}\n\nexport function ReadableStreamBYOBReaderRelease(reader: ReadableStreamBYOBReader) {\n  ReadableStreamReaderGenericRelease(reader);\n  const e = new TypeError('Reader was released');\n  ReadableStreamBYOBReaderErrorReadIntoRequests(reader, e);\n}\n\nexport function ReadableStreamBYOBReaderErrorReadIntoRequests(reader: ReadableStreamBYOBReader, e: any) {\n  const readIntoRequests = reader._readIntoRequests;\n  reader._readIntoRequests = new SimpleQueue();\n  readIntoRequests.forEach(readIntoRequest => {\n    readIntoRequest._errorSteps(e);\n  });\n}\n\n// Helper functions for the ReadableStreamBYOBReader.\n\nfunction byobReaderBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `ReadableStreamBYOBReader.prototype.${name} can only be used on a ReadableStreamBYOBReader`);\n}\n","import type { QueuingStrategy, QueuingStrategySizeCallback } from '../queuing-strategy';\nimport NumberIsNaN from '../../stub/number-isnan';\n\nexport function ExtractHighWaterMark(strategy: QueuingStrategy, defaultHWM: number): number {\n  const { highWaterMark } = strategy;\n\n  if (highWaterMark === undefined) {\n    return defaultHWM;\n  }\n\n  if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n    throw new RangeError('Invalid highWaterMark');\n  }\n\n  return highWaterMark;\n}\n\nexport function ExtractSizeAlgorithm<T>(strategy: QueuingStrategy<T>): QueuingStrategySizeCallback<T> {\n  const { size } = strategy;\n\n  if (!size) {\n    return () => 1;\n  }\n\n  return size;\n}\n","import type { QueuingStrategy, QueuingStrategySizeCallback } from '../queuing-strategy';\nimport { assertDictionary, assertFunction, convertUnrestrictedDouble } from './basic';\n\nexport function convertQueuingStrategy<T>(init: QueuingStrategy<T> | null | undefined,\n                                          context: string): QueuingStrategy<T> {\n  assertDictionary(init, context);\n  const highWaterMark = init?.highWaterMark;\n  const size = init?.size;\n  return {\n    highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n    size: size === undefined ? undefined : convertQueuingStrategySize(size, `${context} has member 'size' that`)\n  };\n}\n\nfunction convertQueuingStrategySize<T>(fn: QueuingStrategySizeCallback<T>,\n                                       context: string): QueuingStrategySizeCallback<T> {\n  assertFunction(fn, context);\n  return chunk => convertUnrestrictedDouble(fn(chunk));\n}\n","import { assertDictionary, assertFunction } from './basic';\nimport { promiseCall, reflectCall } from '../helpers/webidl';\nimport type {\n  UnderlyingSink,\n  UnderlyingSinkAbortCallback,\n  UnderlyingSinkCloseCallback,\n  UnderlyingSinkStartCallback,\n  UnderlyingSinkWriteCallback,\n  ValidatedUnderlyingSink\n} from '../writable-stream/underlying-sink';\nimport { WritableStreamDefaultController } from '../writable-stream';\n\nexport function convertUnderlyingSink<W>(original: UnderlyingSink<W> | null,\n                                         context: string): ValidatedUnderlyingSink<W> {\n  assertDictionary(original, context);\n  const abort = original?.abort;\n  const close = original?.close;\n  const start = original?.start;\n  const type = original?.type;\n  const write = original?.write;\n  return {\n    abort: abort === undefined ?\n      undefined :\n      convertUnderlyingSinkAbortCallback(abort, original!, `${context} has member 'abort' that`),\n    close: close === undefined ?\n      undefined :\n      convertUnderlyingSinkCloseCallback(close, original!, `${context} has member 'close' that`),\n    start: start === undefined ?\n      undefined :\n      convertUnderlyingSinkStartCallback(start, original!, `${context} has member 'start' that`),\n    write: write === undefined ?\n      undefined :\n      convertUnderlyingSinkWriteCallback(write, original!, `${context} has member 'write' that`),\n    type\n  };\n}\n\nfunction convertUnderlyingSinkAbortCallback(\n  fn: UnderlyingSinkAbortCallback,\n  original: UnderlyingSink,\n  context: string\n): (reason: any) => Promise<void> {\n  assertFunction(fn, context);\n  return (reason: any) => promiseCall(fn, original, [reason]);\n}\n\nfunction convertUnderlyingSinkCloseCallback(\n  fn: UnderlyingSinkCloseCallback,\n  original: UnderlyingSink,\n  context: string\n): () => Promise<void> {\n  assertFunction(fn, context);\n  return () => promiseCall(fn, original, []);\n}\n\nfunction convertUnderlyingSinkStartCallback(\n  fn: UnderlyingSinkStartCallback,\n  original: UnderlyingSink,\n  context: string\n): UnderlyingSinkStartCallback {\n  assertFunction(fn, context);\n  return (controller: WritableStreamDefaultController) => reflectCall(fn, original, [controller]);\n}\n\nfunction convertUnderlyingSinkWriteCallback<W>(\n  fn: UnderlyingSinkWriteCallback<W>,\n  original: UnderlyingSink<W>,\n  context: string\n): (chunk: W, controller: WritableStreamDefaultController) => Promise<void> {\n  assertFunction(fn, context);\n  return (chunk: W, controller: WritableStreamDefaultController) => promiseCall(fn, original, [chunk, controller]);\n}\n","import { IsWritableStream, WritableStream } from '../writable-stream';\n\nexport function assertWritableStream(x: unknown, context: string): asserts x is WritableStream {\n  if (!IsWritableStream(x)) {\n    throw new TypeError(`${context} is not a WritableStream.`);\n  }\n}\n","/**\n * A signal object that allows you to communicate with a request and abort it if required\n * via its associated `AbortController` object.\n *\n * @remarks\n *   This interface is compatible with the `AbortSignal` interface defined in TypeScript's DOM types.\n *   It is redefined here, so it can be polyfilled without a DOM, for example with\n *   {@link https://www.npmjs.com/package/abortcontroller-polyfill | abortcontroller-polyfill} in a Node environment.\n *\n * @public\n */\nexport interface AbortSignal {\n  /**\n   * Whether the request is aborted.\n   */\n  readonly aborted: boolean;\n\n  /**\n   * If aborted, returns the reason for aborting.\n   */\n  readonly reason?: any;\n\n  /**\n   * Add an event listener to be triggered when this signal becomes aborted.\n   */\n  addEventListener(type: 'abort', listener: () => void): void;\n\n  /**\n   * Remove an event listener that was previously added with {@link AbortSignal.addEventListener}.\n   */\n  removeEventListener(type: 'abort', listener: () => void): void;\n}\n\nexport function isAbortSignal(value: unknown): value is AbortSignal {\n  if (typeof value !== 'object' || value === null) {\n    return false;\n  }\n  try {\n    return typeof (value as AbortSignal).aborted === 'boolean';\n  } catch {\n    // AbortSignal.prototype.aborted throws if its brand check fails\n    return false;\n  }\n}\n\n/**\n * A controller object that allows you to abort an `AbortSignal` when desired.\n *\n * @remarks\n *   This interface is compatible with the `AbortController` interface defined in TypeScript's DOM types.\n *   It is redefined here, so it can be polyfilled without a DOM, for example with\n *   {@link https://www.npmjs.com/package/abortcontroller-polyfill | abortcontroller-polyfill} in a Node environment.\n *\n * @internal\n */\nexport interface AbortController {\n  readonly signal: AbortSignal;\n\n  abort(reason?: any): void;\n}\n\ninterface AbortControllerConstructor {\n  new(): AbortController;\n}\n\nconst supportsAbortController = typeof (AbortController as any) === 'function';\n\n/**\n * Construct a new AbortController, if supported by the platform.\n *\n * @internal\n */\nexport function createAbortController(): AbortController | undefined {\n  if (supportsAbortController) {\n    return new (AbortController as AbortControllerConstructor)();\n  }\n  return undefined;\n}\n","import assert from '../stub/assert';\nimport {\n  newPromise,\n  promiseRejectedWith,\n  promiseResolvedWith,\n  setPromiseIsHandledToTrue,\n  uponPromise\n} from './helpers/webidl';\nimport {\n  DequeueValue,\n  EnqueueValueWithSize,\n  PeekQueueValue,\n  type QueuePair,\n  ResetQueue\n} from './abstract-ops/queue-with-sizes';\nimport type { QueuingStrategy, QueuingStrategySizeCallback } from './queuing-strategy';\nimport { SimpleQueue } from './simple-queue';\nimport { setFunctionName, typeIsObject } from './helpers/miscellaneous';\nimport { AbortSteps, ErrorSteps } from './abstract-ops/internal-methods';\nimport { IsNonNegativeNumber } from './abstract-ops/miscellaneous';\nimport { ExtractHighWaterMark, ExtractSizeAlgorithm } from './abstract-ops/queuing-strategy';\nimport { convertQueuingStrategy } from './validators/queuing-strategy';\nimport type {\n  UnderlyingSink,\n  UnderlyingSinkAbortCallback,\n  UnderlyingSinkCloseCallback,\n  UnderlyingSinkStartCallback,\n  UnderlyingSinkWriteCallback,\n  ValidatedUnderlyingSink\n} from './writable-stream/underlying-sink';\nimport { assertObject, assertRequiredArgument } from './validators/basic';\nimport { convertUnderlyingSink } from './validators/underlying-sink';\nimport { assertWritableStream } from './validators/writable-stream';\nimport { type AbortController, type AbortSignal, createAbortController } from './abort-signal';\n\ntype WritableStreamState = 'writable' | 'closed' | 'erroring' | 'errored';\n\ninterface WriteOrCloseRequest {\n  _resolve: (value?: undefined) => void;\n  _reject: (reason: any) => void;\n}\n\ntype WriteRequest = WriteOrCloseRequest;\ntype CloseRequest = WriteOrCloseRequest;\n\ninterface PendingAbortRequest {\n  _promise: Promise<undefined>;\n  _resolve: (value?: undefined) => void;\n  _reject: (reason: any) => void;\n  _reason: any;\n  _wasAlreadyErroring: boolean;\n}\n\n/**\n * A writable stream represents a destination for data, into which you can write.\n *\n * @public\n */\nclass WritableStream<W = any> {\n  /** @internal */\n  _state!: WritableStreamState;\n  /** @internal */\n  _storedError: any;\n  /** @internal */\n  _writer: WritableStreamDefaultWriter<W> | undefined;\n  /** @internal */\n  _writableStreamController!: WritableStreamDefaultController<W>;\n  /** @internal */\n  _writeRequests!: SimpleQueue<WriteRequest>;\n  /** @internal */\n  _inFlightWriteRequest: WriteRequest | undefined;\n  /** @internal */\n  _closeRequest: CloseRequest | undefined;\n  /** @internal */\n  _inFlightCloseRequest: CloseRequest | undefined;\n  /** @internal */\n  _pendingAbortRequest: PendingAbortRequest | undefined;\n  /** @internal */\n  _backpressure!: boolean;\n\n  constructor(underlyingSink?: UnderlyingSink<W>, strategy?: QueuingStrategy<W>);\n  constructor(rawUnderlyingSink: UnderlyingSink<W> | null | undefined = {},\n              rawStrategy: QueuingStrategy<W> | null | undefined = {}) {\n    if (rawUnderlyingSink === undefined) {\n      rawUnderlyingSink = null;\n    } else {\n      assertObject(rawUnderlyingSink, 'First parameter');\n    }\n\n    const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n    const underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n\n    InitializeWritableStream(this);\n\n    const type = underlyingSink.type;\n    if (type !== undefined) {\n      throw new RangeError('Invalid type is specified');\n    }\n\n    const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n    const highWaterMark = ExtractHighWaterMark(strategy, 1);\n\n    SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n  }\n\n  /**\n   * Returns whether or not the writable stream is locked to a writer.\n   */\n  get locked(): boolean {\n    if (!IsWritableStream(this)) {\n      throw streamBrandCheckException('locked');\n    }\n\n    return IsWritableStreamLocked(this);\n  }\n\n  /**\n   * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n   * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n   * mechanism of the underlying sink.\n   *\n   * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n   * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n   * the stream) if the stream is currently locked.\n   */\n  abort(reason: any = undefined): Promise<void> {\n    if (!IsWritableStream(this)) {\n      return promiseRejectedWith(streamBrandCheckException('abort'));\n    }\n\n    if (IsWritableStreamLocked(this)) {\n      return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n    }\n\n    return WritableStreamAbort(this, reason);\n  }\n\n  /**\n   * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n   * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n   *\n   * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n   * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n   * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n   */\n  close() {\n    if (!IsWritableStream(this)) {\n      return promiseRejectedWith(streamBrandCheckException('close'));\n    }\n\n    if (IsWritableStreamLocked(this)) {\n      return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n    }\n\n    if (WritableStreamCloseQueuedOrInFlight(this)) {\n      return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n    }\n\n    return WritableStreamClose(this);\n  }\n\n  /**\n   * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n   * is locked, no other writer can be acquired until this one is released.\n   *\n   * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n   * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n   * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n   */\n  getWriter(): WritableStreamDefaultWriter<W> {\n    if (!IsWritableStream(this)) {\n      throw streamBrandCheckException('getWriter');\n    }\n\n    return AcquireWritableStreamDefaultWriter(this);\n  }\n}\n\nObject.defineProperties(WritableStream.prototype, {\n  abort: { enumerable: true },\n  close: { enumerable: true },\n  getWriter: { enumerable: true },\n  locked: { enumerable: true }\n});\nsetFunctionName(WritableStream.prototype.abort, 'abort');\nsetFunctionName(WritableStream.prototype.close, 'close');\nsetFunctionName(WritableStream.prototype.getWriter, 'getWriter');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(WritableStream.prototype, Symbol.toStringTag, {\n    value: 'WritableStream',\n    configurable: true\n  });\n}\n\nexport {\n  AcquireWritableStreamDefaultWriter,\n  CreateWritableStream,\n  IsWritableStream,\n  IsWritableStreamLocked,\n  WritableStream,\n  WritableStreamAbort,\n  WritableStreamDefaultControllerErrorIfNeeded,\n  WritableStreamDefaultWriterCloseWithErrorPropagation,\n  WritableStreamDefaultWriterRelease,\n  WritableStreamDefaultWriterWrite,\n  WritableStreamCloseQueuedOrInFlight\n};\n\nexport type {\n  UnderlyingSink,\n  UnderlyingSinkStartCallback,\n  UnderlyingSinkWriteCallback,\n  UnderlyingSinkCloseCallback,\n  UnderlyingSinkAbortCallback\n};\n\n// Abstract operations for the WritableStream.\n\nfunction AcquireWritableStreamDefaultWriter<W>(stream: WritableStream<W>): WritableStreamDefaultWriter<W> {\n  return new WritableStreamDefaultWriter(stream);\n}\n\n// Throws if and only if startAlgorithm throws.\nfunction CreateWritableStream<W>(startAlgorithm: () => void | PromiseLike<void>,\n                                 writeAlgorithm: (chunk: W) => Promise<void>,\n                                 closeAlgorithm: () => Promise<void>,\n                                 abortAlgorithm: (reason: any) => Promise<void>,\n                                 highWaterMark = 1,\n                                 sizeAlgorithm: QueuingStrategySizeCallback<W> = () => 1) {\n  assert(IsNonNegativeNumber(highWaterMark));\n\n  const stream: WritableStream<W> = Object.create(WritableStream.prototype);\n  InitializeWritableStream(stream);\n\n  const controller: WritableStreamDefaultController<W> = Object.create(WritableStreamDefaultController.prototype);\n\n  SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm,\n                                       abortAlgorithm, highWaterMark, sizeAlgorithm);\n  return stream;\n}\n\nfunction InitializeWritableStream<W>(stream: WritableStream<W>) {\n  stream._state = 'writable';\n\n  // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n  // 'erroring' or 'errored'. May be set to an undefined value.\n  stream._storedError = undefined;\n\n  stream._writer = undefined;\n\n  // Initialize to undefined first because the constructor of the controller checks this\n  // variable to validate the caller.\n  stream._writableStreamController = undefined!;\n\n  // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n  // producer without waiting for the queued writes to finish.\n  stream._writeRequests = new SimpleQueue();\n\n  // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n  // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n  stream._inFlightWriteRequest = undefined;\n\n  // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n  // has been detached.\n  stream._closeRequest = undefined;\n\n  // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n  // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n  stream._inFlightCloseRequest = undefined;\n\n  // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n  stream._pendingAbortRequest = undefined;\n\n  // The backpressure signal set by the controller.\n  stream._backpressure = false;\n}\n\nfunction IsWritableStream(x: unknown): x is WritableStream {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n    return false;\n  }\n\n  return x instanceof WritableStream;\n}\n\nfunction IsWritableStreamLocked(stream: WritableStream): boolean {\n  assert(IsWritableStream(stream));\n\n  if (stream._writer === undefined) {\n    return false;\n  }\n\n  return true;\n}\n\nfunction WritableStreamAbort(stream: WritableStream, reason: any): Promise<undefined> {\n  if (stream._state === 'closed' || stream._state === 'errored') {\n    return promiseResolvedWith(undefined);\n  }\n  stream._writableStreamController._abortReason = reason;\n  stream._writableStreamController._abortController?.abort(reason);\n\n  // TypeScript narrows the type of `stream._state` down to 'writable' | 'erroring',\n  // but it doesn't know that signaling abort runs author code that might have changed the state.\n  // Widen the type again by casting to WritableStreamState.\n  const state = stream._state as WritableStreamState;\n\n  if (state === 'closed' || state === 'errored') {\n    return promiseResolvedWith(undefined);\n  }\n  if (stream._pendingAbortRequest !== undefined) {\n    return stream._pendingAbortRequest._promise;\n  }\n\n  assert(state === 'writable' || state === 'erroring');\n\n  let wasAlreadyErroring = false;\n  if (state === 'erroring') {\n    wasAlreadyErroring = true;\n    // reason will not be used, so don't keep a reference to it.\n    reason = undefined;\n  }\n\n  const promise = newPromise<undefined>((resolve, reject) => {\n    stream._pendingAbortRequest = {\n      _promise: undefined!,\n      _resolve: resolve,\n      _reject: reject,\n      _reason: reason,\n      _wasAlreadyErroring: wasAlreadyErroring\n    };\n  });\n  stream._pendingAbortRequest!._promise = promise;\n\n  if (!wasAlreadyErroring) {\n    WritableStreamStartErroring(stream, reason);\n  }\n\n  return promise;\n}\n\nfunction WritableStreamClose(stream: WritableStream<any>): Promise<undefined> {\n  const state = stream._state;\n  if (state === 'closed' || state === 'errored') {\n    return promiseRejectedWith(new TypeError(\n      `The stream (in ${state} state) is not in the writable state and cannot be closed`));\n  }\n\n  assert(state === 'writable' || state === 'erroring');\n  assert(!WritableStreamCloseQueuedOrInFlight(stream));\n\n  const promise = newPromise<undefined>((resolve, reject) => {\n    const closeRequest: CloseRequest = {\n      _resolve: resolve,\n      _reject: reject\n    };\n\n    stream._closeRequest = closeRequest;\n  });\n\n  const writer = stream._writer;\n  if (writer !== undefined && stream._backpressure && state === 'writable') {\n    defaultWriterReadyPromiseResolve(writer);\n  }\n\n  WritableStreamDefaultControllerClose(stream._writableStreamController);\n\n  return promise;\n}\n\n// WritableStream API exposed for controllers.\n\nfunction WritableStreamAddWriteRequest(stream: WritableStream): Promise<undefined> {\n  assert(IsWritableStreamLocked(stream));\n  assert(stream._state === 'writable');\n\n  const promise = newPromise<undefined>((resolve, reject) => {\n    const writeRequest: WriteRequest = {\n      _resolve: resolve,\n      _reject: reject\n    };\n\n    stream._writeRequests.push(writeRequest);\n  });\n\n  return promise;\n}\n\nfunction WritableStreamDealWithRejection(stream: WritableStream, error: any) {\n  const state = stream._state;\n\n  if (state === 'writable') {\n    WritableStreamStartErroring(stream, error);\n    return;\n  }\n\n  assert(state === 'erroring');\n  WritableStreamFinishErroring(stream);\n}\n\nfunction WritableStreamStartErroring(stream: WritableStream, reason: any) {\n  assert(stream._storedError === undefined);\n  assert(stream._state === 'writable');\n\n  const controller = stream._writableStreamController;\n  assert(controller !== undefined);\n\n  stream._state = 'erroring';\n  stream._storedError = reason;\n  const writer = stream._writer;\n  if (writer !== undefined) {\n    WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n  }\n\n  if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n    WritableStreamFinishErroring(stream);\n  }\n}\n\nfunction WritableStreamFinishErroring(stream: WritableStream) {\n  assert(stream._state === 'erroring');\n  assert(!WritableStreamHasOperationMarkedInFlight(stream));\n  stream._state = 'errored';\n  stream._writableStreamController[ErrorSteps]();\n\n  const storedError = stream._storedError;\n  stream._writeRequests.forEach(writeRequest => {\n    writeRequest._reject(storedError);\n  });\n  stream._writeRequests = new SimpleQueue();\n\n  if (stream._pendingAbortRequest === undefined) {\n    WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n    return;\n  }\n\n  const abortRequest = stream._pendingAbortRequest;\n  stream._pendingAbortRequest = undefined;\n\n  if (abortRequest._wasAlreadyErroring) {\n    abortRequest._reject(storedError);\n    WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n    return;\n  }\n\n  const promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n  uponPromise(\n    promise,\n    () => {\n      abortRequest._resolve();\n      WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n      return null;\n    },\n    (reason: any) => {\n      abortRequest._reject(reason);\n      WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n      return null;\n    });\n}\n\nfunction WritableStreamFinishInFlightWrite(stream: WritableStream) {\n  assert(stream._inFlightWriteRequest !== undefined);\n  stream._inFlightWriteRequest!._resolve(undefined);\n  stream._inFlightWriteRequest = undefined;\n}\n\nfunction WritableStreamFinishInFlightWriteWithError(stream: WritableStream, error: any) {\n  assert(stream._inFlightWriteRequest !== undefined);\n  stream._inFlightWriteRequest!._reject(error);\n  stream._inFlightWriteRequest = undefined;\n\n  assert(stream._state === 'writable' || stream._state === 'erroring');\n\n  WritableStreamDealWithRejection(stream, error);\n}\n\nfunction WritableStreamFinishInFlightClose(stream: WritableStream) {\n  assert(stream._inFlightCloseRequest !== undefined);\n  stream._inFlightCloseRequest!._resolve(undefined);\n  stream._inFlightCloseRequest = undefined;\n\n  const state = stream._state;\n\n  assert(state === 'writable' || state === 'erroring');\n\n  if (state === 'erroring') {\n    // The error was too late to do anything, so it is ignored.\n    stream._storedError = undefined;\n    if (stream._pendingAbortRequest !== undefined) {\n      stream._pendingAbortRequest._resolve();\n      stream._pendingAbortRequest = undefined;\n    }\n  }\n\n  stream._state = 'closed';\n\n  const writer = stream._writer;\n  if (writer !== undefined) {\n    defaultWriterClosedPromiseResolve(writer);\n  }\n\n  assert(stream._pendingAbortRequest === undefined);\n  assert(stream._storedError === undefined);\n}\n\nfunction WritableStreamFinishInFlightCloseWithError(stream: WritableStream, error: any) {\n  assert(stream._inFlightCloseRequest !== undefined);\n  stream._inFlightCloseRequest!._reject(error);\n  stream._inFlightCloseRequest = undefined;\n\n  assert(stream._state === 'writable' || stream._state === 'erroring');\n\n  // Never execute sink abort() after sink close().\n  if (stream._pendingAbortRequest !== undefined) {\n    stream._pendingAbortRequest._reject(error);\n    stream._pendingAbortRequest = undefined;\n  }\n  WritableStreamDealWithRejection(stream, error);\n}\n\n// TODO(ricea): Fix alphabetical order.\nfunction WritableStreamCloseQueuedOrInFlight(stream: WritableStream): boolean {\n  if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n    return false;\n  }\n\n  return true;\n}\n\nfunction WritableStreamHasOperationMarkedInFlight(stream: WritableStream): boolean {\n  if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n    return false;\n  }\n\n  return true;\n}\n\nfunction WritableStreamMarkCloseRequestInFlight(stream: WritableStream) {\n  assert(stream._inFlightCloseRequest === undefined);\n  assert(stream._closeRequest !== undefined);\n  stream._inFlightCloseRequest = stream._closeRequest;\n  stream._closeRequest = undefined;\n}\n\nfunction WritableStreamMarkFirstWriteRequestInFlight(stream: WritableStream) {\n  assert(stream._inFlightWriteRequest === undefined);\n  assert(stream._writeRequests.length !== 0);\n  stream._inFlightWriteRequest = stream._writeRequests.shift();\n}\n\nfunction WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream: WritableStream) {\n  assert(stream._state === 'errored');\n  if (stream._closeRequest !== undefined) {\n    assert(stream._inFlightCloseRequest === undefined);\n\n    stream._closeRequest._reject(stream._storedError);\n    stream._closeRequest = undefined;\n  }\n  const writer = stream._writer;\n  if (writer !== undefined) {\n    defaultWriterClosedPromiseReject(writer, stream._storedError);\n  }\n}\n\nfunction WritableStreamUpdateBackpressure(stream: WritableStream, backpressure: boolean) {\n  assert(stream._state === 'writable');\n  assert(!WritableStreamCloseQueuedOrInFlight(stream));\n\n  const writer = stream._writer;\n  if (writer !== undefined && backpressure !== stream._backpressure) {\n    if (backpressure) {\n      defaultWriterReadyPromiseReset(writer);\n    } else {\n      assert(!backpressure);\n\n      defaultWriterReadyPromiseResolve(writer);\n    }\n  }\n\n  stream._backpressure = backpressure;\n}\n\n/**\n * A default writer vended by a {@link WritableStream}.\n *\n * @public\n */\nexport class WritableStreamDefaultWriter<W = any> {\n  /** @internal */\n  _ownerWritableStream: WritableStream<W>;\n  /** @internal */\n  _closedPromise!: Promise<undefined>;\n  /** @internal */\n  _closedPromise_resolve?: (value?: undefined) => void;\n  /** @internal */\n  _closedPromise_reject?: (reason: any) => void;\n  /** @internal */\n  _closedPromiseState!: 'pending' | 'resolved' | 'rejected';\n  /** @internal */\n  _readyPromise!: Promise<undefined>;\n  /** @internal */\n  _readyPromise_resolve?: (value?: undefined) => void;\n  /** @internal */\n  _readyPromise_reject?: (reason: any) => void;\n  /** @internal */\n  _readyPromiseState!: 'pending' | 'fulfilled' | 'rejected';\n\n  constructor(stream: WritableStream<W>) {\n    assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n    assertWritableStream(stream, 'First parameter');\n\n    if (IsWritableStreamLocked(stream)) {\n      throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n    }\n\n    this._ownerWritableStream = stream;\n    stream._writer = this;\n\n    const state = stream._state;\n\n    if (state === 'writable') {\n      if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n        defaultWriterReadyPromiseInitialize(this);\n      } else {\n        defaultWriterReadyPromiseInitializeAsResolved(this);\n      }\n\n      defaultWriterClosedPromiseInitialize(this);\n    } else if (state === 'erroring') {\n      defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n      defaultWriterClosedPromiseInitialize(this);\n    } else if (state === 'closed') {\n      defaultWriterReadyPromiseInitializeAsResolved(this);\n      defaultWriterClosedPromiseInitializeAsResolved(this);\n    } else {\n      assert(state === 'errored');\n\n      const storedError = stream._storedError;\n      defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n      defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n    }\n  }\n\n  /**\n   * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n   * the writers lock is released before the stream finishes closing.\n   */\n  get closed(): Promise<undefined> {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n    }\n\n    return this._closedPromise;\n  }\n\n  /**\n   * Returns the desired size to fill the streams internal queue. It can be negative, if the queue is over-full.\n   * A producer can use this information to determine the right amount of data to write.\n   *\n   * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n   * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n   * the writers lock is released.\n   */\n  get desiredSize(): number | null {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      throw defaultWriterBrandCheckException('desiredSize');\n    }\n\n    if (this._ownerWritableStream === undefined) {\n      throw defaultWriterLockException('desiredSize');\n    }\n\n    return WritableStreamDefaultWriterGetDesiredSize(this);\n  }\n\n  /**\n   * Returns a promise that will be fulfilled when the desired size to fill the streams internal queue transitions\n   * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n   * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n   *\n   * If the stream becomes errored or aborted, or the writers lock is released, the returned promise will become\n   * rejected.\n   */\n  get ready(): Promise<undefined> {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n    }\n\n    return this._readyPromise;\n  }\n\n  /**\n   * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n   */\n  abort(reason: any = undefined): Promise<void> {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n    }\n\n    if (this._ownerWritableStream === undefined) {\n      return promiseRejectedWith(defaultWriterLockException('abort'));\n    }\n\n    return WritableStreamDefaultWriterAbort(this, reason);\n  }\n\n  /**\n   * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n   */\n  close(): Promise<void> {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n    }\n\n    const stream = this._ownerWritableStream;\n\n    if (stream === undefined) {\n      return promiseRejectedWith(defaultWriterLockException('close'));\n    }\n\n    if (WritableStreamCloseQueuedOrInFlight(stream)) {\n      return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n    }\n\n    return WritableStreamDefaultWriterClose(this);\n  }\n\n  /**\n   * Releases the writers lock on the corresponding stream. After the lock is released, the writer is no longer active.\n   * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n   * now on; otherwise, the writer will appear closed.\n   *\n   * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n   * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n   * Its not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n   * other producers from writing in an interleaved manner.\n   */\n  releaseLock(): void {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      throw defaultWriterBrandCheckException('releaseLock');\n    }\n\n    const stream = this._ownerWritableStream;\n\n    if (stream === undefined) {\n      return;\n    }\n\n    assert(stream._writer !== undefined);\n\n    WritableStreamDefaultWriterRelease(this);\n  }\n\n  /**\n   * Writes the given chunk to the writable stream, by waiting until any previous writes have finished successfully,\n   * and then sending the chunk to the underlying sink's {@link UnderlyingSink.write | write()} method. It will return\n   * a promise that fulfills with undefined upon a successful write, or rejects if the write fails or stream becomes\n   * errored before the writing process is initiated.\n   *\n   * Note that what \"success\" means is up to the underlying sink; it might indicate simply that the chunk has been\n   * accepted, and not necessarily that it is safely saved to its ultimate destination.\n   */\n  write(chunk: W): Promise<void>;\n  write(chunk: W = undefined!): Promise<void> {\n    if (!IsWritableStreamDefaultWriter(this)) {\n      return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n    }\n\n    if (this._ownerWritableStream === undefined) {\n      return promiseRejectedWith(defaultWriterLockException('write to'));\n    }\n\n    return WritableStreamDefaultWriterWrite(this, chunk);\n  }\n}\n\nObject.defineProperties(WritableStreamDefaultWriter.prototype, {\n  abort: { enumerable: true },\n  close: { enumerable: true },\n  releaseLock: { enumerable: true },\n  write: { enumerable: true },\n  closed: { enumerable: true },\n  desiredSize: { enumerable: true },\n  ready: { enumerable: true }\n});\nsetFunctionName(WritableStreamDefaultWriter.prototype.abort, 'abort');\nsetFunctionName(WritableStreamDefaultWriter.prototype.close, 'close');\nsetFunctionName(WritableStreamDefaultWriter.prototype.releaseLock, 'releaseLock');\nsetFunctionName(WritableStreamDefaultWriter.prototype.write, 'write');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(WritableStreamDefaultWriter.prototype, Symbol.toStringTag, {\n    value: 'WritableStreamDefaultWriter',\n    configurable: true\n  });\n}\n\n// Abstract operations for the WritableStreamDefaultWriter.\n\nfunction IsWritableStreamDefaultWriter<W = any>(x: any): x is WritableStreamDefaultWriter<W> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n    return false;\n  }\n\n  return x instanceof WritableStreamDefaultWriter;\n}\n\n// A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\n\nfunction WritableStreamDefaultWriterAbort(writer: WritableStreamDefaultWriter, reason: any) {\n  const stream = writer._ownerWritableStream;\n\n  assert(stream !== undefined);\n\n  return WritableStreamAbort(stream, reason);\n}\n\nfunction WritableStreamDefaultWriterClose(writer: WritableStreamDefaultWriter): Promise<undefined> {\n  const stream = writer._ownerWritableStream;\n\n  assert(stream !== undefined);\n\n  return WritableStreamClose(stream);\n}\n\nfunction WritableStreamDefaultWriterCloseWithErrorPropagation(writer: WritableStreamDefaultWriter): Promise<undefined> {\n  const stream = writer._ownerWritableStream;\n\n  assert(stream !== undefined);\n\n  const state = stream._state;\n  if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n    return promiseResolvedWith(undefined);\n  }\n\n  if (state === 'errored') {\n    return promiseRejectedWith(stream._storedError);\n  }\n\n  assert(state === 'writable' || state === 'erroring');\n\n  return WritableStreamDefaultWriterClose(writer);\n}\n\nfunction WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer: WritableStreamDefaultWriter, error: any) {\n  if (writer._closedPromiseState === 'pending') {\n    defaultWriterClosedPromiseReject(writer, error);\n  } else {\n    defaultWriterClosedPromiseResetToRejected(writer, error);\n  }\n}\n\nfunction WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer: WritableStreamDefaultWriter, error: any) {\n  if (writer._readyPromiseState === 'pending') {\n    defaultWriterReadyPromiseReject(writer, error);\n  } else {\n    defaultWriterReadyPromiseResetToRejected(writer, error);\n  }\n}\n\nfunction WritableStreamDefaultWriterGetDesiredSize(writer: WritableStreamDefaultWriter): number | null {\n  const stream = writer._ownerWritableStream;\n  const state = stream._state;\n\n  if (state === 'errored' || state === 'erroring') {\n    return null;\n  }\n\n  if (state === 'closed') {\n    return 0;\n  }\n\n  return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n}\n\nfunction WritableStreamDefaultWriterRelease(writer: WritableStreamDefaultWriter) {\n  const stream = writer._ownerWritableStream;\n  assert(stream !== undefined);\n  assert(stream._writer === writer);\n\n  const releasedError = new TypeError(\n    `Writer was released and can no longer be used to monitor the stream's closedness`);\n\n  WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n\n  // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n  // rejected until afterwards. This means that simply testing state will not work.\n  WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n\n  stream._writer = undefined;\n  writer._ownerWritableStream = undefined!;\n}\n\nfunction WritableStreamDefaultWriterWrite<W>(writer: WritableStreamDefaultWriter<W>, chunk: W): Promise<undefined> {\n  const stream = writer._ownerWritableStream;\n\n  assert(stream !== undefined);\n\n  const controller = stream._writableStreamController;\n\n  const chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n\n  if (stream !== writer._ownerWritableStream) {\n    return promiseRejectedWith(defaultWriterLockException('write to'));\n  }\n\n  const state = stream._state;\n  if (state === 'errored') {\n    return promiseRejectedWith(stream._storedError);\n  }\n  if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n    return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n  }\n  if (state === 'erroring') {\n    return promiseRejectedWith(stream._storedError);\n  }\n\n  assert(state === 'writable');\n\n  const promise = WritableStreamAddWriteRequest(stream);\n\n  WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n\n  return promise;\n}\n\nconst closeSentinel: unique symbol = {} as any;\n\ntype QueueRecord<W> = W | typeof closeSentinel;\n\n/**\n * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n *\n * @public\n */\nexport class WritableStreamDefaultController<W = any> {\n  /** @internal */\n  _controlledWritableStream!: WritableStream<W>;\n  /** @internal */\n  _queue!: SimpleQueue<QueuePair<QueueRecord<W>>>;\n  /** @internal */\n  _queueTotalSize!: number;\n  /** @internal */\n  _abortReason: any;\n  /** @internal */\n  _abortController: AbortController | undefined;\n  /** @internal */\n  _started!: boolean;\n  /** @internal */\n  _strategySizeAlgorithm!: QueuingStrategySizeCallback<W>;\n  /** @internal */\n  _strategyHWM!: number;\n  /** @internal */\n  _writeAlgorithm!: (chunk: W) => Promise<void>;\n  /** @internal */\n  _closeAlgorithm!: () => Promise<void>;\n  /** @internal */\n  _abortAlgorithm!: (reason: any) => Promise<void>;\n\n  private constructor() {\n    throw new TypeError('Illegal constructor');\n  }\n\n  /**\n   * The reason which was passed to `WritableStream.abort(reason)` when the stream was aborted.\n   *\n   * @deprecated\n   *  This property has been removed from the specification, see https://github.com/whatwg/streams/pull/1177.\n   *  Use {@link WritableStreamDefaultController.signal}'s `reason` instead.\n   */\n  get abortReason(): any {\n    if (!IsWritableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('abortReason');\n    }\n    return this._abortReason;\n  }\n\n  /**\n   * An `AbortSignal` that can be used to abort the pending write or close operation when the stream is aborted.\n   */\n  get signal(): AbortSignal {\n    if (!IsWritableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('signal');\n    }\n    if (this._abortController === undefined) {\n      // Older browsers or older Node versions may not support `AbortController` or `AbortSignal`.\n      // We don't want to bundle and ship an `AbortController` polyfill together with our polyfill,\n      // so instead we only implement support for `signal` if we find a global `AbortController` constructor.\n      throw new TypeError('WritableStreamDefaultController.prototype.signal is not supported');\n    }\n    return this._abortController.signal;\n  }\n\n  /**\n   * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n   *\n   * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n   * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n   * normal lifecycle of interactions with the underlying sink.\n   */\n  error(e: any = undefined): void {\n    if (!IsWritableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('error');\n    }\n    const state = this._controlledWritableStream._state;\n    if (state !== 'writable') {\n      // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n      // just treat it as a no-op.\n      return;\n    }\n\n    WritableStreamDefaultControllerError(this, e);\n  }\n\n  /** @internal */\n  [AbortSteps](reason: any): Promise<void> {\n    const result = this._abortAlgorithm(reason);\n    WritableStreamDefaultControllerClearAlgorithms(this);\n    return result;\n  }\n\n  /** @internal */\n  [ErrorSteps]() {\n    ResetQueue(this);\n  }\n}\n\nObject.defineProperties(WritableStreamDefaultController.prototype, {\n  abortReason: { enumerable: true },\n  signal: { enumerable: true },\n  error: { enumerable: true }\n});\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(WritableStreamDefaultController.prototype, Symbol.toStringTag, {\n    value: 'WritableStreamDefaultController',\n    configurable: true\n  });\n}\n\n// Abstract operations implementing interface required by the WritableStream.\n\nfunction IsWritableStreamDefaultController(x: any): x is WritableStreamDefaultController<any> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n    return false;\n  }\n\n  return x instanceof WritableStreamDefaultController;\n}\n\nfunction SetUpWritableStreamDefaultController<W>(stream: WritableStream<W>,\n                                                 controller: WritableStreamDefaultController<W>,\n                                                 startAlgorithm: () => void | PromiseLike<void>,\n                                                 writeAlgorithm: (chunk: W) => Promise<void>,\n                                                 closeAlgorithm: () => Promise<void>,\n                                                 abortAlgorithm: (reason: any) => Promise<void>,\n                                                 highWaterMark: number,\n                                                 sizeAlgorithm: QueuingStrategySizeCallback<W>) {\n  assert(IsWritableStream(stream));\n  assert(stream._writableStreamController === undefined);\n\n  controller._controlledWritableStream = stream;\n  stream._writableStreamController = controller;\n\n  // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n  controller._queue = undefined!;\n  controller._queueTotalSize = undefined!;\n  ResetQueue(controller);\n\n  controller._abortReason = undefined;\n  controller._abortController = createAbortController();\n  controller._started = false;\n\n  controller._strategySizeAlgorithm = sizeAlgorithm;\n  controller._strategyHWM = highWaterMark;\n\n  controller._writeAlgorithm = writeAlgorithm;\n  controller._closeAlgorithm = closeAlgorithm;\n  controller._abortAlgorithm = abortAlgorithm;\n\n  const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n  WritableStreamUpdateBackpressure(stream, backpressure);\n\n  const startResult = startAlgorithm();\n  const startPromise = promiseResolvedWith(startResult);\n  uponPromise(\n    startPromise,\n    () => {\n      assert(stream._state === 'writable' || stream._state === 'erroring');\n      controller._started = true;\n      WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n      return null;\n    },\n    r => {\n      assert(stream._state === 'writable' || stream._state === 'erroring');\n      controller._started = true;\n      WritableStreamDealWithRejection(stream, r);\n      return null;\n    }\n  );\n}\n\nfunction SetUpWritableStreamDefaultControllerFromUnderlyingSink<W>(stream: WritableStream<W>,\n                                                                   underlyingSink: ValidatedUnderlyingSink<W>,\n                                                                   highWaterMark: number,\n                                                                   sizeAlgorithm: QueuingStrategySizeCallback<W>) {\n  const controller = Object.create(WritableStreamDefaultController.prototype);\n\n  let startAlgorithm: () => void | PromiseLike<void>;\n  let writeAlgorithm: (chunk: W) => Promise<void>;\n  let closeAlgorithm: () => Promise<void>;\n  let abortAlgorithm: (reason: any) => Promise<void>;\n\n  if (underlyingSink.start !== undefined) {\n    startAlgorithm = () => underlyingSink.start!(controller);\n  } else {\n    startAlgorithm = () => undefined;\n  }\n  if (underlyingSink.write !== undefined) {\n    writeAlgorithm = chunk => underlyingSink.write!(chunk, controller);\n  } else {\n    writeAlgorithm = () => promiseResolvedWith(undefined);\n  }\n  if (underlyingSink.close !== undefined) {\n    closeAlgorithm = () => underlyingSink.close!();\n  } else {\n    closeAlgorithm = () => promiseResolvedWith(undefined);\n  }\n  if (underlyingSink.abort !== undefined) {\n    abortAlgorithm = reason => underlyingSink.abort!(reason);\n  } else {\n    abortAlgorithm = () => promiseResolvedWith(undefined);\n  }\n\n  SetUpWritableStreamDefaultController(\n    stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm\n  );\n}\n\n// ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\nfunction WritableStreamDefaultControllerClearAlgorithms(controller: WritableStreamDefaultController<any>) {\n  controller._writeAlgorithm = undefined!;\n  controller._closeAlgorithm = undefined!;\n  controller._abortAlgorithm = undefined!;\n  controller._strategySizeAlgorithm = undefined!;\n}\n\nfunction WritableStreamDefaultControllerClose<W>(controller: WritableStreamDefaultController<W>) {\n  EnqueueValueWithSize(controller, closeSentinel, 0);\n  WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n}\n\nfunction WritableStreamDefaultControllerGetChunkSize<W>(controller: WritableStreamDefaultController<W>,\n                                                        chunk: W): number {\n  try {\n    return controller._strategySizeAlgorithm(chunk);\n  } catch (chunkSizeE) {\n    WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n    return 1;\n  }\n}\n\nfunction WritableStreamDefaultControllerGetDesiredSize(controller: WritableStreamDefaultController<any>): number {\n  return controller._strategyHWM - controller._queueTotalSize;\n}\n\nfunction WritableStreamDefaultControllerWrite<W>(controller: WritableStreamDefaultController<W>,\n                                                 chunk: W,\n                                                 chunkSize: number) {\n  try {\n    EnqueueValueWithSize(controller, chunk, chunkSize);\n  } catch (enqueueE) {\n    WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n    return;\n  }\n\n  const stream = controller._controlledWritableStream;\n  if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n    const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n    WritableStreamUpdateBackpressure(stream, backpressure);\n  }\n\n  WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n}\n\n// Abstract operations for the WritableStreamDefaultController.\n\nfunction WritableStreamDefaultControllerAdvanceQueueIfNeeded<W>(controller: WritableStreamDefaultController<W>) {\n  const stream = controller._controlledWritableStream;\n\n  if (!controller._started) {\n    return;\n  }\n\n  if (stream._inFlightWriteRequest !== undefined) {\n    return;\n  }\n\n  const state = stream._state;\n  assert(state !== 'closed' && state !== 'errored');\n  if (state === 'erroring') {\n    WritableStreamFinishErroring(stream);\n    return;\n  }\n\n  if (controller._queue.length === 0) {\n    return;\n  }\n\n  const value = PeekQueueValue(controller);\n  if (value === closeSentinel) {\n    WritableStreamDefaultControllerProcessClose(controller);\n  } else {\n    WritableStreamDefaultControllerProcessWrite(controller, value);\n  }\n}\n\nfunction WritableStreamDefaultControllerErrorIfNeeded(controller: WritableStreamDefaultController<any>, error: any) {\n  if (controller._controlledWritableStream._state === 'writable') {\n    WritableStreamDefaultControllerError(controller, error);\n  }\n}\n\nfunction WritableStreamDefaultControllerProcessClose(controller: WritableStreamDefaultController<any>) {\n  const stream = controller._controlledWritableStream;\n\n  WritableStreamMarkCloseRequestInFlight(stream);\n\n  DequeueValue(controller);\n  assert(controller._queue.length === 0);\n\n  const sinkClosePromise = controller._closeAlgorithm();\n  WritableStreamDefaultControllerClearAlgorithms(controller);\n  uponPromise(\n    sinkClosePromise,\n    () => {\n      WritableStreamFinishInFlightClose(stream);\n      return null;\n    },\n    reason => {\n      WritableStreamFinishInFlightCloseWithError(stream, reason);\n      return null;\n    }\n  );\n}\n\nfunction WritableStreamDefaultControllerProcessWrite<W>(controller: WritableStreamDefaultController<W>, chunk: W) {\n  const stream = controller._controlledWritableStream;\n\n  WritableStreamMarkFirstWriteRequestInFlight(stream);\n\n  const sinkWritePromise = controller._writeAlgorithm(chunk);\n  uponPromise(\n    sinkWritePromise,\n    () => {\n      WritableStreamFinishInFlightWrite(stream);\n\n      const state = stream._state;\n      assert(state === 'writable' || state === 'erroring');\n\n      DequeueValue(controller);\n\n      if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n        const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n      }\n\n      WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n      return null;\n    },\n    reason => {\n      if (stream._state === 'writable') {\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n      }\n      WritableStreamFinishInFlightWriteWithError(stream, reason);\n      return null;\n    }\n  );\n}\n\nfunction WritableStreamDefaultControllerGetBackpressure(controller: WritableStreamDefaultController<any>): boolean {\n  const desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n  return desiredSize <= 0;\n}\n\n// A client of WritableStreamDefaultController may use these functions directly to bypass state check.\n\nfunction WritableStreamDefaultControllerError(controller: WritableStreamDefaultController<any>, error: any) {\n  const stream = controller._controlledWritableStream;\n\n  assert(stream._state === 'writable');\n\n  WritableStreamDefaultControllerClearAlgorithms(controller);\n  WritableStreamStartErroring(stream, error);\n}\n\n// Helper functions for the WritableStream.\n\nfunction streamBrandCheckException(name: string): TypeError {\n  return new TypeError(`WritableStream.prototype.${name} can only be used on a WritableStream`);\n}\n\n// Helper functions for the WritableStreamDefaultController.\n\nfunction defaultControllerBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `WritableStreamDefaultController.prototype.${name} can only be used on a WritableStreamDefaultController`);\n}\n\n\n// Helper functions for the WritableStreamDefaultWriter.\n\nfunction defaultWriterBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `WritableStreamDefaultWriter.prototype.${name} can only be used on a WritableStreamDefaultWriter`);\n}\n\nfunction defaultWriterLockException(name: string): TypeError {\n  return new TypeError('Cannot ' + name + ' a stream using a released writer');\n}\n\nfunction defaultWriterClosedPromiseInitialize(writer: WritableStreamDefaultWriter) {\n  writer._closedPromise = newPromise((resolve, reject) => {\n    writer._closedPromise_resolve = resolve;\n    writer._closedPromise_reject = reject;\n    writer._closedPromiseState = 'pending';\n  });\n}\n\nfunction defaultWriterClosedPromiseInitializeAsRejected(writer: WritableStreamDefaultWriter, reason: any) {\n  defaultWriterClosedPromiseInitialize(writer);\n  defaultWriterClosedPromiseReject(writer, reason);\n}\n\nfunction defaultWriterClosedPromiseInitializeAsResolved(writer: WritableStreamDefaultWriter) {\n  defaultWriterClosedPromiseInitialize(writer);\n  defaultWriterClosedPromiseResolve(writer);\n}\n\nfunction defaultWriterClosedPromiseReject(writer: WritableStreamDefaultWriter, reason: any) {\n  if (writer._closedPromise_reject === undefined) {\n    return;\n  }\n  assert(writer._closedPromiseState === 'pending');\n\n  setPromiseIsHandledToTrue(writer._closedPromise);\n  writer._closedPromise_reject(reason);\n  writer._closedPromise_resolve = undefined;\n  writer._closedPromise_reject = undefined;\n  writer._closedPromiseState = 'rejected';\n}\n\nfunction defaultWriterClosedPromiseResetToRejected(writer: WritableStreamDefaultWriter, reason: any) {\n  assert(writer._closedPromise_resolve === undefined);\n  assert(writer._closedPromise_reject === undefined);\n  assert(writer._closedPromiseState !== 'pending');\n\n  defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n}\n\nfunction defaultWriterClosedPromiseResolve(writer: WritableStreamDefaultWriter) {\n  if (writer._closedPromise_resolve === undefined) {\n    return;\n  }\n  assert(writer._closedPromiseState === 'pending');\n\n  writer._closedPromise_resolve(undefined);\n  writer._closedPromise_resolve = undefined;\n  writer._closedPromise_reject = undefined;\n  writer._closedPromiseState = 'resolved';\n}\n\nfunction defaultWriterReadyPromiseInitialize(writer: WritableStreamDefaultWriter) {\n  writer._readyPromise = newPromise((resolve, reject) => {\n    writer._readyPromise_resolve = resolve;\n    writer._readyPromise_reject = reject;\n  });\n  writer._readyPromiseState = 'pending';\n}\n\nfunction defaultWriterReadyPromiseInitializeAsRejected(writer: WritableStreamDefaultWriter, reason: any) {\n  defaultWriterReadyPromiseInitialize(writer);\n  defaultWriterReadyPromiseReject(writer, reason);\n}\n\nfunction defaultWriterReadyPromiseInitializeAsResolved(writer: WritableStreamDefaultWriter) {\n  defaultWriterReadyPromiseInitialize(writer);\n  defaultWriterReadyPromiseResolve(writer);\n}\n\nfunction defaultWriterReadyPromiseReject(writer: WritableStreamDefaultWriter, reason: any) {\n  if (writer._readyPromise_reject === undefined) {\n    return;\n  }\n\n  setPromiseIsHandledToTrue(writer._readyPromise);\n  writer._readyPromise_reject(reason);\n  writer._readyPromise_resolve = undefined;\n  writer._readyPromise_reject = undefined;\n  writer._readyPromiseState = 'rejected';\n}\n\nfunction defaultWriterReadyPromiseReset(writer: WritableStreamDefaultWriter) {\n  assert(writer._readyPromise_resolve === undefined);\n  assert(writer._readyPromise_reject === undefined);\n\n  defaultWriterReadyPromiseInitialize(writer);\n}\n\nfunction defaultWriterReadyPromiseResetToRejected(writer: WritableStreamDefaultWriter, reason: any) {\n  assert(writer._readyPromise_resolve === undefined);\n  assert(writer._readyPromise_reject === undefined);\n\n  defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n}\n\nfunction defaultWriterReadyPromiseResolve(writer: WritableStreamDefaultWriter) {\n  if (writer._readyPromise_resolve === undefined) {\n    return;\n  }\n\n  writer._readyPromise_resolve(undefined);\n  writer._readyPromise_resolve = undefined;\n  writer._readyPromise_reject = undefined;\n  writer._readyPromiseState = 'fulfilled';\n}\n","/// <reference lib=\"dom\" />\n\nfunction getGlobals(): typeof globalThis | undefined {\n  if (typeof globalThis !== 'undefined') {\n    return globalThis;\n  } else if (typeof self !== 'undefined') {\n    return self;\n  } else if (typeof global !== 'undefined') {\n    return global;\n  }\n  return undefined;\n}\n\nexport const globals = getGlobals();\n","/// <reference types=\"node\" />\nimport { globals } from '../globals';\nimport { setFunctionName } from '../lib/helpers/miscellaneous';\n\ninterface DOMException extends Error {\n  name: string;\n  message: string;\n}\n\ntype DOMExceptionConstructor = new (message?: string, name?: string) => DOMException;\n\nfunction isDOMExceptionConstructor(ctor: unknown): ctor is DOMExceptionConstructor {\n  if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n    return false;\n  }\n  if ((ctor as DOMExceptionConstructor).name !== 'DOMException') {\n    return false;\n  }\n  try {\n    new (ctor as DOMExceptionConstructor)();\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Support:\n * - Web browsers\n * - Node 18 and higher (https://github.com/nodejs/node/commit/e4b1fb5e6422c1ff151234bb9de792d45dd88d87)\n */\nfunction getFromGlobal(): DOMExceptionConstructor | undefined {\n  const ctor = globals?.DOMException;\n  return isDOMExceptionConstructor(ctor) ? ctor : undefined;\n}\n\n/**\n * Support:\n * - All platforms\n */\nfunction createPolyfill(): DOMExceptionConstructor {\n  // eslint-disable-next-line @typescript-eslint/no-shadow\n  const ctor = function DOMException(this: DOMException, message?: string, name?: string) {\n    this.message = message || '';\n    this.name = name || 'Error';\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  } as any;\n  setFunctionName(ctor, 'DOMException');\n  ctor.prototype = Object.create(Error.prototype);\n  Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n  return ctor;\n}\n\n// eslint-disable-next-line @typescript-eslint/no-redeclare\nconst DOMException: DOMExceptionConstructor = getFromGlobal() || createPolyfill();\n\nexport { DOMException };\n","import { IsReadableStream, IsReadableStreamLocked, ReadableStream, ReadableStreamCancel } from '../readable-stream';\nimport { AcquireReadableStreamDefaultReader, ReadableStreamDefaultReaderRead } from './default-reader';\nimport { ReadableStreamReaderGenericRelease } from './generic-reader';\nimport {\n  AcquireWritableStreamDefaultWriter,\n  IsWritableStream,\n  IsWritableStreamLocked,\n  WritableStream,\n  WritableStreamAbort,\n  WritableStreamCloseQueuedOrInFlight,\n  WritableStreamDefaultWriterCloseWithErrorPropagation,\n  WritableStreamDefaultWriterRelease,\n  WritableStreamDefaultWriterWrite\n} from '../writable-stream';\nimport assert from '../../stub/assert';\nimport {\n  newPromise,\n  PerformPromiseThen,\n  promiseResolvedWith,\n  setPromiseIsHandledToTrue,\n  uponFulfillment,\n  uponPromise,\n  uponRejection\n} from '../helpers/webidl';\nimport { noop } from '../../utils';\nimport { type AbortSignal, isAbortSignal } from '../abort-signal';\nimport { DOMException } from '../../stub/dom-exception';\n\nexport function ReadableStreamPipeTo<T>(source: ReadableStream<T>,\n                                        dest: WritableStream<T>,\n                                        preventClose: boolean,\n                                        preventAbort: boolean,\n                                        preventCancel: boolean,\n                                        signal: AbortSignal | undefined): Promise<undefined> {\n  assert(IsReadableStream(source));\n  assert(IsWritableStream(dest));\n  assert(typeof preventClose === 'boolean');\n  assert(typeof preventAbort === 'boolean');\n  assert(typeof preventCancel === 'boolean');\n  assert(signal === undefined || isAbortSignal(signal));\n  assert(!IsReadableStreamLocked(source));\n  assert(!IsWritableStreamLocked(dest));\n\n  const reader = AcquireReadableStreamDefaultReader<T>(source);\n  const writer = AcquireWritableStreamDefaultWriter<T>(dest);\n\n  source._disturbed = true;\n\n  let shuttingDown = false;\n\n  // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n  let currentWrite = promiseResolvedWith<void>(undefined);\n\n  return newPromise((resolve, reject) => {\n    let abortAlgorithm: () => void;\n    if (signal !== undefined) {\n      abortAlgorithm = () => {\n        const error = signal.reason !== undefined ? signal.reason : new DOMException('Aborted', 'AbortError');\n        const actions: Array<() => Promise<void>> = [];\n        if (!preventAbort) {\n          actions.push(() => {\n            if (dest._state === 'writable') {\n              return WritableStreamAbort(dest, error);\n            }\n            return promiseResolvedWith(undefined);\n          });\n        }\n        if (!preventCancel) {\n          actions.push(() => {\n            if (source._state === 'readable') {\n              return ReadableStreamCancel(source, error);\n            }\n            return promiseResolvedWith(undefined);\n          });\n        }\n        shutdownWithAction(() => Promise.all(actions.map(action => action())), true, error);\n      };\n\n      if (signal.aborted) {\n        abortAlgorithm();\n        return;\n      }\n\n      signal.addEventListener('abort', abortAlgorithm);\n    }\n\n    // Using reader and writer, read all chunks from this and write them to dest\n    // - Backpressure must be enforced\n    // - Shutdown must stop all activity\n    function pipeLoop() {\n      return newPromise<void>((resolveLoop, rejectLoop) => {\n        function next(done: boolean) {\n          if (done) {\n            resolveLoop();\n          } else {\n            // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n            // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n            PerformPromiseThen(pipeStep(), next, rejectLoop);\n          }\n        }\n\n        next(false);\n      });\n    }\n\n    function pipeStep(): Promise<boolean> {\n      if (shuttingDown) {\n        return promiseResolvedWith(true);\n      }\n\n      return PerformPromiseThen(writer._readyPromise, () => {\n        return newPromise<boolean>((resolveRead, rejectRead) => {\n          ReadableStreamDefaultReaderRead(\n            reader,\n            {\n              _chunkSteps: chunk => {\n                currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                resolveRead(false);\n              },\n              _closeSteps: () => resolveRead(true),\n              _errorSteps: rejectRead\n            }\n          );\n        });\n      });\n    }\n\n    // Errors must be propagated forward\n    isOrBecomesErrored(source, reader._closedPromise, storedError => {\n      if (!preventAbort) {\n        shutdownWithAction(() => WritableStreamAbort(dest, storedError), true, storedError);\n      } else {\n        shutdown(true, storedError);\n      }\n      return null;\n    });\n\n    // Errors must be propagated backward\n    isOrBecomesErrored(dest, writer._closedPromise, storedError => {\n      if (!preventCancel) {\n        shutdownWithAction(() => ReadableStreamCancel(source, storedError), true, storedError);\n      } else {\n        shutdown(true, storedError);\n      }\n      return null;\n    });\n\n    // Closing must be propagated forward\n    isOrBecomesClosed(source, reader._closedPromise, () => {\n      if (!preventClose) {\n        shutdownWithAction(() => WritableStreamDefaultWriterCloseWithErrorPropagation(writer));\n      } else {\n        shutdown();\n      }\n      return null;\n    });\n\n    // Closing must be propagated backward\n    if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n      const destClosed = new TypeError('the destination writable stream closed before all data could be piped to it');\n\n      if (!preventCancel) {\n        shutdownWithAction(() => ReadableStreamCancel(source, destClosed), true, destClosed);\n      } else {\n        shutdown(true, destClosed);\n      }\n    }\n\n    setPromiseIsHandledToTrue(pipeLoop());\n\n    function waitForWritesToFinish(): Promise<void> {\n      // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n      // for that too.\n      const oldCurrentWrite = currentWrite;\n      return PerformPromiseThen(\n        currentWrite,\n        () => oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined\n      );\n    }\n\n    function isOrBecomesErrored(stream: ReadableStream | WritableStream,\n                                promise: Promise<void>,\n                                action: (reason: any) => null) {\n      if (stream._state === 'errored') {\n        action(stream._storedError);\n      } else {\n        uponRejection(promise, action);\n      }\n    }\n\n    function isOrBecomesClosed(stream: ReadableStream | WritableStream, promise: Promise<void>, action: () => null) {\n      if (stream._state === 'closed') {\n        action();\n      } else {\n        uponFulfillment(promise, action);\n      }\n    }\n\n    function shutdownWithAction(action: () => Promise<unknown>, originalIsError?: boolean, originalError?: any) {\n      if (shuttingDown) {\n        return;\n      }\n      shuttingDown = true;\n\n      if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n        uponFulfillment(waitForWritesToFinish(), doTheRest);\n      } else {\n        doTheRest();\n      }\n\n      function doTheRest(): null {\n        uponPromise(\n          action(),\n          () => finalize(originalIsError, originalError),\n          newError => finalize(true, newError)\n        );\n        return null;\n      }\n    }\n\n    function shutdown(isError?: boolean, error?: any) {\n      if (shuttingDown) {\n        return;\n      }\n      shuttingDown = true;\n\n      if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n        uponFulfillment(waitForWritesToFinish(), () => finalize(isError, error));\n      } else {\n        finalize(isError, error);\n      }\n    }\n\n    function finalize(isError?: boolean, error?: any): null {\n      WritableStreamDefaultWriterRelease(writer);\n      ReadableStreamReaderGenericRelease(reader);\n\n      if (signal !== undefined) {\n        signal.removeEventListener('abort', abortAlgorithm);\n      }\n      if (isError) {\n        reject(error);\n      } else {\n        resolve(undefined);\n      }\n\n      return null;\n    }\n  });\n}\n","import type { QueuingStrategySizeCallback } from '../queuing-strategy';\nimport assert from '../../stub/assert';\nimport { DequeueValue, EnqueueValueWithSize, type QueuePair, ResetQueue } from '../abstract-ops/queue-with-sizes';\nimport {\n  ReadableStreamAddReadRequest,\n  ReadableStreamFulfillReadRequest,\n  ReadableStreamGetNumReadRequests,\n  type ReadRequest\n} from './default-reader';\nimport { SimpleQueue } from '../simple-queue';\nimport { IsReadableStreamLocked, ReadableStream, ReadableStreamClose, ReadableStreamError } from '../readable-stream';\nimport type { ValidatedUnderlyingSource } from './underlying-source';\nimport { setFunctionName, typeIsObject } from '../helpers/miscellaneous';\nimport { CancelSteps, PullSteps, ReleaseSteps } from '../abstract-ops/internal-methods';\nimport { promiseResolvedWith, uponPromise } from '../helpers/webidl';\n\n/**\n * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n *\n * @public\n */\nexport class ReadableStreamDefaultController<R> {\n  /** @internal */\n  _controlledReadableStream!: ReadableStream<R>;\n  /** @internal */\n  _queue!: SimpleQueue<QueuePair<R>>;\n  /** @internal */\n  _queueTotalSize!: number;\n  /** @internal */\n  _started!: boolean;\n  /** @internal */\n  _closeRequested!: boolean;\n  /** @internal */\n  _pullAgain!: boolean;\n  /** @internal */\n  _pulling !: boolean;\n  /** @internal */\n  _strategySizeAlgorithm!: QueuingStrategySizeCallback<R>;\n  /** @internal */\n  _strategyHWM!: number;\n  /** @internal */\n  _pullAlgorithm!: () => Promise<void>;\n  /** @internal */\n  _cancelAlgorithm!: (reason: any) => Promise<void>;\n\n  private constructor() {\n    throw new TypeError('Illegal constructor');\n  }\n\n  /**\n   * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n   * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n   */\n  get desiredSize(): number | null {\n    if (!IsReadableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('desiredSize');\n    }\n\n    return ReadableStreamDefaultControllerGetDesiredSize(this);\n  }\n\n  /**\n   * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n   * the stream, but once those are read, the stream will become closed.\n   */\n  close(): void {\n    if (!IsReadableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('close');\n    }\n\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n      throw new TypeError('The stream is not in a state that permits close');\n    }\n\n    ReadableStreamDefaultControllerClose(this);\n  }\n\n  /**\n   * Enqueues the given chunk `chunk` in the controlled readable stream.\n   */\n  enqueue(chunk: R): void;\n  enqueue(chunk: R = undefined!): void {\n    if (!IsReadableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('enqueue');\n    }\n\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n      throw new TypeError('The stream is not in a state that permits enqueue');\n    }\n\n    return ReadableStreamDefaultControllerEnqueue(this, chunk);\n  }\n\n  /**\n   * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n   */\n  error(e: any = undefined): void {\n    if (!IsReadableStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('error');\n    }\n\n    ReadableStreamDefaultControllerError(this, e);\n  }\n\n  /** @internal */\n  [CancelSteps](reason: any): Promise<void> {\n    ResetQueue(this);\n    const result = this._cancelAlgorithm(reason);\n    ReadableStreamDefaultControllerClearAlgorithms(this);\n    return result;\n  }\n\n  /** @internal */\n  [PullSteps](readRequest: ReadRequest<R>): void {\n    const stream = this._controlledReadableStream;\n\n    if (this._queue.length > 0) {\n      const chunk = DequeueValue(this);\n\n      if (this._closeRequested && this._queue.length === 0) {\n        ReadableStreamDefaultControllerClearAlgorithms(this);\n        ReadableStreamClose(stream);\n      } else {\n        ReadableStreamDefaultControllerCallPullIfNeeded(this);\n      }\n\n      readRequest._chunkSteps(chunk);\n    } else {\n      ReadableStreamAddReadRequest(stream, readRequest);\n      ReadableStreamDefaultControllerCallPullIfNeeded(this);\n    }\n  }\n\n  /** @internal */\n  [ReleaseSteps](): void {\n    // Do nothing.\n  }\n}\n\nObject.defineProperties(ReadableStreamDefaultController.prototype, {\n  close: { enumerable: true },\n  enqueue: { enumerable: true },\n  error: { enumerable: true },\n  desiredSize: { enumerable: true }\n});\nsetFunctionName(ReadableStreamDefaultController.prototype.close, 'close');\nsetFunctionName(ReadableStreamDefaultController.prototype.enqueue, 'enqueue');\nsetFunctionName(ReadableStreamDefaultController.prototype.error, 'error');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableStreamDefaultController.prototype, Symbol.toStringTag, {\n    value: 'ReadableStreamDefaultController',\n    configurable: true\n  });\n}\n\n// Abstract operations for the ReadableStreamDefaultController.\n\nfunction IsReadableStreamDefaultController<R = any>(x: any): x is ReadableStreamDefaultController<R> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n    return false;\n  }\n\n  return x instanceof ReadableStreamDefaultController;\n}\n\nfunction ReadableStreamDefaultControllerCallPullIfNeeded(controller: ReadableStreamDefaultController<any>): void {\n  const shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n  if (!shouldPull) {\n    return;\n  }\n\n  if (controller._pulling) {\n    controller._pullAgain = true;\n    return;\n  }\n\n  assert(!controller._pullAgain);\n\n  controller._pulling = true;\n\n  const pullPromise = controller._pullAlgorithm();\n  uponPromise(\n    pullPromise,\n    () => {\n      controller._pulling = false;\n\n      if (controller._pullAgain) {\n        controller._pullAgain = false;\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n      }\n\n      return null;\n    },\n    e => {\n      ReadableStreamDefaultControllerError(controller, e);\n      return null;\n    }\n  );\n}\n\nfunction ReadableStreamDefaultControllerShouldCallPull(controller: ReadableStreamDefaultController<any>): boolean {\n  const stream = controller._controlledReadableStream;\n\n  if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n    return false;\n  }\n\n  if (!controller._started) {\n    return false;\n  }\n\n  if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n    return true;\n  }\n\n  const desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n  assert(desiredSize !== null);\n  if (desiredSize! > 0) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction ReadableStreamDefaultControllerClearAlgorithms(controller: ReadableStreamDefaultController<any>) {\n  controller._pullAlgorithm = undefined!;\n  controller._cancelAlgorithm = undefined!;\n  controller._strategySizeAlgorithm = undefined!;\n}\n\n// A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\n\nexport function ReadableStreamDefaultControllerClose(controller: ReadableStreamDefaultController<any>) {\n  if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n    return;\n  }\n\n  const stream = controller._controlledReadableStream;\n\n  controller._closeRequested = true;\n\n  if (controller._queue.length === 0) {\n    ReadableStreamDefaultControllerClearAlgorithms(controller);\n    ReadableStreamClose(stream);\n  }\n}\n\nexport function ReadableStreamDefaultControllerEnqueue<R>(\n  controller: ReadableStreamDefaultController<R>,\n  chunk: R\n): void {\n  if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n    return;\n  }\n\n  const stream = controller._controlledReadableStream;\n\n  if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n    ReadableStreamFulfillReadRequest(stream, chunk, false);\n  } else {\n    let chunkSize;\n    try {\n      chunkSize = controller._strategySizeAlgorithm(chunk);\n    } catch (chunkSizeE) {\n      ReadableStreamDefaultControllerError(controller, chunkSizeE);\n      throw chunkSizeE;\n    }\n\n    try {\n      EnqueueValueWithSize(controller, chunk, chunkSize);\n    } catch (enqueueE) {\n      ReadableStreamDefaultControllerError(controller, enqueueE);\n      throw enqueueE;\n    }\n  }\n\n  ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n}\n\nexport function ReadableStreamDefaultControllerError(controller: ReadableStreamDefaultController<any>, e: any) {\n  const stream = controller._controlledReadableStream;\n\n  if (stream._state !== 'readable') {\n    return;\n  }\n\n  ResetQueue(controller);\n\n  ReadableStreamDefaultControllerClearAlgorithms(controller);\n  ReadableStreamError(stream, e);\n}\n\nexport function ReadableStreamDefaultControllerGetDesiredSize(\n  controller: ReadableStreamDefaultController<any>\n): number | null {\n  const state = controller._controlledReadableStream._state;\n\n  if (state === 'errored') {\n    return null;\n  }\n  if (state === 'closed') {\n    return 0;\n  }\n\n  return controller._strategyHWM - controller._queueTotalSize;\n}\n\n// This is used in the implementation of TransformStream.\nexport function ReadableStreamDefaultControllerHasBackpressure(\n  controller: ReadableStreamDefaultController<any>\n): boolean {\n  if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n    return false;\n  }\n\n  return true;\n}\n\nexport function ReadableStreamDefaultControllerCanCloseOrEnqueue(\n  controller: ReadableStreamDefaultController<any>\n): boolean {\n  const state = controller._controlledReadableStream._state;\n\n  if (!controller._closeRequested && state === 'readable') {\n    return true;\n  }\n\n  return false;\n}\n\nexport function SetUpReadableStreamDefaultController<R>(stream: ReadableStream<R>,\n                                                        controller: ReadableStreamDefaultController<R>,\n                                                        startAlgorithm: () => void | PromiseLike<void>,\n                                                        pullAlgorithm: () => Promise<void>,\n                                                        cancelAlgorithm: (reason: any) => Promise<void>,\n                                                        highWaterMark: number,\n                                                        sizeAlgorithm: QueuingStrategySizeCallback<R>) {\n  assert(stream._readableStreamController === undefined);\n\n  controller._controlledReadableStream = stream;\n\n  controller._queue = undefined!;\n  controller._queueTotalSize = undefined!;\n  ResetQueue(controller);\n\n  controller._started = false;\n  controller._closeRequested = false;\n  controller._pullAgain = false;\n  controller._pulling = false;\n\n  controller._strategySizeAlgorithm = sizeAlgorithm;\n  controller._strategyHWM = highWaterMark;\n\n  controller._pullAlgorithm = pullAlgorithm;\n  controller._cancelAlgorithm = cancelAlgorithm;\n\n  stream._readableStreamController = controller;\n\n  const startResult = startAlgorithm();\n  uponPromise(\n    promiseResolvedWith(startResult),\n    () => {\n      controller._started = true;\n\n      assert(!controller._pulling);\n      assert(!controller._pullAgain);\n\n      ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n      return null;\n    },\n    r => {\n      ReadableStreamDefaultControllerError(controller, r);\n      return null;\n    }\n  );\n}\n\nexport function SetUpReadableStreamDefaultControllerFromUnderlyingSource<R>(\n  stream: ReadableStream<R>,\n  underlyingSource: ValidatedUnderlyingSource<R>,\n  highWaterMark: number,\n  sizeAlgorithm: QueuingStrategySizeCallback<R>\n) {\n  const controller: ReadableStreamDefaultController<R> = Object.create(ReadableStreamDefaultController.prototype);\n\n  let startAlgorithm: () => void | PromiseLike<void>;\n  let pullAlgorithm: () => Promise<void>;\n  let cancelAlgorithm: (reason: any) => Promise<void>;\n\n  if (underlyingSource.start !== undefined) {\n    startAlgorithm = () => underlyingSource.start!(controller);\n  } else {\n    startAlgorithm = () => undefined;\n  }\n  if (underlyingSource.pull !== undefined) {\n    pullAlgorithm = () => underlyingSource.pull!(controller);\n  } else {\n    pullAlgorithm = () => promiseResolvedWith(undefined);\n  }\n  if (underlyingSource.cancel !== undefined) {\n    cancelAlgorithm = reason => underlyingSource.cancel!(reason);\n  } else {\n    cancelAlgorithm = () => promiseResolvedWith(undefined);\n  }\n\n  SetUpReadableStreamDefaultController(\n    stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm\n  );\n}\n\n// Helper functions for the ReadableStreamDefaultController.\n\nfunction defaultControllerBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `ReadableStreamDefaultController.prototype.${name} can only be used on a ReadableStreamDefaultController`);\n}\n","import {\n  CreateReadableByteStream,\n  CreateReadableStream,\n  type DefaultReadableStream,\n  IsReadableStream,\n  type ReadableByteStream,\n  ReadableStream,\n  ReadableStreamCancel,\n  type ReadableStreamReader\n} from '../readable-stream';\nimport { ReadableStreamReaderGenericRelease } from './generic-reader';\nimport {\n  AcquireReadableStreamDefaultReader,\n  IsReadableStreamDefaultReader,\n  ReadableStreamDefaultReaderRead,\n  type ReadRequest\n} from './default-reader';\nimport {\n  AcquireReadableStreamBYOBReader,\n  IsReadableStreamBYOBReader,\n  ReadableStreamBYOBReaderRead,\n  type ReadIntoRequest\n} from './byob-reader';\nimport assert from '../../stub/assert';\nimport { newPromise, promiseResolvedWith, queueMicrotask, uponRejection } from '../helpers/webidl';\nimport {\n  ReadableStreamDefaultControllerClose,\n  ReadableStreamDefaultControllerEnqueue,\n  ReadableStreamDefaultControllerError\n} from './default-controller';\nimport {\n  IsReadableByteStreamController,\n  ReadableByteStreamControllerClose,\n  ReadableByteStreamControllerEnqueue,\n  ReadableByteStreamControllerError,\n  ReadableByteStreamControllerGetBYOBRequest,\n  ReadableByteStreamControllerRespond,\n  ReadableByteStreamControllerRespondWithNewView\n} from './byte-stream-controller';\nimport { CreateArrayFromList } from '../abstract-ops/ecmascript';\nimport { CloneAsUint8Array } from '../abstract-ops/miscellaneous';\nimport type { NonShared } from '../helpers/array-buffer-view';\n\nexport function ReadableStreamTee<R>(stream: ReadableStream<R>,\n                                     cloneForBranch2: boolean): [ReadableStream<R>, ReadableStream<R>] {\n  assert(IsReadableStream(stream));\n  assert(typeof cloneForBranch2 === 'boolean');\n  if (IsReadableByteStreamController(stream._readableStreamController)) {\n    return ReadableByteStreamTee(stream as unknown as ReadableByteStream) as\n      unknown as [ReadableStream<R>, ReadableStream<R>];\n  }\n  return ReadableStreamDefaultTee(stream, cloneForBranch2);\n}\n\nexport function ReadableStreamDefaultTee<R>(\n  stream: ReadableStream<R>,\n  cloneForBranch2: boolean\n): [DefaultReadableStream<R>, DefaultReadableStream<R>] {\n  assert(IsReadableStream(stream));\n  assert(typeof cloneForBranch2 === 'boolean');\n\n  const reader = AcquireReadableStreamDefaultReader<R>(stream);\n\n  let reading = false;\n  let readAgain = false;\n  let canceled1 = false;\n  let canceled2 = false;\n  let reason1: any;\n  let reason2: any;\n  let branch1: DefaultReadableStream<R>;\n  let branch2: DefaultReadableStream<R>;\n\n  let resolveCancelPromise: (value: undefined | Promise<undefined>) => void;\n  const cancelPromise = newPromise<undefined>(resolve => {\n    resolveCancelPromise = resolve;\n  });\n\n  function pullAlgorithm(): Promise<void> {\n    if (reading) {\n      readAgain = true;\n      return promiseResolvedWith(undefined);\n    }\n\n    reading = true;\n\n    const readRequest: ReadRequest<R> = {\n      _chunkSteps: chunk => {\n        // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n        // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n        // successful synchronously-available reads get ahead of asynchronously-available errors.\n        queueMicrotask(() => {\n          readAgain = false;\n          const chunk1 = chunk;\n          const chunk2 = chunk;\n\n          // There is no way to access the cloning code right now in the reference implementation.\n          // If we add one then we'll need an implementation for serializable objects.\n          // if (!canceled2 && cloneForBranch2) {\n          //   chunk2 = StructuredDeserialize(StructuredSerialize(chunk2));\n          // }\n\n          if (!canceled1) {\n            ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, chunk1);\n          }\n          if (!canceled2) {\n            ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, chunk2);\n          }\n\n          reading = false;\n          if (readAgain) {\n            pullAlgorithm();\n          }\n        });\n      },\n      _closeSteps: () => {\n        reading = false;\n        if (!canceled1) {\n          ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n        }\n        if (!canceled2) {\n          ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n        }\n\n        if (!canceled1 || !canceled2) {\n          resolveCancelPromise(undefined);\n        }\n      },\n      _errorSteps: () => {\n        reading = false;\n      }\n    };\n    ReadableStreamDefaultReaderRead(reader, readRequest);\n\n    return promiseResolvedWith(undefined);\n  }\n\n  function cancel1Algorithm(reason: any): Promise<void> {\n    canceled1 = true;\n    reason1 = reason;\n    if (canceled2) {\n      const compositeReason = CreateArrayFromList([reason1, reason2]);\n      const cancelResult = ReadableStreamCancel(stream, compositeReason);\n      resolveCancelPromise(cancelResult);\n    }\n    return cancelPromise;\n  }\n\n  function cancel2Algorithm(reason: any): Promise<void> {\n    canceled2 = true;\n    reason2 = reason;\n    if (canceled1) {\n      const compositeReason = CreateArrayFromList([reason1, reason2]);\n      const cancelResult = ReadableStreamCancel(stream, compositeReason);\n      resolveCancelPromise(cancelResult);\n    }\n    return cancelPromise;\n  }\n\n  function startAlgorithm() {\n    // do nothing\n  }\n\n  branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n  branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n\n  uponRejection(reader._closedPromise, (r: any) => {\n    ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n    ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n    if (!canceled1 || !canceled2) {\n      resolveCancelPromise(undefined);\n    }\n    return null;\n  });\n\n  return [branch1, branch2];\n}\n\nexport function ReadableByteStreamTee(stream: ReadableByteStream): [ReadableByteStream, ReadableByteStream] {\n  assert(IsReadableStream(stream));\n  assert(IsReadableByteStreamController(stream._readableStreamController));\n\n  let reader: ReadableStreamReader<NonShared<Uint8Array>> = AcquireReadableStreamDefaultReader(stream);\n  let reading = false;\n  let readAgainForBranch1 = false;\n  let readAgainForBranch2 = false;\n  let canceled1 = false;\n  let canceled2 = false;\n  let reason1: any;\n  let reason2: any;\n  let branch1: ReadableByteStream;\n  let branch2: ReadableByteStream;\n\n  let resolveCancelPromise: (value: undefined | Promise<undefined>) => void;\n  const cancelPromise = newPromise<void>(resolve => {\n    resolveCancelPromise = resolve;\n  });\n\n  function forwardReaderError(thisReader: ReadableStreamReader<NonShared<Uint8Array>>) {\n    uponRejection(thisReader._closedPromise, r => {\n      if (thisReader !== reader) {\n        return null;\n      }\n      ReadableByteStreamControllerError(branch1._readableStreamController, r);\n      ReadableByteStreamControllerError(branch2._readableStreamController, r);\n      if (!canceled1 || !canceled2) {\n        resolveCancelPromise(undefined);\n      }\n      return null;\n    });\n  }\n\n  function pullWithDefaultReader() {\n    if (IsReadableStreamBYOBReader(reader)) {\n      assert(reader._readIntoRequests.length === 0);\n      ReadableStreamReaderGenericRelease(reader);\n\n      reader = AcquireReadableStreamDefaultReader(stream);\n      forwardReaderError(reader);\n    }\n\n    const readRequest: ReadRequest<NonShared<Uint8Array>> = {\n      _chunkSteps: chunk => {\n        // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n        // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n        // successful synchronously-available reads get ahead of asynchronously-available errors.\n        queueMicrotask(() => {\n          readAgainForBranch1 = false;\n          readAgainForBranch2 = false;\n\n          const chunk1 = chunk;\n          let chunk2 = chunk;\n          if (!canceled1 && !canceled2) {\n            try {\n              chunk2 = CloneAsUint8Array(chunk);\n            } catch (cloneE) {\n              ReadableByteStreamControllerError(branch1._readableStreamController, cloneE);\n              ReadableByteStreamControllerError(branch2._readableStreamController, cloneE);\n              resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n              return;\n            }\n          }\n\n          if (!canceled1) {\n            ReadableByteStreamControllerEnqueue(branch1._readableStreamController, chunk1);\n          }\n          if (!canceled2) {\n            ReadableByteStreamControllerEnqueue(branch2._readableStreamController, chunk2);\n          }\n\n          reading = false;\n          if (readAgainForBranch1) {\n            pull1Algorithm();\n          } else if (readAgainForBranch2) {\n            pull2Algorithm();\n          }\n        });\n      },\n      _closeSteps: () => {\n        reading = false;\n        if (!canceled1) {\n          ReadableByteStreamControllerClose(branch1._readableStreamController);\n        }\n        if (!canceled2) {\n          ReadableByteStreamControllerClose(branch2._readableStreamController);\n        }\n        if (branch1._readableStreamController._pendingPullIntos.length > 0) {\n          ReadableByteStreamControllerRespond(branch1._readableStreamController, 0);\n        }\n        if (branch2._readableStreamController._pendingPullIntos.length > 0) {\n          ReadableByteStreamControllerRespond(branch2._readableStreamController, 0);\n        }\n        if (!canceled1 || !canceled2) {\n          resolveCancelPromise(undefined);\n        }\n      },\n      _errorSteps: () => {\n        reading = false;\n      }\n    };\n    ReadableStreamDefaultReaderRead(reader, readRequest);\n  }\n\n  function pullWithBYOBReader(view: NonShared<ArrayBufferView>, forBranch2: boolean) {\n    if (IsReadableStreamDefaultReader<NonShared<Uint8Array>>(reader)) {\n      assert(reader._readRequests.length === 0);\n      ReadableStreamReaderGenericRelease(reader);\n\n      reader = AcquireReadableStreamBYOBReader(stream);\n      forwardReaderError(reader);\n    }\n\n    const byobBranch = forBranch2 ? branch2 : branch1;\n    const otherBranch = forBranch2 ? branch1 : branch2;\n\n    const readIntoRequest: ReadIntoRequest<NonShared<ArrayBufferView>> = {\n      _chunkSteps: chunk => {\n        // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n        // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n        // successful synchronously-available reads get ahead of asynchronously-available errors.\n        queueMicrotask(() => {\n          readAgainForBranch1 = false;\n          readAgainForBranch2 = false;\n\n          const byobCanceled = forBranch2 ? canceled2 : canceled1;\n          const otherCanceled = forBranch2 ? canceled1 : canceled2;\n\n          if (!otherCanceled) {\n            let clonedChunk;\n            try {\n              clonedChunk = CloneAsUint8Array(chunk);\n            } catch (cloneE) {\n              ReadableByteStreamControllerError(byobBranch._readableStreamController, cloneE);\n              ReadableByteStreamControllerError(otherBranch._readableStreamController, cloneE);\n              resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n              return;\n            }\n            if (!byobCanceled) {\n              ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n            }\n            ReadableByteStreamControllerEnqueue(otherBranch._readableStreamController, clonedChunk);\n          } else if (!byobCanceled) {\n            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n          }\n\n          reading = false;\n          if (readAgainForBranch1) {\n            pull1Algorithm();\n          } else if (readAgainForBranch2) {\n            pull2Algorithm();\n          }\n        });\n      },\n      _closeSteps: chunk => {\n        reading = false;\n\n        const byobCanceled = forBranch2 ? canceled2 : canceled1;\n        const otherCanceled = forBranch2 ? canceled1 : canceled2;\n\n        if (!byobCanceled) {\n          ReadableByteStreamControllerClose(byobBranch._readableStreamController);\n        }\n        if (!otherCanceled) {\n          ReadableByteStreamControllerClose(otherBranch._readableStreamController);\n        }\n\n        if (chunk !== undefined) {\n          assert(chunk.byteLength === 0);\n\n          if (!byobCanceled) {\n            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n          }\n          if (!otherCanceled && otherBranch._readableStreamController._pendingPullIntos.length > 0) {\n            ReadableByteStreamControllerRespond(otherBranch._readableStreamController, 0);\n          }\n        }\n\n        if (!byobCanceled || !otherCanceled) {\n          resolveCancelPromise(undefined);\n        }\n      },\n      _errorSteps: () => {\n        reading = false;\n      }\n    };\n    ReadableStreamBYOBReaderRead(reader, view, 1, readIntoRequest);\n  }\n\n  function pull1Algorithm(): Promise<void> {\n    if (reading) {\n      readAgainForBranch1 = true;\n      return promiseResolvedWith(undefined);\n    }\n\n    reading = true;\n\n    const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch1._readableStreamController);\n    if (byobRequest === null) {\n      pullWithDefaultReader();\n    } else {\n      pullWithBYOBReader(byobRequest._view!, false);\n    }\n\n    return promiseResolvedWith(undefined);\n  }\n\n  function pull2Algorithm(): Promise<void> {\n    if (reading) {\n      readAgainForBranch2 = true;\n      return promiseResolvedWith(undefined);\n    }\n\n    reading = true;\n\n    const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch2._readableStreamController);\n    if (byobRequest === null) {\n      pullWithDefaultReader();\n    } else {\n      pullWithBYOBReader(byobRequest._view!, true);\n    }\n\n    return promiseResolvedWith(undefined);\n  }\n\n  function cancel1Algorithm(reason: any): Promise<void> {\n    canceled1 = true;\n    reason1 = reason;\n    if (canceled2) {\n      const compositeReason = CreateArrayFromList([reason1, reason2]);\n      const cancelResult = ReadableStreamCancel(stream, compositeReason);\n      resolveCancelPromise(cancelResult);\n    }\n    return cancelPromise;\n  }\n\n  function cancel2Algorithm(reason: any): Promise<void> {\n    canceled2 = true;\n    reason2 = reason;\n    if (canceled1) {\n      const compositeReason = CreateArrayFromList([reason1, reason2]);\n      const cancelResult = ReadableStreamCancel(stream, compositeReason);\n      resolveCancelPromise(cancelResult);\n    }\n    return cancelPromise;\n  }\n\n  function startAlgorithm(): void {\n    return;\n  }\n\n  branch1 = CreateReadableByteStream(startAlgorithm, pull1Algorithm, cancel1Algorithm);\n  branch2 = CreateReadableByteStream(startAlgorithm, pull2Algorithm, cancel2Algorithm);\n\n  forwardReaderError(reader);\n\n  return [branch1, branch2];\n}\n","import { typeIsObject } from '../helpers/miscellaneous';\nimport type { ReadableStreamDefaultReadResult } from './default-reader';\n\n/**\n * A common interface for a `ReadadableStream` implementation.\n *\n * @public\n */\nexport interface ReadableStreamLike<R = any> {\n  readonly locked: boolean;\n\n  getReader(): ReadableStreamDefaultReaderLike<R>;\n}\n\n/**\n * A common interface for a `ReadableStreamDefaultReader` implementation.\n *\n * @public\n */\nexport interface ReadableStreamDefaultReaderLike<R = any> {\n  readonly closed: Promise<undefined>;\n\n  cancel(reason?: any): Promise<void>;\n\n  read(): Promise<ReadableStreamDefaultReadResult<R>>;\n\n  releaseLock(): void;\n}\n\nexport function isReadableStreamLike<R>(stream: unknown): stream is ReadableStreamLike<R> {\n  return typeIsObject(stream) && typeof (stream as ReadableStreamLike<R>).getReader !== 'undefined';\n}\n","import { CreateReadableStream, type DefaultReadableStream } from '../readable-stream';\nimport {\n  isReadableStreamLike,\n  type ReadableStreamDefaultReaderLike,\n  type ReadableStreamLike\n} from './readable-stream-like';\nimport { ReadableStreamDefaultControllerClose, ReadableStreamDefaultControllerEnqueue } from './default-controller';\nimport { GetIterator, GetMethod, IteratorComplete, IteratorNext, IteratorValue } from '../abstract-ops/ecmascript';\nimport { promiseRejectedWith, promiseResolvedWith, reflectCall, transformPromiseWith } from '../helpers/webidl';\nimport { typeIsObject } from '../helpers/miscellaneous';\nimport { noop } from '../../utils';\n\nexport function ReadableStreamFrom<R>(\n  source: Iterable<R> | AsyncIterable<R> | ReadableStreamLike<R>\n): DefaultReadableStream<R> {\n  if (isReadableStreamLike(source)) {\n    return ReadableStreamFromDefaultReader(source.getReader());\n  }\n  return ReadableStreamFromIterable(source);\n}\n\nexport function ReadableStreamFromIterable<R>(asyncIterable: Iterable<R> | AsyncIterable<R>): DefaultReadableStream<R> {\n  let stream: DefaultReadableStream<R>;\n  const iteratorRecord = GetIterator(asyncIterable, 'async');\n\n  const startAlgorithm = noop;\n\n  function pullAlgorithm(): Promise<void> {\n    let nextResult;\n    try {\n      nextResult = IteratorNext(iteratorRecord);\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n    const nextPromise = promiseResolvedWith(nextResult);\n    return transformPromiseWith(nextPromise, iterResult => {\n      if (!typeIsObject(iterResult)) {\n        throw new TypeError('The promise returned by the iterator.next() method must fulfill with an object');\n      }\n      const done = IteratorComplete(iterResult);\n      if (done) {\n        ReadableStreamDefaultControllerClose(stream._readableStreamController);\n      } else {\n        const value = IteratorValue(iterResult);\n        ReadableStreamDefaultControllerEnqueue(stream._readableStreamController, value);\n      }\n    });\n  }\n\n  function cancelAlgorithm(reason: any): Promise<void> {\n    const iterator = iteratorRecord.iterator;\n    let returnMethod: (typeof iterator)['return'] | undefined;\n    try {\n      returnMethod = GetMethod(iterator, 'return');\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n    if (returnMethod === undefined) {\n      return promiseResolvedWith(undefined);\n    }\n    let returnResult: IteratorResult<R> | Promise<IteratorResult<R>>;\n    try {\n      returnResult = reflectCall(returnMethod, iterator, [reason]);\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n    const returnPromise = promiseResolvedWith(returnResult);\n    return transformPromiseWith(returnPromise, iterResult => {\n      if (!typeIsObject(iterResult)) {\n        throw new TypeError('The promise returned by the iterator.return() method must fulfill with an object');\n      }\n      return undefined;\n    });\n  }\n\n  stream = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, 0);\n  return stream;\n}\n\nexport function ReadableStreamFromDefaultReader<R>(\n  reader: ReadableStreamDefaultReaderLike<R>\n): DefaultReadableStream<R> {\n  let stream: DefaultReadableStream<R>;\n\n  const startAlgorithm = noop;\n\n  function pullAlgorithm(): Promise<void> {\n    let readPromise;\n    try {\n      readPromise = reader.read();\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n    return transformPromiseWith(readPromise, readResult => {\n      if (!typeIsObject(readResult)) {\n        throw new TypeError('The promise returned by the reader.read() method must fulfill with an object');\n      }\n      if (readResult.done) {\n        ReadableStreamDefaultControllerClose(stream._readableStreamController);\n      } else {\n        const value = readResult.value;\n        ReadableStreamDefaultControllerEnqueue(stream._readableStreamController, value);\n      }\n    });\n  }\n\n  function cancelAlgorithm(reason: any): Promise<void> {\n    try {\n      return promiseResolvedWith(reader.cancel(reason));\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n  }\n\n  stream = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, 0);\n  return stream;\n}\n","import { assertDictionary, assertFunction, convertUnsignedLongLongWithEnforceRange } from './basic';\nimport type {\n  ReadableStreamController,\n  UnderlyingByteSource,\n  UnderlyingDefaultOrByteSource,\n  UnderlyingDefaultOrByteSourcePullCallback,\n  UnderlyingDefaultOrByteSourceStartCallback,\n  UnderlyingSource,\n  UnderlyingSourceCancelCallback,\n  ValidatedUnderlyingDefaultOrByteSource\n} from '../readable-stream/underlying-source';\nimport { promiseCall, reflectCall } from '../helpers/webidl';\n\nexport function convertUnderlyingDefaultOrByteSource<R>(\n  source: UnderlyingSource<R> | UnderlyingByteSource | null,\n  context: string\n): ValidatedUnderlyingDefaultOrByteSource<R> {\n  assertDictionary(source, context);\n  const original = source as (UnderlyingDefaultOrByteSource<R> | null);\n  const autoAllocateChunkSize = original?.autoAllocateChunkSize;\n  const cancel = original?.cancel;\n  const pull = original?.pull;\n  const start = original?.start;\n  const type = original?.type;\n  return {\n    autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n      undefined :\n      convertUnsignedLongLongWithEnforceRange(\n        autoAllocateChunkSize,\n        `${context} has member 'autoAllocateChunkSize' that`\n      ),\n    cancel: cancel === undefined ?\n      undefined :\n      convertUnderlyingSourceCancelCallback(cancel, original!, `${context} has member 'cancel' that`),\n    pull: pull === undefined ?\n      undefined :\n      convertUnderlyingSourcePullCallback(pull, original!, `${context} has member 'pull' that`),\n    start: start === undefined ?\n      undefined :\n      convertUnderlyingSourceStartCallback(start, original!, `${context} has member 'start' that`),\n    type: type === undefined ? undefined : convertReadableStreamType(type, `${context} has member 'type' that`)\n  };\n}\n\nfunction convertUnderlyingSourceCancelCallback(\n  fn: UnderlyingSourceCancelCallback,\n  original: UnderlyingDefaultOrByteSource,\n  context: string\n): (reason: any) => Promise<void> {\n  assertFunction(fn, context);\n  return (reason: any) => promiseCall(fn, original, [reason]);\n}\n\nfunction convertUnderlyingSourcePullCallback<R>(\n  fn: UnderlyingDefaultOrByteSourcePullCallback<R>,\n  original: UnderlyingDefaultOrByteSource<R>,\n  context: string\n): (controller: ReadableStreamController<R>) => Promise<void> {\n  assertFunction(fn, context);\n  return (controller: ReadableStreamController<R>) => promiseCall(fn, original, [controller]);\n}\n\nfunction convertUnderlyingSourceStartCallback<R>(\n  fn: UnderlyingDefaultOrByteSourceStartCallback<R>,\n  original: UnderlyingDefaultOrByteSource<R>,\n  context: string\n): UnderlyingDefaultOrByteSourceStartCallback<R> {\n  assertFunction(fn, context);\n  return (controller: ReadableStreamController<R>) => reflectCall(fn, original, [controller]);\n}\n\nfunction convertReadableStreamType(type: string, context: string): 'bytes' {\n  type = `${type}`;\n  if (type !== 'bytes') {\n    throw new TypeError(`${context} '${type}' is not a valid enumeration value for ReadableStreamType`);\n  }\n  return type;\n}\n","import { assertDictionary } from './basic';\nimport type {\n  ReadableStreamIteratorOptions,\n  ValidatedReadableStreamIteratorOptions\n} from '../readable-stream/iterator-options';\n\nexport function convertIteratorOptions(options: ReadableStreamIteratorOptions | null | undefined,\n                                       context: string): ValidatedReadableStreamIteratorOptions {\n  assertDictionary(options, context);\n  const preventCancel = options?.preventCancel;\n  return { preventCancel: Boolean(preventCancel) };\n}\n","import { assertDictionary } from './basic';\nimport type { StreamPipeOptions, ValidatedStreamPipeOptions } from '../readable-stream/pipe-options';\nimport { type AbortSignal, isAbortSignal } from '../abort-signal';\n\nexport function convertPipeOptions(options: StreamPipeOptions | null | undefined,\n                                   context: string): ValidatedStreamPipeOptions {\n  assertDictionary(options, context);\n  const preventAbort = options?.preventAbort;\n  const preventCancel = options?.preventCancel;\n  const preventClose = options?.preventClose;\n  const signal = options?.signal;\n  if (signal !== undefined) {\n    assertAbortSignal(signal, `${context} has member 'signal' that`);\n  }\n  return {\n    preventAbort: Boolean(preventAbort),\n    preventCancel: Boolean(preventCancel),\n    preventClose: Boolean(preventClose),\n    signal\n  };\n}\n\nfunction assertAbortSignal(signal: unknown, context: string): asserts signal is AbortSignal {\n  if (!isAbortSignal(signal)) {\n    throw new TypeError(`${context} is not an AbortSignal.`);\n  }\n}\n","import { assertDictionary, assertRequiredField } from './basic';\nimport { ReadableStream } from '../readable-stream';\nimport { WritableStream } from '../writable-stream';\nimport { assertReadableStream } from './readable-stream';\nimport { assertWritableStream } from './writable-stream';\n\nexport function convertReadableWritablePair<RS extends ReadableStream, WS extends WritableStream>(\n  pair: { readable: RS; writable: WS } | null | undefined,\n  context: string\n): { readable: RS; writable: WS } {\n  assertDictionary(pair, context);\n\n  const readable = pair?.readable;\n  assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n  assertReadableStream(readable, `${context} has member 'readable' that`);\n\n  const writable = pair?.writable;\n  assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n  assertWritableStream(writable, `${context} has member 'writable' that`);\n\n  return { readable, writable };\n}\n","import assert from '../stub/assert';\nimport {\n  promiseRejectedWith,\n  promiseResolvedWith,\n  setPromiseIsHandledToTrue,\n  transformPromiseWith\n} from './helpers/webidl';\nimport type { QueuingStrategy, QueuingStrategySizeCallback } from './queuing-strategy';\nimport { AcquireReadableStreamAsyncIterator, type ReadableStreamAsyncIterator } from './readable-stream/async-iterator';\nimport { defaultReaderClosedPromiseReject, defaultReaderClosedPromiseResolve } from './readable-stream/generic-reader';\nimport {\n  AcquireReadableStreamDefaultReader,\n  IsReadableStreamDefaultReader,\n  ReadableStreamDefaultReader,\n  ReadableStreamDefaultReaderErrorReadRequests,\n  type ReadableStreamDefaultReadResult\n} from './readable-stream/default-reader';\nimport {\n  AcquireReadableStreamBYOBReader,\n  IsReadableStreamBYOBReader,\n  ReadableStreamBYOBReader,\n  ReadableStreamBYOBReaderErrorReadIntoRequests,\n  type ReadableStreamBYOBReadResult\n} from './readable-stream/byob-reader';\nimport { ReadableStreamPipeTo } from './readable-stream/pipe';\nimport { ReadableStreamTee } from './readable-stream/tee';\nimport { ReadableStreamFrom } from './readable-stream/from';\nimport { IsWritableStream, IsWritableStreamLocked, WritableStream } from './writable-stream';\nimport { SimpleQueue } from './simple-queue';\nimport {\n  ReadableByteStreamController,\n  ReadableStreamBYOBRequest,\n  SetUpReadableByteStreamController,\n  SetUpReadableByteStreamControllerFromUnderlyingSource\n} from './readable-stream/byte-stream-controller';\nimport {\n  ReadableStreamDefaultController,\n  SetUpReadableStreamDefaultController,\n  SetUpReadableStreamDefaultControllerFromUnderlyingSource\n} from './readable-stream/default-controller';\nimport type {\n  UnderlyingByteSource,\n  UnderlyingByteSourcePullCallback,\n  UnderlyingByteSourceStartCallback,\n  UnderlyingSource,\n  UnderlyingSourceCancelCallback,\n  UnderlyingSourcePullCallback,\n  UnderlyingSourceStartCallback\n} from './readable-stream/underlying-source';\nimport { noop } from '../utils';\nimport { setFunctionName, typeIsObject } from './helpers/miscellaneous';\nimport { CreateArrayFromList, SymbolAsyncIterator } from './abstract-ops/ecmascript';\nimport { CancelSteps } from './abstract-ops/internal-methods';\nimport { IsNonNegativeNumber } from './abstract-ops/miscellaneous';\nimport { assertObject, assertRequiredArgument } from './validators/basic';\nimport { convertQueuingStrategy } from './validators/queuing-strategy';\nimport { ExtractHighWaterMark, ExtractSizeAlgorithm } from './abstract-ops/queuing-strategy';\nimport { convertUnderlyingDefaultOrByteSource } from './validators/underlying-source';\nimport type {\n  ReadableStreamBYOBReaderReadOptions,\n  ReadableStreamGetReaderOptions\n} from './readable-stream/reader-options';\nimport { convertReaderOptions } from './validators/reader-options';\nimport type { StreamPipeOptions, ValidatedStreamPipeOptions } from './readable-stream/pipe-options';\nimport type { ReadableStreamIteratorOptions } from './readable-stream/iterator-options';\nimport { convertIteratorOptions } from './validators/iterator-options';\nimport { convertPipeOptions } from './validators/pipe-options';\nimport type { ReadableWritablePair } from './readable-stream/readable-writable-pair';\nimport { convertReadableWritablePair } from './validators/readable-writable-pair';\nimport type { ReadableStreamDefaultReaderLike, ReadableStreamLike } from './readable-stream/readable-stream-like';\nimport type { NonShared } from './helpers/array-buffer-view';\n\nexport type DefaultReadableStream<R = any> = ReadableStream<R> & {\n  _readableStreamController: ReadableStreamDefaultController<R>\n};\n\nexport type ReadableByteStream = ReadableStream<NonShared<Uint8Array>> & {\n  _readableStreamController: ReadableByteStreamController\n};\n\ntype ReadableStreamState = 'readable' | 'closed' | 'errored';\n\n/**\n * A readable stream represents a source of data, from which you can read.\n *\n * @public\n */\nexport class ReadableStream<R = any> implements AsyncIterable<R> {\n  /** @internal */\n  _state!: ReadableStreamState;\n  /** @internal */\n  _reader: ReadableStreamReader<R> | undefined;\n  /** @internal */\n  _storedError: any;\n  /** @internal */\n  _disturbed!: boolean;\n  /** @internal */\n  _readableStreamController!: ReadableStreamDefaultController<R> | ReadableByteStreamController;\n\n  constructor(underlyingSource: UnderlyingByteSource, strategy?: { highWaterMark?: number; size?: undefined });\n  constructor(underlyingSource?: UnderlyingSource<R>, strategy?: QueuingStrategy<R>);\n  constructor(rawUnderlyingSource: UnderlyingSource<R> | UnderlyingByteSource | null | undefined = {},\n              rawStrategy: QueuingStrategy<R> | null | undefined = {}) {\n    if (rawUnderlyingSource === undefined) {\n      rawUnderlyingSource = null;\n    } else {\n      assertObject(rawUnderlyingSource, 'First parameter');\n    }\n\n    const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n    const underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n\n    InitializeReadableStream(this);\n\n    if (underlyingSource.type === 'bytes') {\n      if (strategy.size !== undefined) {\n        throw new RangeError('The strategy for a byte stream cannot have a size function');\n      }\n      const highWaterMark = ExtractHighWaterMark(strategy, 0);\n      SetUpReadableByteStreamControllerFromUnderlyingSource(\n        this as unknown as ReadableByteStream,\n        underlyingSource,\n        highWaterMark\n      );\n    } else {\n      assert(underlyingSource.type === undefined);\n      const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n      const highWaterMark = ExtractHighWaterMark(strategy, 1);\n      SetUpReadableStreamDefaultControllerFromUnderlyingSource(\n        this,\n        underlyingSource,\n        highWaterMark,\n        sizeAlgorithm\n      );\n    }\n  }\n\n  /**\n   * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n   */\n  get locked(): boolean {\n    if (!IsReadableStream(this)) {\n      throw streamBrandCheckException('locked');\n    }\n\n    return IsReadableStreamLocked(this);\n  }\n\n  /**\n   * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n   *\n   * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n   * method, which might or might not use it.\n   */\n  cancel(reason: any = undefined): Promise<void> {\n    if (!IsReadableStream(this)) {\n      return promiseRejectedWith(streamBrandCheckException('cancel'));\n    }\n\n    if (IsReadableStreamLocked(this)) {\n      return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n    }\n\n    return ReadableStreamCancel(this, reason);\n  }\n\n  /**\n   * Creates a {@link ReadableStreamBYOBReader} and locks the stream to the new reader.\n   *\n   * This call behaves the same way as the no-argument variant, except that it only works on readable byte streams,\n   * i.e. streams which were constructed specifically with the ability to handle \"bring your own buffer\" reading.\n   * The returned BYOB reader provides the ability to directly read individual chunks from the stream via its\n   * {@link ReadableStreamBYOBReader.read | read()} method, into developer-supplied buffers, allowing more precise\n   * control over allocation.\n   */\n  getReader({ mode }: { mode: 'byob' }): ReadableStreamBYOBReader;\n  /**\n   * Creates a {@link ReadableStreamDefaultReader} and locks the stream to the new reader.\n   * While the stream is locked, no other reader can be acquired until this one is released.\n   *\n   * This functionality is especially useful for creating abstractions that desire the ability to consume a stream\n   * in its entirety. By getting a reader for the stream, you can ensure nobody else can interleave reads with yours\n   * or cancel the stream, which would interfere with your abstraction.\n   */\n  getReader(): ReadableStreamDefaultReader<R>;\n  getReader(\n    rawOptions: ReadableStreamGetReaderOptions | null | undefined = undefined\n  ): ReadableStreamDefaultReader<R> | ReadableStreamBYOBReader {\n    if (!IsReadableStream(this)) {\n      throw streamBrandCheckException('getReader');\n    }\n\n    const options = convertReaderOptions(rawOptions, 'First parameter');\n\n    if (options.mode === undefined) {\n      return AcquireReadableStreamDefaultReader(this);\n    }\n\n    assert(options.mode === 'byob');\n    return AcquireReadableStreamBYOBReader(this as unknown as ReadableByteStream);\n  }\n\n  /**\n   * Provides a convenient, chainable way of piping this readable stream through a transform stream\n   * (or any other `{ writable, readable }` pair). It simply {@link ReadableStream.pipeTo | pipes} the stream\n   * into the writable side of the supplied pair, and returns the readable side for further use.\n   *\n   * Piping a stream will lock it for the duration of the pipe, preventing any other consumer from acquiring a reader.\n   */\n  pipeThrough<RS extends ReadableStream>(\n    transform: { readable: RS; writable: WritableStream<R> },\n    options?: StreamPipeOptions\n  ): RS;\n  pipeThrough<RS extends ReadableStream>(\n    rawTransform: { readable: RS; writable: WritableStream<R> } | null | undefined,\n    rawOptions: StreamPipeOptions | null | undefined = {}\n  ): RS {\n    if (!IsReadableStream(this)) {\n      throw streamBrandCheckException('pipeThrough');\n    }\n    assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n\n    const transform = convertReadableWritablePair(rawTransform, 'First parameter');\n    const options = convertPipeOptions(rawOptions, 'Second parameter');\n\n    if (IsReadableStreamLocked(this)) {\n      throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n    }\n    if (IsWritableStreamLocked(transform.writable)) {\n      throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n    }\n\n    const promise = ReadableStreamPipeTo(\n      this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal\n    );\n\n    setPromiseIsHandledToTrue(promise);\n\n    return transform.readable;\n  }\n\n  /**\n   * Pipes this readable stream to a given writable stream. The way in which the piping process behaves under\n   * various error conditions can be customized with a number of passed options. It returns a promise that fulfills\n   * when the piping process completes successfully, or rejects if any errors were encountered.\n   *\n   * Piping a stream will lock it for the duration of the pipe, preventing any other consumer from acquiring a reader.\n   */\n  pipeTo(destination: WritableStream<R>, options?: StreamPipeOptions): Promise<void>;\n  pipeTo(destination: WritableStream<R> | null | undefined,\n         rawOptions: StreamPipeOptions | null | undefined = {}): Promise<void> {\n    if (!IsReadableStream(this)) {\n      return promiseRejectedWith(streamBrandCheckException('pipeTo'));\n    }\n\n    if (destination === undefined) {\n      return promiseRejectedWith(`Parameter 1 is required in 'pipeTo'.`);\n    }\n    if (!IsWritableStream(destination)) {\n      return promiseRejectedWith(\n        new TypeError(`ReadableStream.prototype.pipeTo's first argument must be a WritableStream`)\n      );\n    }\n\n    let options: ValidatedStreamPipeOptions;\n    try {\n      options = convertPipeOptions(rawOptions, 'Second parameter');\n    } catch (e) {\n      return promiseRejectedWith(e);\n    }\n\n    if (IsReadableStreamLocked(this)) {\n      return promiseRejectedWith(\n        new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream')\n      );\n    }\n    if (IsWritableStreamLocked(destination)) {\n      return promiseRejectedWith(\n        new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream')\n      );\n    }\n\n    return ReadableStreamPipeTo<R>(\n      this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal\n    );\n  }\n\n  /**\n   * Tees this readable stream, returning a two-element array containing the two resulting branches as\n   * new {@link ReadableStream} instances.\n   *\n   * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n   * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n   * propagated to the stream's underlying source.\n   *\n   * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n   * this could allow interference between the two branches.\n   */\n  tee(): [ReadableStream<R>, ReadableStream<R>] {\n    if (!IsReadableStream(this)) {\n      throw streamBrandCheckException('tee');\n    }\n\n    const branches = ReadableStreamTee(this, false);\n    return CreateArrayFromList(branches);\n  }\n\n  /**\n   * Asynchronously iterates over the chunks in the stream's internal queue.\n   *\n   * Asynchronously iterating over the stream will lock it, preventing any other consumer from acquiring a reader.\n   * The lock will be released if the async iterator's {@link ReadableStreamAsyncIterator.return | return()} method\n   * is called, e.g. by breaking out of the loop.\n   *\n   * By default, calling the async iterator's {@link ReadableStreamAsyncIterator.return | return()} method will also\n   * cancel the stream. To prevent this, use the stream's {@link ReadableStream.values | values()} method, passing\n   * `true` for the `preventCancel` option.\n   */\n  values(options?: ReadableStreamIteratorOptions): ReadableStreamAsyncIterator<R>;\n  values(rawOptions: ReadableStreamIteratorOptions | null | undefined = undefined): ReadableStreamAsyncIterator<R> {\n    if (!IsReadableStream(this)) {\n      throw streamBrandCheckException('values');\n    }\n\n    const options = convertIteratorOptions(rawOptions, 'First parameter');\n    return AcquireReadableStreamAsyncIterator<R>(this, options.preventCancel);\n  }\n\n  /**\n   * {@inheritDoc ReadableStream.values}\n   */\n  [Symbol.asyncIterator](options?: ReadableStreamIteratorOptions): ReadableStreamAsyncIterator<R>;\n\n  [SymbolAsyncIterator](options?: ReadableStreamIteratorOptions): ReadableStreamAsyncIterator<R> {\n    // Stub implementation, overridden below\n    return this.values(options);\n  }\n\n  /**\n   * Creates a new ReadableStream wrapping the provided iterable or async iterable.\n   *\n   * This can be used to adapt various kinds of objects into a readable stream,\n   * such as an array, an async generator, or a Node.js readable stream.\n   */\n  static from<R>(asyncIterable: Iterable<R> | AsyncIterable<R> | ReadableStreamLike<R>): ReadableStream<R> {\n    return ReadableStreamFrom(asyncIterable);\n  }\n}\n\nObject.defineProperties(ReadableStream, {\n  from: { enumerable: true }\n});\nObject.defineProperties(ReadableStream.prototype, {\n  cancel: { enumerable: true },\n  getReader: { enumerable: true },\n  pipeThrough: { enumerable: true },\n  pipeTo: { enumerable: true },\n  tee: { enumerable: true },\n  values: { enumerable: true },\n  locked: { enumerable: true }\n});\nsetFunctionName(ReadableStream.from, 'from');\nsetFunctionName(ReadableStream.prototype.cancel, 'cancel');\nsetFunctionName(ReadableStream.prototype.getReader, 'getReader');\nsetFunctionName(ReadableStream.prototype.pipeThrough, 'pipeThrough');\nsetFunctionName(ReadableStream.prototype.pipeTo, 'pipeTo');\nsetFunctionName(ReadableStream.prototype.tee, 'tee');\nsetFunctionName(ReadableStream.prototype.values, 'values');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ReadableStream.prototype, Symbol.toStringTag, {\n    value: 'ReadableStream',\n    configurable: true\n  });\n}\nObject.defineProperty(ReadableStream.prototype, SymbolAsyncIterator, {\n  value: ReadableStream.prototype.values,\n  writable: true,\n  configurable: true\n});\n\nexport type {\n  ReadableStreamAsyncIterator,\n  ReadableStreamDefaultReadResult,\n  ReadableStreamBYOBReadResult,\n  ReadableStreamBYOBReaderReadOptions,\n  UnderlyingByteSource,\n  UnderlyingSource,\n  UnderlyingSourceStartCallback,\n  UnderlyingSourcePullCallback,\n  UnderlyingSourceCancelCallback,\n  UnderlyingByteSourceStartCallback,\n  UnderlyingByteSourcePullCallback,\n  StreamPipeOptions,\n  ReadableWritablePair,\n  ReadableStreamIteratorOptions,\n  ReadableStreamLike,\n  ReadableStreamDefaultReaderLike\n};\n\n// Abstract operations for the ReadableStream.\n\n// Throws if and only if startAlgorithm throws.\nexport function CreateReadableStream<R>(\n  startAlgorithm: () => void | PromiseLike<void>,\n  pullAlgorithm: () => Promise<void>,\n  cancelAlgorithm: (reason: any) => Promise<void>,\n  highWaterMark = 1,\n  sizeAlgorithm: QueuingStrategySizeCallback<R> = () => 1\n): DefaultReadableStream<R> {\n  assert(IsNonNegativeNumber(highWaterMark));\n\n  const stream: DefaultReadableStream<R> = Object.create(ReadableStream.prototype);\n  InitializeReadableStream(stream);\n\n  const controller: ReadableStreamDefaultController<R> = Object.create(ReadableStreamDefaultController.prototype);\n  SetUpReadableStreamDefaultController(\n    stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm\n  );\n\n  return stream;\n}\n\n// Throws if and only if startAlgorithm throws.\nexport function CreateReadableByteStream(\n  startAlgorithm: () => void | PromiseLike<void>,\n  pullAlgorithm: () => Promise<void>,\n  cancelAlgorithm: (reason: any) => Promise<void>\n): ReadableByteStream {\n  const stream: ReadableByteStream = Object.create(ReadableStream.prototype);\n  InitializeReadableStream(stream);\n\n  const controller: ReadableByteStreamController = Object.create(ReadableByteStreamController.prototype);\n  SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, 0, undefined);\n\n  return stream;\n}\n\nfunction InitializeReadableStream(stream: ReadableStream) {\n  stream._state = 'readable';\n  stream._reader = undefined;\n  stream._storedError = undefined;\n  stream._disturbed = false;\n}\n\nexport function IsReadableStream(x: unknown): x is ReadableStream {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n    return false;\n  }\n\n  return x instanceof ReadableStream;\n}\n\nexport function IsReadableStreamDisturbed(stream: ReadableStream): boolean {\n  assert(IsReadableStream(stream));\n\n  return stream._disturbed;\n}\n\nexport function IsReadableStreamLocked(stream: ReadableStream): boolean {\n  assert(IsReadableStream(stream));\n\n  if (stream._reader === undefined) {\n    return false;\n  }\n\n  return true;\n}\n\n// ReadableStream API exposed for controllers.\n\nexport function ReadableStreamCancel<R>(stream: ReadableStream<R>, reason: any): Promise<undefined> {\n  stream._disturbed = true;\n\n  if (stream._state === 'closed') {\n    return promiseResolvedWith(undefined);\n  }\n  if (stream._state === 'errored') {\n    return promiseRejectedWith(stream._storedError);\n  }\n\n  ReadableStreamClose(stream);\n\n  const reader = stream._reader;\n  if (reader !== undefined && IsReadableStreamBYOBReader(reader)) {\n    const readIntoRequests = reader._readIntoRequests;\n    reader._readIntoRequests = new SimpleQueue();\n    readIntoRequests.forEach(readIntoRequest => {\n      readIntoRequest._closeSteps(undefined);\n    });\n  }\n\n  const sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n  return transformPromiseWith(sourceCancelPromise, noop);\n}\n\nexport function ReadableStreamClose<R>(stream: ReadableStream<R>): void {\n  assert(stream._state === 'readable');\n\n  stream._state = 'closed';\n\n  const reader = stream._reader;\n\n  if (reader === undefined) {\n    return;\n  }\n\n  defaultReaderClosedPromiseResolve(reader);\n\n  if (IsReadableStreamDefaultReader<R>(reader)) {\n    const readRequests = reader._readRequests;\n    reader._readRequests = new SimpleQueue();\n    readRequests.forEach(readRequest => {\n      readRequest._closeSteps();\n    });\n  }\n}\n\nexport function ReadableStreamError<R>(stream: ReadableStream<R>, e: any): void {\n  assert(IsReadableStream(stream));\n  assert(stream._state === 'readable');\n\n  stream._state = 'errored';\n  stream._storedError = e;\n\n  const reader = stream._reader;\n\n  if (reader === undefined) {\n    return;\n  }\n\n  defaultReaderClosedPromiseReject(reader, e);\n\n  if (IsReadableStreamDefaultReader<R>(reader)) {\n    ReadableStreamDefaultReaderErrorReadRequests(reader, e);\n  } else {\n    assert(IsReadableStreamBYOBReader(reader));\n    ReadableStreamBYOBReaderErrorReadIntoRequests(reader, e);\n  }\n}\n\n// Readers\n\nexport type ReadableStreamReader<R> = ReadableStreamDefaultReader<R> | ReadableStreamBYOBReader;\n\nexport {\n  ReadableStreamDefaultReader,\n  ReadableStreamBYOBReader\n};\n\n// Controllers\n\nexport {\n  ReadableStreamDefaultController,\n  ReadableStreamBYOBRequest,\n  ReadableByteStreamController\n};\n\n// Helper functions for the ReadableStream.\n\nfunction streamBrandCheckException(name: string): TypeError {\n  return new TypeError(`ReadableStream.prototype.${name} can only be used on a ReadableStream`);\n}\n","import type { QueuingStrategyInit } from '../queuing-strategy';\nimport { assertDictionary, assertRequiredField, convertUnrestrictedDouble } from './basic';\n\nexport function convertQueuingStrategyInit(init: QueuingStrategyInit | null | undefined,\n                                           context: string): QueuingStrategyInit {\n  assertDictionary(init, context);\n  const highWaterMark = init?.highWaterMark;\n  assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n  return {\n    highWaterMark: convertUnrestrictedDouble(highWaterMark)\n  };\n}\n","import type { QueuingStrategy, QueuingStrategyInit } from './queuing-strategy';\nimport { setFunctionName, typeIsObject } from './helpers/miscellaneous';\nimport { assertRequiredArgument } from './validators/basic';\nimport { convertQueuingStrategyInit } from './validators/queuing-strategy-init';\n\n// The size function must not have a prototype property nor be a constructor\nconst byteLengthSizeFunction = (chunk: ArrayBufferView): number => {\n  return chunk.byteLength;\n};\nsetFunctionName(byteLengthSizeFunction, 'size');\n\n/**\n * A queuing strategy that counts the number of bytes in each chunk.\n *\n * @public\n */\nexport default class ByteLengthQueuingStrategy implements QueuingStrategy<ArrayBufferView> {\n  /** @internal */\n  readonly _byteLengthQueuingStrategyHighWaterMark: number;\n\n  constructor(options: QueuingStrategyInit) {\n    assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n    options = convertQueuingStrategyInit(options, 'First parameter');\n    this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n  }\n\n  /**\n   * Returns the high water mark provided to the constructor.\n   */\n  get highWaterMark(): number {\n    if (!IsByteLengthQueuingStrategy(this)) {\n      throw byteLengthBrandCheckException('highWaterMark');\n    }\n    return this._byteLengthQueuingStrategyHighWaterMark;\n  }\n\n  /**\n   * Measures the size of `chunk` by returning the value of its `byteLength` property.\n   */\n  get size(): (chunk: ArrayBufferView) => number {\n    if (!IsByteLengthQueuingStrategy(this)) {\n      throw byteLengthBrandCheckException('size');\n    }\n    return byteLengthSizeFunction;\n  }\n}\n\nObject.defineProperties(ByteLengthQueuingStrategy.prototype, {\n  highWaterMark: { enumerable: true },\n  size: { enumerable: true }\n});\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(ByteLengthQueuingStrategy.prototype, Symbol.toStringTag, {\n    value: 'ByteLengthQueuingStrategy',\n    configurable: true\n  });\n}\n\n// Helper functions for the ByteLengthQueuingStrategy.\n\nfunction byteLengthBrandCheckException(name: string): TypeError {\n  return new TypeError(`ByteLengthQueuingStrategy.prototype.${name} can only be used on a ByteLengthQueuingStrategy`);\n}\n\nexport function IsByteLengthQueuingStrategy(x: any): x is ByteLengthQueuingStrategy {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n    return false;\n  }\n\n  return x instanceof ByteLengthQueuingStrategy;\n}\n","import type { QueuingStrategy, QueuingStrategyInit } from './queuing-strategy';\nimport { setFunctionName, typeIsObject } from './helpers/miscellaneous';\nimport { assertRequiredArgument } from './validators/basic';\nimport { convertQueuingStrategyInit } from './validators/queuing-strategy-init';\n\n// The size function must not have a prototype property nor be a constructor\nconst countSizeFunction = (): 1 => {\n  return 1;\n};\nsetFunctionName(countSizeFunction, 'size');\n\n/**\n * A queuing strategy that counts the number of chunks.\n *\n * @public\n */\nexport default class CountQueuingStrategy implements QueuingStrategy<any> {\n  /** @internal */\n  readonly _countQueuingStrategyHighWaterMark!: number;\n\n  constructor(options: QueuingStrategyInit) {\n    assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n    options = convertQueuingStrategyInit(options, 'First parameter');\n    this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n  }\n\n  /**\n   * Returns the high water mark provided to the constructor.\n   */\n  get highWaterMark(): number {\n    if (!IsCountQueuingStrategy(this)) {\n      throw countBrandCheckException('highWaterMark');\n    }\n    return this._countQueuingStrategyHighWaterMark;\n  }\n\n  /**\n   * Measures the size of `chunk` by always returning 1.\n   * This ensures that the total queue size is a count of the number of chunks in the queue.\n   */\n  get size(): (chunk: any) => 1 {\n    if (!IsCountQueuingStrategy(this)) {\n      throw countBrandCheckException('size');\n    }\n    return countSizeFunction;\n  }\n}\n\nObject.defineProperties(CountQueuingStrategy.prototype, {\n  highWaterMark: { enumerable: true },\n  size: { enumerable: true }\n});\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(CountQueuingStrategy.prototype, Symbol.toStringTag, {\n    value: 'CountQueuingStrategy',\n    configurable: true\n  });\n}\n\n// Helper functions for the CountQueuingStrategy.\n\nfunction countBrandCheckException(name: string): TypeError {\n  return new TypeError(`CountQueuingStrategy.prototype.${name} can only be used on a CountQueuingStrategy`);\n}\n\nexport function IsCountQueuingStrategy(x: any): x is CountQueuingStrategy {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n    return false;\n  }\n\n  return x instanceof CountQueuingStrategy;\n}\n","import { assertDictionary, assertFunction } from './basic';\nimport { promiseCall, reflectCall } from '../helpers/webidl';\nimport type {\n  Transformer,\n  TransformerCancelCallback,\n  TransformerFlushCallback,\n  TransformerStartCallback,\n  TransformerTransformCallback,\n  ValidatedTransformer\n} from '../transform-stream/transformer';\nimport { TransformStreamDefaultController } from '../transform-stream';\n\nexport function convertTransformer<I, O>(original: Transformer<I, O> | null,\n                                         context: string): ValidatedTransformer<I, O> {\n  assertDictionary(original, context);\n  const cancel = original?.cancel;\n  const flush = original?.flush;\n  const readableType = original?.readableType;\n  const start = original?.start;\n  const transform = original?.transform;\n  const writableType = original?.writableType;\n  return {\n    cancel: cancel === undefined ?\n      undefined :\n      convertTransformerCancelCallback(cancel, original!, `${context} has member 'cancel' that`),\n    flush: flush === undefined ?\n      undefined :\n      convertTransformerFlushCallback(flush, original!, `${context} has member 'flush' that`),\n    readableType,\n    start: start === undefined ?\n      undefined :\n      convertTransformerStartCallback(start, original!, `${context} has member 'start' that`),\n    transform: transform === undefined ?\n      undefined :\n      convertTransformerTransformCallback(transform, original!, `${context} has member 'transform' that`),\n    writableType\n  };\n}\n\nfunction convertTransformerFlushCallback<I, O>(\n  fn: TransformerFlushCallback<O>,\n  original: Transformer<I, O>,\n  context: string\n): (controller: TransformStreamDefaultController<O>) => Promise<void> {\n  assertFunction(fn, context);\n  return (controller: TransformStreamDefaultController<O>) => promiseCall(fn, original, [controller]);\n}\n\nfunction convertTransformerStartCallback<I, O>(\n  fn: TransformerStartCallback<O>,\n  original: Transformer<I, O>,\n  context: string\n): TransformerStartCallback<O> {\n  assertFunction(fn, context);\n  return (controller: TransformStreamDefaultController<O>) => reflectCall(fn, original, [controller]);\n}\n\nfunction convertTransformerTransformCallback<I, O>(\n  fn: TransformerTransformCallback<I, O>,\n  original: Transformer<I, O>,\n  context: string\n): (chunk: I, controller: TransformStreamDefaultController<O>) => Promise<void> {\n  assertFunction(fn, context);\n  return (chunk: I, controller: TransformStreamDefaultController<O>) => promiseCall(fn, original, [chunk, controller]);\n}\n\nfunction convertTransformerCancelCallback<I, O>(\n  fn: TransformerCancelCallback,\n  original: Transformer<I, O>,\n  context: string\n): (reason: any) => Promise<void> {\n  assertFunction(fn, context);\n  return (reason: any) => promiseCall(fn, original, [reason]);\n}\n","import assert from '../stub/assert';\nimport {\n  newPromise,\n  promiseRejectedWith,\n  promiseResolvedWith,\n  setPromiseIsHandledToTrue,\n  transformPromiseWith,\n  uponPromise\n} from './helpers/webidl';\nimport { CreateReadableStream, type DefaultReadableStream, ReadableStream } from './readable-stream';\nimport {\n  ReadableStreamDefaultControllerCanCloseOrEnqueue,\n  ReadableStreamDefaultControllerClose,\n  ReadableStreamDefaultControllerEnqueue,\n  ReadableStreamDefaultControllerError,\n  ReadableStreamDefaultControllerGetDesiredSize,\n  ReadableStreamDefaultControllerHasBackpressure\n} from './readable-stream/default-controller';\nimport type { QueuingStrategy, QueuingStrategySizeCallback } from './queuing-strategy';\nimport { CreateWritableStream, WritableStream, WritableStreamDefaultControllerErrorIfNeeded } from './writable-stream';\nimport { setFunctionName, typeIsObject } from './helpers/miscellaneous';\nimport { IsNonNegativeNumber } from './abstract-ops/miscellaneous';\nimport { convertQueuingStrategy } from './validators/queuing-strategy';\nimport { ExtractHighWaterMark, ExtractSizeAlgorithm } from './abstract-ops/queuing-strategy';\nimport type {\n  Transformer,\n  TransformerCancelCallback,\n  TransformerFlushCallback,\n  TransformerStartCallback,\n  TransformerTransformCallback,\n  ValidatedTransformer\n} from './transform-stream/transformer';\nimport { convertTransformer } from './validators/transformer';\n\n// Class TransformStream\n\n/**\n * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n * made available for reading from the readable side.\n *\n * @public\n */\nexport class TransformStream<I = any, O = any> {\n  /** @internal */\n  _writable!: WritableStream<I>;\n  /** @internal */\n  _readable!: DefaultReadableStream<O>;\n  /** @internal */\n  _backpressure!: boolean;\n  /** @internal */\n  _backpressureChangePromise!: Promise<void>;\n  /** @internal */\n  _backpressureChangePromise_resolve!: () => void;\n  /** @internal */\n  _transformStreamController!: TransformStreamDefaultController<O>;\n\n  constructor(\n    transformer?: Transformer<I, O>,\n    writableStrategy?: QueuingStrategy<I>,\n    readableStrategy?: QueuingStrategy<O>\n  );\n  constructor(rawTransformer: Transformer<I, O> | null | undefined = {},\n              rawWritableStrategy: QueuingStrategy<I> | null | undefined = {},\n              rawReadableStrategy: QueuingStrategy<O> | null | undefined = {}) {\n    if (rawTransformer === undefined) {\n      rawTransformer = null;\n    }\n\n    const writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n    const readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n\n    const transformer = convertTransformer(rawTransformer, 'First parameter');\n    if (transformer.readableType !== undefined) {\n      throw new RangeError('Invalid readableType specified');\n    }\n    if (transformer.writableType !== undefined) {\n      throw new RangeError('Invalid writableType specified');\n    }\n\n    const readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n    const readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n    const writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n    const writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n\n    let startPromise_resolve!: (value: void | PromiseLike<void>) => void;\n    const startPromise = newPromise<void>(resolve => {\n      startPromise_resolve = resolve;\n    });\n\n    InitializeTransformStream(\n      this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm\n    );\n    SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n\n    if (transformer.start !== undefined) {\n      startPromise_resolve(transformer.start(this._transformStreamController));\n    } else {\n      startPromise_resolve(undefined);\n    }\n  }\n\n  /**\n   * The readable side of the transform stream.\n   */\n  get readable(): ReadableStream<O> {\n    if (!IsTransformStream(this)) {\n      throw streamBrandCheckException('readable');\n    }\n\n    return this._readable;\n  }\n\n  /**\n   * The writable side of the transform stream.\n   */\n  get writable(): WritableStream<I> {\n    if (!IsTransformStream(this)) {\n      throw streamBrandCheckException('writable');\n    }\n\n    return this._writable;\n  }\n}\n\nObject.defineProperties(TransformStream.prototype, {\n  readable: { enumerable: true },\n  writable: { enumerable: true }\n});\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(TransformStream.prototype, Symbol.toStringTag, {\n    value: 'TransformStream',\n    configurable: true\n  });\n}\n\nexport type {\n  Transformer,\n  TransformerCancelCallback,\n  TransformerStartCallback,\n  TransformerFlushCallback,\n  TransformerTransformCallback\n};\n\n// Transform Stream Abstract Operations\n\nexport function CreateTransformStream<I, O>(startAlgorithm: () => void | PromiseLike<void>,\n                                            transformAlgorithm: (chunk: I) => Promise<void>,\n                                            flushAlgorithm: () => Promise<void>,\n                                            cancelAlgorithm: (reason: any) => Promise<void>,\n                                            writableHighWaterMark = 1,\n                                            writableSizeAlgorithm: QueuingStrategySizeCallback<I> = () => 1,\n                                            readableHighWaterMark = 0,\n                                            readableSizeAlgorithm: QueuingStrategySizeCallback<O> = () => 1) {\n  assert(IsNonNegativeNumber(writableHighWaterMark));\n  assert(IsNonNegativeNumber(readableHighWaterMark));\n\n  const stream: TransformStream<I, O> = Object.create(TransformStream.prototype);\n\n  let startPromise_resolve!: (value: void | PromiseLike<void>) => void;\n  const startPromise = newPromise<void>(resolve => {\n    startPromise_resolve = resolve;\n  });\n\n  InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark,\n                            readableSizeAlgorithm);\n\n  const controller: TransformStreamDefaultController<O> = Object.create(TransformStreamDefaultController.prototype);\n\n  SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm, cancelAlgorithm);\n\n  const startResult = startAlgorithm();\n  startPromise_resolve(startResult);\n  return stream;\n}\n\nfunction InitializeTransformStream<I, O>(stream: TransformStream<I, O>,\n                                         startPromise: Promise<void>,\n                                         writableHighWaterMark: number,\n                                         writableSizeAlgorithm: QueuingStrategySizeCallback<I>,\n                                         readableHighWaterMark: number,\n                                         readableSizeAlgorithm: QueuingStrategySizeCallback<O>) {\n  function startAlgorithm(): Promise<void> {\n    return startPromise;\n  }\n\n  function writeAlgorithm(chunk: I): Promise<void> {\n    return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n  }\n\n  function abortAlgorithm(reason: any): Promise<void> {\n    return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n  }\n\n  function closeAlgorithm(): Promise<void> {\n    return TransformStreamDefaultSinkCloseAlgorithm(stream);\n  }\n\n  stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm,\n                                          writableHighWaterMark, writableSizeAlgorithm);\n\n  function pullAlgorithm(): Promise<void> {\n    return TransformStreamDefaultSourcePullAlgorithm(stream);\n  }\n\n  function cancelAlgorithm(reason: any): Promise<void> {\n    return TransformStreamDefaultSourceCancelAlgorithm(stream, reason);\n  }\n\n  stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark,\n                                          readableSizeAlgorithm);\n\n  // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n  stream._backpressure = undefined!;\n  stream._backpressureChangePromise = undefined!;\n  stream._backpressureChangePromise_resolve = undefined!;\n  TransformStreamSetBackpressure(stream, true);\n\n  stream._transformStreamController = undefined!;\n}\n\nfunction IsTransformStream(x: unknown): x is TransformStream {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n    return false;\n  }\n\n  return x instanceof TransformStream;\n}\n\n// This is a no-op if both sides are already errored.\nfunction TransformStreamError(stream: TransformStream, e: any) {\n  ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n  TransformStreamErrorWritableAndUnblockWrite(stream, e);\n}\n\nfunction TransformStreamErrorWritableAndUnblockWrite(stream: TransformStream, e: any) {\n  TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n  WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n  TransformStreamUnblockWrite(stream);\n}\n\nfunction TransformStreamUnblockWrite(stream: TransformStream) {\n  if (stream._backpressure) {\n    // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n    // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n    // _backpressure is set.\n    TransformStreamSetBackpressure(stream, false);\n  }\n}\n\nfunction TransformStreamSetBackpressure(stream: TransformStream, backpressure: boolean) {\n  // Passes also when called during construction.\n  assert(stream._backpressure !== backpressure);\n\n  if (stream._backpressureChangePromise !== undefined) {\n    stream._backpressureChangePromise_resolve();\n  }\n\n  stream._backpressureChangePromise = newPromise(resolve => {\n    stream._backpressureChangePromise_resolve = resolve;\n  });\n\n  stream._backpressure = backpressure;\n}\n\n// Class TransformStreamDefaultController\n\n/**\n * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n *\n * @public\n */\nexport class TransformStreamDefaultController<O> {\n  /** @internal */\n  _controlledTransformStream: TransformStream<any, O>;\n  /** @internal */\n  _finishPromise: Promise<undefined> | undefined;\n  /** @internal */\n  _finishPromise_resolve?: (value?: undefined) => void;\n  /** @internal */\n  _finishPromise_reject?: (reason: any) => void;\n  /** @internal */\n  _transformAlgorithm: (chunk: any) => Promise<void>;\n  /** @internal */\n  _flushAlgorithm: () => Promise<void>;\n  /** @internal */\n  _cancelAlgorithm: (reason: any) => Promise<void>;\n\n  private constructor() {\n    throw new TypeError('Illegal constructor');\n  }\n\n  /**\n   * Returns the desired size to fill the readable sides internal queue. It can be negative, if the queue is over-full.\n   */\n  get desiredSize(): number | null {\n    if (!IsTransformStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('desiredSize');\n    }\n\n    const readableController = this._controlledTransformStream._readable._readableStreamController;\n    return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n  }\n\n  /**\n   * Enqueues the given chunk `chunk` in the readable side of the controlled transform stream.\n   */\n  enqueue(chunk: O): void;\n  enqueue(chunk: O = undefined!): void {\n    if (!IsTransformStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('enqueue');\n    }\n\n    TransformStreamDefaultControllerEnqueue(this, chunk);\n  }\n\n  /**\n   * Errors both the readable side and the writable side of the controlled transform stream, making all future\n   * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n   */\n  error(reason: any = undefined): void {\n    if (!IsTransformStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('error');\n    }\n\n    TransformStreamDefaultControllerError(this, reason);\n  }\n\n  /**\n   * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n   * transformer only needs to consume a portion of the chunks written to the writable side.\n   */\n  terminate(): void {\n    if (!IsTransformStreamDefaultController(this)) {\n      throw defaultControllerBrandCheckException('terminate');\n    }\n\n    TransformStreamDefaultControllerTerminate(this);\n  }\n}\n\nObject.defineProperties(TransformStreamDefaultController.prototype, {\n  enqueue: { enumerable: true },\n  error: { enumerable: true },\n  terminate: { enumerable: true },\n  desiredSize: { enumerable: true }\n});\nsetFunctionName(TransformStreamDefaultController.prototype.enqueue, 'enqueue');\nsetFunctionName(TransformStreamDefaultController.prototype.error, 'error');\nsetFunctionName(TransformStreamDefaultController.prototype.terminate, 'terminate');\nif (typeof Symbol.toStringTag === 'symbol') {\n  Object.defineProperty(TransformStreamDefaultController.prototype, Symbol.toStringTag, {\n    value: 'TransformStreamDefaultController',\n    configurable: true\n  });\n}\n\n// Transform Stream Default Controller Abstract Operations\n\nfunction IsTransformStreamDefaultController<O = any>(x: any): x is TransformStreamDefaultController<O> {\n  if (!typeIsObject(x)) {\n    return false;\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n    return false;\n  }\n\n  return x instanceof TransformStreamDefaultController;\n}\n\nfunction SetUpTransformStreamDefaultController<I, O>(stream: TransformStream<I, O>,\n                                                     controller: TransformStreamDefaultController<O>,\n                                                     transformAlgorithm: (chunk: I) => Promise<void>,\n                                                     flushAlgorithm: () => Promise<void>,\n                                                     cancelAlgorithm: (reason: any) => Promise<void>) {\n  assert(IsTransformStream(stream));\n  assert(stream._transformStreamController === undefined);\n\n  controller._controlledTransformStream = stream;\n  stream._transformStreamController = controller;\n\n  controller._transformAlgorithm = transformAlgorithm;\n  controller._flushAlgorithm = flushAlgorithm;\n  controller._cancelAlgorithm = cancelAlgorithm;\n\n  controller._finishPromise = undefined;\n  controller._finishPromise_resolve = undefined;\n  controller._finishPromise_reject = undefined;\n}\n\nfunction SetUpTransformStreamDefaultControllerFromTransformer<I, O>(stream: TransformStream<I, O>,\n                                                                    transformer: ValidatedTransformer<I, O>) {\n  const controller: TransformStreamDefaultController<O> = Object.create(TransformStreamDefaultController.prototype);\n\n  let transformAlgorithm: (chunk: I) => Promise<void>;\n  let flushAlgorithm: () => Promise<void>;\n  let cancelAlgorithm: (reason: any) => Promise<void>;\n\n  if (transformer.transform !== undefined) {\n    transformAlgorithm = chunk => transformer.transform!(chunk, controller);\n  } else {\n    transformAlgorithm = chunk => {\n      try {\n        TransformStreamDefaultControllerEnqueue(controller, chunk as unknown as O);\n        return promiseResolvedWith(undefined);\n      } catch (transformResultE) {\n        return promiseRejectedWith(transformResultE);\n      }\n    };\n  }\n\n  if (transformer.flush !== undefined) {\n    flushAlgorithm = () => transformer.flush!(controller);\n  } else {\n    flushAlgorithm = () => promiseResolvedWith(undefined);\n  }\n\n  if (transformer.cancel !== undefined) {\n    cancelAlgorithm = reason => transformer.cancel!(reason);\n  } else {\n    cancelAlgorithm = () => promiseResolvedWith(undefined);\n  }\n\n  SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm, cancelAlgorithm);\n}\n\nfunction TransformStreamDefaultControllerClearAlgorithms(controller: TransformStreamDefaultController<any>) {\n  controller._transformAlgorithm = undefined!;\n  controller._flushAlgorithm = undefined!;\n  controller._cancelAlgorithm = undefined!;\n}\n\nfunction TransformStreamDefaultControllerEnqueue<O>(controller: TransformStreamDefaultController<O>, chunk: O) {\n  const stream = controller._controlledTransformStream;\n  const readableController = stream._readable._readableStreamController;\n  if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n    throw new TypeError('Readable side is not in a state that permits enqueue');\n  }\n\n  // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n  // accept TransformStreamDefaultControllerEnqueue() calls.\n\n  try {\n    ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n  } catch (e) {\n    // This happens when readableStrategy.size() throws.\n    TransformStreamErrorWritableAndUnblockWrite(stream, e);\n\n    throw stream._readable._storedError;\n  }\n\n  const backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n  if (backpressure !== stream._backpressure) {\n    assert(backpressure);\n    TransformStreamSetBackpressure(stream, true);\n  }\n}\n\nfunction TransformStreamDefaultControllerError(controller: TransformStreamDefaultController<any>, e: any) {\n  TransformStreamError(controller._controlledTransformStream, e);\n}\n\nfunction TransformStreamDefaultControllerPerformTransform<I, O>(controller: TransformStreamDefaultController<O>,\n                                                                chunk: I) {\n  const transformPromise = controller._transformAlgorithm(chunk);\n  return transformPromiseWith(transformPromise, undefined, r => {\n    TransformStreamError(controller._controlledTransformStream, r);\n    throw r;\n  });\n}\n\nfunction TransformStreamDefaultControllerTerminate<O>(controller: TransformStreamDefaultController<O>) {\n  const stream = controller._controlledTransformStream;\n  const readableController = stream._readable._readableStreamController;\n\n  ReadableStreamDefaultControllerClose(readableController);\n\n  const error = new TypeError('TransformStream terminated');\n  TransformStreamErrorWritableAndUnblockWrite(stream, error);\n}\n\n// TransformStreamDefaultSink Algorithms\n\nfunction TransformStreamDefaultSinkWriteAlgorithm<I, O>(stream: TransformStream<I, O>, chunk: I): Promise<void> {\n  assert(stream._writable._state === 'writable');\n\n  const controller = stream._transformStreamController;\n\n  if (stream._backpressure) {\n    const backpressureChangePromise = stream._backpressureChangePromise;\n    assert(backpressureChangePromise !== undefined);\n    return transformPromiseWith(backpressureChangePromise, () => {\n      const writable = stream._writable;\n      const state = writable._state;\n      if (state === 'erroring') {\n        throw writable._storedError;\n      }\n      assert(state === 'writable');\n      return TransformStreamDefaultControllerPerformTransform<I, O>(controller, chunk);\n    });\n  }\n\n  return TransformStreamDefaultControllerPerformTransform<I, O>(controller, chunk);\n}\n\nfunction TransformStreamDefaultSinkAbortAlgorithm<I, O>(stream: TransformStream<I, O>, reason: any): Promise<void> {\n  const controller = stream._transformStreamController;\n  if (controller._finishPromise !== undefined) {\n    return controller._finishPromise;\n  }\n\n  // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n  const readable = stream._readable;\n\n  // Assign the _finishPromise now so that if _cancelAlgorithm calls readable.cancel() internally,\n  // we don't run the _cancelAlgorithm again.\n  controller._finishPromise = newPromise((resolve, reject) => {\n    controller._finishPromise_resolve = resolve;\n    controller._finishPromise_reject = reject;\n  });\n\n  const cancelPromise = controller._cancelAlgorithm(reason);\n  TransformStreamDefaultControllerClearAlgorithms(controller);\n\n  uponPromise(cancelPromise, () => {\n    if (readable._state === 'errored') {\n      defaultControllerFinishPromiseReject(controller, readable._storedError);\n    } else {\n      ReadableStreamDefaultControllerError(readable._readableStreamController, reason);\n      defaultControllerFinishPromiseResolve(controller);\n    }\n    return null;\n  }, r => {\n    ReadableStreamDefaultControllerError(readable._readableStreamController, r);\n    defaultControllerFinishPromiseReject(controller, r);\n    return null;\n  });\n\n  return controller._finishPromise;\n}\n\nfunction TransformStreamDefaultSinkCloseAlgorithm<I, O>(stream: TransformStream<I, O>): Promise<void> {\n  const controller = stream._transformStreamController;\n  if (controller._finishPromise !== undefined) {\n    return controller._finishPromise;\n  }\n\n  // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n  const readable = stream._readable;\n\n  // Assign the _finishPromise now so that if _flushAlgorithm calls readable.cancel() internally,\n  // we don't also run the _cancelAlgorithm.\n  controller._finishPromise = newPromise((resolve, reject) => {\n    controller._finishPromise_resolve = resolve;\n    controller._finishPromise_reject = reject;\n  });\n\n  const flushPromise = controller._flushAlgorithm();\n  TransformStreamDefaultControllerClearAlgorithms(controller);\n\n  uponPromise(flushPromise, () => {\n    if (readable._state === 'errored') {\n      defaultControllerFinishPromiseReject(controller, readable._storedError);\n    } else {\n      ReadableStreamDefaultControllerClose(readable._readableStreamController);\n      defaultControllerFinishPromiseResolve(controller);\n    }\n    return null;\n  }, r => {\n    ReadableStreamDefaultControllerError(readable._readableStreamController, r);\n    defaultControllerFinishPromiseReject(controller, r);\n    return null;\n  });\n\n  return controller._finishPromise;\n}\n\n// TransformStreamDefaultSource Algorithms\n\nfunction TransformStreamDefaultSourcePullAlgorithm(stream: TransformStream): Promise<void> {\n  // Invariant. Enforced by the promises returned by start() and pull().\n  assert(stream._backpressure);\n\n  assert(stream._backpressureChangePromise !== undefined);\n\n  TransformStreamSetBackpressure(stream, false);\n\n  // Prevent the next pull() call until there is backpressure.\n  return stream._backpressureChangePromise;\n}\n\nfunction TransformStreamDefaultSourceCancelAlgorithm<I, O>(stream: TransformStream<I, O>, reason: any): Promise<void> {\n  const controller = stream._transformStreamController;\n  if (controller._finishPromise !== undefined) {\n    return controller._finishPromise;\n  }\n\n  // stream._writable cannot change after construction, so caching it across a call to user code is safe.\n  const writable = stream._writable;\n\n  // Assign the _finishPromise now so that if _flushAlgorithm calls writable.abort() or\n  // writable.cancel() internally, we don't run the _cancelAlgorithm again, or also run the\n  // _flushAlgorithm.\n  controller._finishPromise = newPromise((resolve, reject) => {\n    controller._finishPromise_resolve = resolve;\n    controller._finishPromise_reject = reject;\n  });\n\n  const cancelPromise = controller._cancelAlgorithm(reason);\n  TransformStreamDefaultControllerClearAlgorithms(controller);\n\n  uponPromise(cancelPromise, () => {\n    if (writable._state === 'errored') {\n      defaultControllerFinishPromiseReject(controller, writable._storedError);\n    } else {\n      WritableStreamDefaultControllerErrorIfNeeded(writable._writableStreamController, reason);\n      TransformStreamUnblockWrite(stream);\n      defaultControllerFinishPromiseResolve(controller);\n    }\n    return null;\n  }, r => {\n    WritableStreamDefaultControllerErrorIfNeeded(writable._writableStreamController, r);\n    TransformStreamUnblockWrite(stream);\n    defaultControllerFinishPromiseReject(controller, r);\n    return null;\n  });\n\n  return controller._finishPromise;\n}\n\n// Helper functions for the TransformStreamDefaultController.\n\nfunction defaultControllerBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `TransformStreamDefaultController.prototype.${name} can only be used on a TransformStreamDefaultController`);\n}\n\nexport function defaultControllerFinishPromiseResolve(controller: TransformStreamDefaultController<any>) {\n  if (controller._finishPromise_resolve === undefined) {\n    return;\n  }\n\n  controller._finishPromise_resolve();\n  controller._finishPromise_resolve = undefined;\n  controller._finishPromise_reject = undefined;\n}\n\nexport function defaultControllerFinishPromiseReject(controller: TransformStreamDefaultController<any>, reason: any) {\n  if (controller._finishPromise_reject === undefined) {\n    return;\n  }\n\n  setPromiseIsHandledToTrue(controller._finishPromise!);\n  controller._finishPromise_reject(reason);\n  controller._finishPromise_resolve = undefined;\n  controller._finishPromise_reject = undefined;\n}\n\n// Helper functions for the TransformStream.\n\nfunction streamBrandCheckException(name: string): TypeError {\n  return new TypeError(\n    `TransformStream.prototype.${name} can only be used on a TransformStream`);\n}\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport { type RequestOptions } from '../core';\n\nexport interface Shims {\n  kind: string;\n  fetch: any;\n  Request: any;\n  Response: any;\n  Headers: any;\n  FormData: any;\n  Blob: any;\n  File: any;\n  ReadableStream: any;\n  getMultipartRequestOptions: <T = Record<string, unknown>>(\n    form: Shims['FormData'],\n    opts: RequestOptions<T>,\n  ) => Promise<RequestOptions<T>>;\n  getDefaultAgent: (url: string) => any;\n  fileFromPath:\n    | ((path: string, filename?: string, options?: {}) => Promise<Shims['File']>)\n    | ((path: string, options?: {}) => Promise<Shims['File']>);\n  isFsReadStream: (value: any) => boolean;\n}\n\nexport let auto = false;\nexport let kind: Shims['kind'] | undefined = undefined;\nexport let fetch: Shims['fetch'] | undefined = undefined;\nexport let Request: Shims['Request'] | undefined = undefined;\nexport let Response: Shims['Response'] | undefined = undefined;\nexport let Headers: Shims['Headers'] | undefined = undefined;\nexport let FormData: Shims['FormData'] | undefined = undefined;\nexport let Blob: Shims['Blob'] | undefined = undefined;\nexport let File: Shims['File'] | undefined = undefined;\nexport let ReadableStream: Shims['ReadableStream'] | undefined = undefined;\nexport let getMultipartRequestOptions: Shims['getMultipartRequestOptions'] | undefined = undefined;\nexport let getDefaultAgent: Shims['getDefaultAgent'] | undefined = undefined;\nexport let fileFromPath: Shims['fileFromPath'] | undefined = undefined;\nexport let isFsReadStream: Shims['isFsReadStream'] | undefined = undefined;\n\nexport function setShims(shims: Shims, options: { auto: boolean } = { auto: false }) {\n  if (auto) {\n    throw new Error(\n      `you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`,\n    );\n  }\n  if (kind) {\n    throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\n  }\n  auto = options.auto;\n  kind = shims.kind;\n  fetch = shims.fetch;\n  Request = shims.Request;\n  Response = shims.Response;\n  Headers = shims.Headers;\n  FormData = shims.FormData;\n  Blob = shims.Blob;\n  File = shims.File;\n  ReadableStream = shims.ReadableStream;\n  getMultipartRequestOptions = shims.getMultipartRequestOptions;\n  getDefaultAgent = shims.getDefaultAgent;\n  fileFromPath = shims.fileFromPath;\n  isFsReadStream = shims.isFsReadStream;\n}\n","var __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _FormData_instances, _FormData_entries, _FormData_setEntry;\nimport { inspect } from \"util\";\nimport { File } from \"./File.js\";\nimport { isFile } from \"./isFile.js\";\nimport { isBlob } from \"./isBlob.js\";\nimport { isFunction } from \"./isFunction.js\";\nimport { deprecateConstructorEntries } from \"./deprecateConstructorEntries.js\";\nexport class FormData {\n    constructor(entries) {\n        _FormData_instances.add(this);\n        _FormData_entries.set(this, new Map());\n        if (entries) {\n            deprecateConstructorEntries();\n            entries.forEach(({ name, value, fileName }) => this.append(name, value, fileName));\n        }\n    }\n    static [(_FormData_entries = new WeakMap(), _FormData_instances = new WeakSet(), Symbol.hasInstance)](value) {\n        return Boolean(value\n            && isFunction(value.constructor)\n            && value[Symbol.toStringTag] === \"FormData\"\n            && isFunction(value.append)\n            && isFunction(value.set)\n            && isFunction(value.get)\n            && isFunction(value.getAll)\n            && isFunction(value.has)\n            && isFunction(value.delete)\n            && isFunction(value.entries)\n            && isFunction(value.values)\n            && isFunction(value.keys)\n            && isFunction(value[Symbol.iterator])\n            && isFunction(value.forEach));\n    }\n    append(name, value, fileName) {\n        __classPrivateFieldGet(this, _FormData_instances, \"m\", _FormData_setEntry).call(this, {\n            name,\n            fileName,\n            append: true,\n            rawValue: value,\n            argsLength: arguments.length\n        });\n    }\n    set(name, value, fileName) {\n        __classPrivateFieldGet(this, _FormData_instances, \"m\", _FormData_setEntry).call(this, {\n            name,\n            fileName,\n            append: false,\n            rawValue: value,\n            argsLength: arguments.length\n        });\n    }\n    get(name) {\n        const field = __classPrivateFieldGet(this, _FormData_entries, \"f\").get(String(name));\n        if (!field) {\n            return null;\n        }\n        return field[0];\n    }\n    getAll(name) {\n        const field = __classPrivateFieldGet(this, _FormData_entries, \"f\").get(String(name));\n        if (!field) {\n            return [];\n        }\n        return field.slice();\n    }\n    has(name) {\n        return __classPrivateFieldGet(this, _FormData_entries, \"f\").has(String(name));\n    }\n    delete(name) {\n        __classPrivateFieldGet(this, _FormData_entries, \"f\").delete(String(name));\n    }\n    *keys() {\n        for (const key of __classPrivateFieldGet(this, _FormData_entries, \"f\").keys()) {\n            yield key;\n        }\n    }\n    *entries() {\n        for (const name of this.keys()) {\n            const values = this.getAll(name);\n            for (const value of values) {\n                yield [name, value];\n            }\n        }\n    }\n    *values() {\n        for (const [, value] of this) {\n            yield value;\n        }\n    }\n    [(_FormData_setEntry = function _FormData_setEntry({ name, rawValue, append, fileName, argsLength }) {\n        const methodName = append ? \"append\" : \"set\";\n        if (argsLength < 2) {\n            throw new TypeError(`Failed to execute '${methodName}' on 'FormData': `\n                + `2 arguments required, but only ${argsLength} present.`);\n        }\n        name = String(name);\n        let value;\n        if (isFile(rawValue)) {\n            value = fileName === undefined\n                ? rawValue\n                : new File([rawValue], fileName, {\n                    type: rawValue.type,\n                    lastModified: rawValue.lastModified\n                });\n        }\n        else if (isBlob(rawValue)) {\n            value = new File([rawValue], fileName === undefined ? \"blob\" : fileName, {\n                type: rawValue.type\n            });\n        }\n        else if (fileName) {\n            throw new TypeError(`Failed to execute '${methodName}' on 'FormData': `\n                + \"parameter 2 is not of type 'Blob'.\");\n        }\n        else {\n            value = String(rawValue);\n        }\n        const values = __classPrivateFieldGet(this, _FormData_entries, \"f\").get(name);\n        if (!values) {\n            return void __classPrivateFieldGet(this, _FormData_entries, \"f\").set(name, [value]);\n        }\n        if (!append) {\n            return void __classPrivateFieldGet(this, _FormData_entries, \"f\").set(name, [value]);\n        }\n        values.push(value);\n    }, Symbol.iterator)]() {\n        return this.entries();\n    }\n    forEach(callback, thisArg) {\n        for (const [name, value] of this) {\n            callback.call(thisArg, value, name, this);\n        }\n    }\n    get [Symbol.toStringTag]() {\n        return \"FormData\";\n    }\n    [inspect.custom]() {\n        return this[Symbol.toStringTag];\n    }\n}\n","import { Blob } from \"./Blob.js\";\nexport const isBlob = (value) => value instanceof Blob;\n","import { deprecate } from \"util\";\nexport const deprecateConstructorEntries = deprecate(() => { }, \"Constructor \\\"entries\\\" argument is not spec-compliant \"\n    + \"and will be removed in next major release.\");\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as nf from 'node-fetch';\nimport * as fd from 'formdata-node';\nimport { type File, type FilePropertyBag } from 'formdata-node';\nimport KeepAliveAgent from 'agentkeepalive';\nimport { AbortController as AbortControllerPolyfill } from 'abort-controller';\nimport { ReadStream as FsReadStream } from 'node:fs';\nimport { type Agent } from 'node:http';\nimport { FormDataEncoder } from 'form-data-encoder';\nimport { Readable } from 'node:stream';\nimport { type RequestOptions } from '../core';\nimport { MultipartBody } from './MultipartBody';\nimport { type Shims } from './registry';\n\n// @ts-ignore (this package does not have proper export maps for this export)\nimport { ReadableStream } from 'web-streams-polyfill/dist/ponyfill.es2018.js';\n\ntype FileFromPathOptions = Omit<FilePropertyBag, 'lastModified'>;\n\nlet fileFromPathWarned = false;\n\n/**\n * @deprecated use fs.createReadStream('./my/file.txt') instead\n */\nasync function fileFromPath(path: string): Promise<File>;\nasync function fileFromPath(path: string, filename?: string): Promise<File>;\nasync function fileFromPath(path: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, filename?: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, ...args: any[]): Promise<File> {\n  // this import fails in environments that don't handle export maps correctly, like old versions of Jest\n  const { fileFromPath: _fileFromPath } = await import('formdata-node/file-from-path');\n\n  if (!fileFromPathWarned) {\n    console.warn(`fileFromPath is deprecated; use fs.createReadStream(${JSON.stringify(path)}) instead`);\n    fileFromPathWarned = true;\n  }\n  // @ts-ignore\n  return await _fileFromPath(path, ...args);\n}\n\nconst defaultHttpAgent: Agent = new KeepAliveAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\nconst defaultHttpsAgent: Agent = new KeepAliveAgent.HttpsAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\n\nasync function getMultipartRequestOptions<T = Record<string, unknown>>(\n  form: fd.FormData,\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T>> {\n  const encoder = new FormDataEncoder(form);\n  const readable = Readable.from(encoder);\n  const body = new MultipartBody(readable);\n  const headers = {\n    ...opts.headers,\n    ...encoder.headers,\n    'Content-Length': encoder.contentLength,\n  };\n\n  return { ...opts, body: body as any, headers };\n}\n\nexport function getRuntime(): Shims {\n  // Polyfill global object if needed.\n  if (typeof AbortController === 'undefined') {\n    // @ts-expect-error (the types are subtly different, but compatible in practice)\n    globalThis.AbortController = AbortControllerPolyfill;\n  }\n  return {\n    kind: 'node',\n    fetch: nf.default,\n    Request: nf.Request,\n    Response: nf.Response,\n    Headers: nf.Headers,\n    FormData: fd.FormData,\n    Blob: fd.Blob,\n    File: fd.File,\n    ReadableStream,\n    getMultipartRequestOptions,\n    getDefaultAgent: (url: string): Agent => (url.startsWith('https') ? defaultHttpsAgent : defaultHttpAgent),\n    fileFromPath,\n    isFsReadStream: (value: any): value is FsReadStream => value instanceof FsReadStream,\n  };\n}\n","const alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\";\nfunction createBoundary() {\n    let size = 16;\n    let res = \"\";\n    while (size--) {\n        res += alphabet[(Math.random() * alphabet.length) << 0];\n    }\n    return res;\n}\nexport default createBoundary;\n","const getType = (value) => (Object.prototype.toString.call(value).slice(8, -1).toLowerCase());\nfunction isPlainObject(value) {\n    if (getType(value) !== \"object\") {\n        return false;\n    }\n    const pp = Object.getPrototypeOf(value);\n    if (pp === null || pp === undefined) {\n        return true;\n    }\n    const Ctor = pp.constructor && pp.constructor.toString();\n    return Ctor === Object.toString();\n}\nexport default isPlainObject;\n","const normalizeValue = (value) => String(value)\n    .replace(/\\r|\\n/g, (match, i, str) => {\n    if ((match === \"\\r\" && str[i + 1] !== \"\\n\")\n        || (match === \"\\n\" && str[i - 1] !== \"\\r\")) {\n        return \"\\r\\n\";\n    }\n    return match;\n});\nexport default normalizeValue;\n","const escapeName = (name) => String(name)\n    .replace(/\\r/g, \"%0D\")\n    .replace(/\\n/g, \"%0A\")\n    .replace(/\"/g, \"%22\");\nexport default escapeName;\n","const isFunction = (value) => (typeof value === \"function\");\nexport default isFunction;\n","import isFunction from \"./isFunction.js\";\nexport const isFileLike = (value) => Boolean(value\n    && typeof value === \"object\"\n    && isFunction(value.constructor)\n    && value[Symbol.toStringTag] === \"File\"\n    && isFunction(value.stream)\n    && value.name != null\n    && value.size != null\n    && value.lastModified != null);\n","import isFunction from \"./isFunction.js\";\nexport const isFormData = (value) => Boolean(value\n    && isFunction(value.constructor)\n    && value[Symbol.toStringTag] === \"FormData\"\n    && isFunction(value.append)\n    && isFunction(value.getAll)\n    && isFunction(value.entries)\n    && isFunction(value[Symbol.iterator]));\nexport const isFormDataLike = isFormData;\n","var __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _FormDataEncoder_instances, _FormDataEncoder_CRLF, _FormDataEncoder_CRLF_BYTES, _FormDataEncoder_CRLF_BYTES_LENGTH, _FormDataEncoder_DASHES, _FormDataEncoder_encoder, _FormDataEncoder_footer, _FormDataEncoder_form, _FormDataEncoder_options, _FormDataEncoder_getFieldHeader;\nimport createBoundary from \"./util/createBoundary.js\";\nimport isPlainObject from \"./util/isPlainObject.js\";\nimport normalize from \"./util/normalizeValue.js\";\nimport escape from \"./util/escapeName.js\";\nimport { isFileLike } from \"./util/isFileLike.js\";\nimport { isFormData } from \"./util/isFormData.js\";\nconst defaultOptions = {\n    enableAdditionalHeaders: false\n};\nexport class FormDataEncoder {\n    constructor(form, boundaryOrOptions, options) {\n        _FormDataEncoder_instances.add(this);\n        _FormDataEncoder_CRLF.set(this, \"\\r\\n\");\n        _FormDataEncoder_CRLF_BYTES.set(this, void 0);\n        _FormDataEncoder_CRLF_BYTES_LENGTH.set(this, void 0);\n        _FormDataEncoder_DASHES.set(this, \"-\".repeat(2));\n        _FormDataEncoder_encoder.set(this, new TextEncoder());\n        _FormDataEncoder_footer.set(this, void 0);\n        _FormDataEncoder_form.set(this, void 0);\n        _FormDataEncoder_options.set(this, void 0);\n        if (!isFormData(form)) {\n            throw new TypeError(\"Expected first argument to be a FormData instance.\");\n        }\n        let boundary;\n        if (isPlainObject(boundaryOrOptions)) {\n            options = boundaryOrOptions;\n        }\n        else {\n            boundary = boundaryOrOptions;\n        }\n        if (!boundary) {\n            boundary = createBoundary();\n        }\n        if (typeof boundary !== \"string\") {\n            throw new TypeError(\"Expected boundary argument to be a string.\");\n        }\n        if (options && !isPlainObject(options)) {\n            throw new TypeError(\"Expected options argument to be an object.\");\n        }\n        __classPrivateFieldSet(this, _FormDataEncoder_form, form, \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_options, { ...defaultOptions, ...options }, \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_CRLF_BYTES, __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")), \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_CRLF_BYTES_LENGTH, __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES, \"f\").byteLength, \"f\");\n        this.boundary = `form-data-boundary-${boundary}`;\n        this.contentType = `multipart/form-data; boundary=${this.boundary}`;\n        __classPrivateFieldSet(this, _FormDataEncoder_footer, __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(`${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${this.boundary}${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\").repeat(2)}`), \"f\");\n        this.contentLength = String(this.getContentLength());\n        this.headers = Object.freeze({\n            \"Content-Type\": this.contentType,\n            \"Content-Length\": this.contentLength\n        });\n        Object.defineProperties(this, {\n            boundary: { writable: false, configurable: false },\n            contentType: { writable: false, configurable: false },\n            contentLength: { writable: false, configurable: false },\n            headers: { writable: false, configurable: false }\n        });\n    }\n    getContentLength() {\n        let length = 0;\n        for (const [name, raw] of __classPrivateFieldGet(this, _FormDataEncoder_form, \"f\")) {\n            const value = isFileLike(raw) ? raw : __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(normalize(raw));\n            length += __classPrivateFieldGet(this, _FormDataEncoder_instances, \"m\", _FormDataEncoder_getFieldHeader).call(this, name, value).byteLength;\n            length += isFileLike(value) ? value.size : value.byteLength;\n            length += __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES_LENGTH, \"f\");\n        }\n        return length + __classPrivateFieldGet(this, _FormDataEncoder_footer, \"f\").byteLength;\n    }\n    *values() {\n        for (const [name, raw] of __classPrivateFieldGet(this, _FormDataEncoder_form, \"f\").entries()) {\n            const value = isFileLike(raw) ? raw : __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(normalize(raw));\n            yield __classPrivateFieldGet(this, _FormDataEncoder_instances, \"m\", _FormDataEncoder_getFieldHeader).call(this, name, value);\n            yield value;\n            yield __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES, \"f\");\n        }\n        yield __classPrivateFieldGet(this, _FormDataEncoder_footer, \"f\");\n    }\n    async *encode() {\n        for (const part of this.values()) {\n            if (isFileLike(part)) {\n                yield* part.stream();\n            }\n            else {\n                yield part;\n            }\n        }\n    }\n    [(_FormDataEncoder_CRLF = new WeakMap(), _FormDataEncoder_CRLF_BYTES = new WeakMap(), _FormDataEncoder_CRLF_BYTES_LENGTH = new WeakMap(), _FormDataEncoder_DASHES = new WeakMap(), _FormDataEncoder_encoder = new WeakMap(), _FormDataEncoder_footer = new WeakMap(), _FormDataEncoder_form = new WeakMap(), _FormDataEncoder_options = new WeakMap(), _FormDataEncoder_instances = new WeakSet(), _FormDataEncoder_getFieldHeader = function _FormDataEncoder_getFieldHeader(name, value) {\n        let header = \"\";\n        header += `${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${this.boundary}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}`;\n        header += `Content-Disposition: form-data; name=\"${escape(name)}\"`;\n        if (isFileLike(value)) {\n            header += `; filename=\"${escape(value.name)}\"${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}`;\n            header += `Content-Type: ${value.type || \"application/octet-stream\"}`;\n        }\n        if (__classPrivateFieldGet(this, _FormDataEncoder_options, \"f\").enableAdditionalHeaders === true) {\n            header += `${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}Content-Length: ${isFileLike(value) ? value.size : value.byteLength}`;\n        }\n        return __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(`${header}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\").repeat(2)}`);\n    }, Symbol.iterator)]() {\n        return this.values();\n    }\n    [Symbol.asyncIterator]() {\n        return this.encode();\n    }\n}\nexport const Encoder = FormDataEncoder;\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nexport class MultipartBody {\n  constructor(public body: any) {}\n  get [Symbol.toStringTag](): string {\n    return 'MultipartBody';\n  }\n}\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as shims from './registry.mjs';\nimport * as auto from 'openai/_shims/auto/runtime';\nif (!shims.kind) shims.setShims(auto.getRuntime(), { auto: true });\nexport * from './registry.mjs';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError, Headers } from './core';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError extends OpenAIError {\n  readonly status: number | undefined;\n  readonly headers: Headers | undefined;\n  readonly error: Object | undefined;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly request_id: string | null | undefined;\n\n  constructor(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.request_id = headers?.['x-request-id'];\n\n    const data = error as Record<string, any>;\n    this.error = data;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    if (!status) {\n      return new APIConnectionError({ cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message, cause }: { message?: string; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError {\n  override readonly status: 400 = 400;\n}\n\nexport class AuthenticationError extends APIError {\n  override readonly status: 401 = 401;\n}\n\nexport class PermissionDeniedError extends APIError {\n  override readonly status: 403 = 403;\n}\n\nexport class NotFoundError extends APIError {\n  override readonly status: 404 = 404;\n}\n\nexport class ConflictError extends APIError {\n  override readonly status: 409 = 409;\n}\n\nexport class UnprocessableEntityError extends APIError {\n  override readonly status: 422 = 422;\n}\n\nexport class RateLimitError extends APIError {\n  override readonly status: 429 = 429;\n}\n\nexport class InternalServerError extends APIError {}\n","import { ReadableStream, type Response } from './_shims/index';\nimport { OpenAIError } from './error';\n\nimport { APIError } from \"./error\";\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n  ) {\n    this.controller = controller;\n  }\n\n  static fromSSEResponse<Item>(response: Response, controller: AbortController) {\n    let consumed = false;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, undefined);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(readableStream: ReadableStream, controller: AbortController) {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = readableStreamAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller),\n      new Stream(() => teeIterator(right), this.controller),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n    const encoder = new TextEncoder();\n\n    return new ReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = readableStreamAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nfunction findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 2; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nclass LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  buffer: string[];\n  trailingCR: boolean;\n  textDecoder: any; // TextDecoder found in browsers; not typed to avoid pulling in either \"dom\" or \"node\" types.\n\n  constructor() {\n    this.buffer = [];\n    this.trailingCR = false;\n  }\n\n  decode(chunk: Bytes): string[] {\n    let text = this.decodeText(chunk);\n\n    if (this.trailingCR) {\n      text = '\\r' + text;\n      this.trailingCR = false;\n    }\n    if (text.endsWith('\\r')) {\n      this.trailingCR = true;\n      text = text.slice(0, -1);\n    }\n\n    if (!text) {\n      return [];\n    }\n\n    const trailingNewline = LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || '');\n    let lines = text.split(LineDecoder.NEWLINE_REGEXP);\n\n    // if there is a trailing new line then the last entry will be an empty\n    // string which we don't care about\n    if (trailingNewline) {\n      lines.pop();\n    }\n\n    if (lines.length === 1 && !trailingNewline) {\n      this.buffer.push(lines[0]!);\n      return [];\n    }\n\n    if (this.buffer.length > 0) {\n      lines = [this.buffer.join('') + lines[0], ...lines.slice(1)];\n      this.buffer = [];\n    }\n\n    if (!trailingNewline) {\n      this.buffer = [lines.pop() || ''];\n    }\n\n    return lines;\n  }\n\n  decodeText(bytes: Bytes): string {\n    if (bytes == null) return '';\n    if (typeof bytes === 'string') return bytes;\n\n    // Node:\n    if (typeof Buffer !== 'undefined') {\n      if (bytes instanceof Buffer) {\n        return bytes.toString();\n      }\n      if (bytes instanceof Uint8Array) {\n        return Buffer.from(bytes).toString();\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`,\n      );\n    }\n\n    // Browser\n    if (typeof TextDecoder !== 'undefined') {\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n        this.textDecoder ??= new TextDecoder('utf8');\n        return this.textDecoder.decode(bytes);\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array/ArrayBuffer (${\n          (bytes as any).constructor.name\n        }) in a web platform. Please report this error.`,\n      );\n    }\n\n    throw new OpenAIError(\n      `Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`,\n    );\n  }\n\n  flush(): string[] {\n    if (!this.buffer.length && !this.trailingCR) {\n      return [];\n    }\n\n    const lines = [this.buffer.join('')];\n    this.buffer = [];\n    this.trailingCR = false;\n    return lines;\n  }\n}\n\n/** This is an internal helper function that's just used for testing */\nexport function _decodeChunks(chunks: string[]): string[] {\n  const decoder = new LineDecoder();\n  const lines: string[] = [];\n  for (const chunk of chunks) {\n    lines.push(...decoder.decode(chunk));\n  }\n\n  return lines;\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function readableStreamAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n","import { type RequestOptions } from './core';\nimport {\n  FormData,\n  File,\n  type Blob,\n  type FilePropertyBag,\n  getMultipartRequestOptions,\n  type FsReadStream,\n  isFsReadStream,\n} from './_shims/index';\nimport { MultipartBody } from './_shims/MultipartBody';\nexport { fileFromPath } from './_shims/index';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | Uint8Array | DataView;\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | Uint8Array | DataView;\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = FileLike | ResponseLike | FsReadStream;\n\n/**\n * Intended to match web.Blob, node.Blob, node-fetch.Blob, etc.\n */\nexport interface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n  // unfortunately @types/node-fetch@^2.6.4 doesn't type the arrayBuffer method\n}\n\n/**\n * Intended to match web.File, node.File, node-fetch.File, etc.\n */\nexport interface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name: string;\n}\n\n/**\n * Intended to match web.Response, node.Response, node-fetch.Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nexport const isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport const isFileLike = (value: any): value is FileLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\n * adds the arrayBuffer() method type because it is available and used at runtime\n */\nexport const isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\nexport const isUploadable = (value: any): value is Uploadable => {\n  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);\n};\n\nexport type ToFileInput = Uploadable | Exclude<BlobLikePart, string> | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<FileLike> {\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // Use the file's options if there isn't one provided\n  options ??= isFileLike(value) ? { lastModified: value.lastModified, type: value.type } : {};\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file';\n\n    return new File([blob as any], name, options);\n  }\n\n  const bits = await getBytes(value);\n\n  name ||= getName(value) ?? 'unknown_file';\n\n  if (!options.type) {\n    const type = (bits[0] as any)?.type;\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return new File(bits, name, options);\n}\n\nasync function getBytes(value: ToFileInput): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(await value.arrayBuffer());\n  } else if (\n    isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(chunk as BlobPart); // TODO, consider validating?\n    }\n  } else {\n    throw new Error(\n      `Unexpected data type: ${typeof value}; constructor: ${value?.constructor\n        ?.name}; props: ${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: any): string {\n  const props = Object.getOwnPropertyNames(value);\n  return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n\nfunction getName(value: any): string | undefined {\n  return (\n    getStringFromMaybeBuffer(value.name) ||\n    getStringFromMaybeBuffer(value.filename) ||\n    // For fs.ReadStream\n    getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop()\n  );\n}\n\nconst getStringFromMaybeBuffer = (x: string | Buffer | unknown): string | undefined => {\n  if (typeof x === 'string') return x;\n  if (typeof Buffer !== 'undefined' && x instanceof Buffer) return String(x);\n  return undefined;\n};\n\nconst isAsyncIterableIterator = (value: any): value is AsyncIterableIterator<unknown> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\nexport const isMultipartBody = (body: any): body is MultipartBody =>\n  body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const multipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const createForm = async <T = Record<string, unknown>>(body: T | undefined): Promise<FormData> => {\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (isUploadable(value)) {\n    const file = await toFile(value);\n    form.append(key, file as File);\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n","import { VERSION } from './version';\nimport { Stream } from './streaming';\nimport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n} from './error';\nimport {\n  kind as shimsKind,\n  type Readable,\n  getDefaultAgent,\n  type Agent,\n  fetch,\n  type RequestInfo,\n  type RequestInit,\n  type Response,\n  type HeadersInit,\n} from './_shims/index';\nexport { type Response };\nimport { BlobLike, isBlobLike, isMultipartBody } from './uploads';\nexport {\n  maybeMultipartFormRequestOptions,\n  multipartFormRequestOptions,\n  createForm,\n  type Uploadable,\n} from './uploads';\n\nexport type Fetch = (url: RequestInfo, init?: RequestInit) => Promise<Response>;\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\ntype APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n};\n\nasync function defaultParseResponse<T>(props: APIResponseProps): Promise<T> {\n  const { response } = props;\n  if (props.options.stream) {\n    debug('response', response.status, response.url, response.headers, response.body);\n\n    // Note: there is an invariant here that isn't represented in the type system\n    // that if you set `stream: true` the response type must also be `Stream<T>`\n\n    if (props.options.__streamClass) {\n      return props.options.__streamClass.fromSSEResponse(response, props.controller) as any;\n    }\n\n    return Stream.fromSSEResponse(response, props.controller) as any;\n  }\n\n  // fetch refuses to read the body when the status code is 204.\n  if (response.status === 204) {\n    return null as T;\n  }\n\n  if (props.options.__binaryResponse) {\n    return response as unknown as T;\n  }\n\n  const contentType = response.headers.get('content-type');\n  const isJSON =\n    contentType?.includes('application/json') || contentType?.includes('application/vnd.api+json');\n  if (isJSON) {\n    const json = await response.json();\n\n    debug('response', response.status, response.url, response.headers, json);\n\n    return json as T;\n  }\n\n  const text = await response.text();\n  debug('response', response.status, response.url, response.headers, text);\n\n  // TODO handle blob, arraybuffer, other content types, etc.\n  return text as unknown as T;\n}\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<T> {\n  private parsedPromise: Promise<T> | undefined;\n\n  constructor(\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (props: APIResponseProps) => PromiseOrValue<T> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n  }\n\n  _thenUnwrap<U>(transform: (data: T) => U): APIPromise<U> {\n    return new APIPromise(this.responsePromise, async (props) => transform(await this.parseResponse(props)));\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import  from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n  /**\n   * Gets the parsed response data and the raw `Response` instance.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import  from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  async withResponse(): Promise<{ data: T; response: Response }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response };\n  }\n\n  private parse(): Promise<T> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then(this.parseResponse);\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = T, TResult2 = never>(\n    onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<T | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<T> {\n    return this.parse().finally(onfinally);\n  }\n}\n\nexport abstract class APIClient {\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  httpAgent: Agent | undefined;\n\n  private fetch: Fetch;\n  protected idempotencyHeader?: string;\n\n  constructor({\n    baseURL,\n    maxRetries = 2,\n    timeout = 600000, // 10 minutes\n    httpAgent,\n    fetch: overridenFetch,\n  }: {\n    baseURL: string;\n    maxRetries?: number | undefined;\n    timeout: number | undefined;\n    httpAgent: Agent | undefined;\n    fetch: Fetch | undefined;\n  }) {\n    this.baseURL = baseURL;\n    this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\n    this.timeout = validatePositiveInteger('timeout', timeout);\n    this.httpAgent = httpAgent;\n\n    this.fetch = overridenFetch ?? fetch;\n  }\n\n  protected authHeaders(opts: FinalRequestOptions): Headers {\n    return {};\n  }\n\n  /**\n   * Override this to add your own default headers, for example:\n   *\n   *  {\n   *    ...super.defaultHeaders(),\n   *    Authorization: 'Bearer 123',\n   *  }\n   */\n  protected defaultHeaders(opts: FinalRequestOptions): Headers {\n    return {\n      Accept: 'application/json',\n      'Content-Type': 'application/json',\n      'User-Agent': this.getUserAgent(),\n      ...getPlatformHeaders(),\n      ...this.authHeaders(opts),\n    };\n  }\n\n  protected abstract defaultQuery(): DefaultQuery | undefined;\n\n  /**\n   * Override this to add your own headers validation:\n   */\n  protected validateHeaders(headers: Headers, customHeaders: Headers) {}\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  get<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Req, Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions<Req>>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then(async (opts) => {\n        const body =\n          opts && isBlobLike(opts?.body) ? new DataView(await opts.body.arrayBuffer())\n          : opts?.body instanceof DataView ? opts.body\n          : opts?.body instanceof ArrayBuffer ? new DataView(opts.body)\n          : opts && ArrayBuffer.isView(opts?.body) ? new DataView(opts.body.buffer)\n          : opts?.body;\n        return { method, path, ...opts, body };\n      }),\n    );\n  }\n\n  getAPIList<Item, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions<any>,\n  ): PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  private calculateContentLength(body: unknown): string | null {\n    if (typeof body === 'string') {\n      if (typeof Buffer !== 'undefined') {\n        return Buffer.byteLength(body, 'utf8').toString();\n      }\n\n      if (typeof TextEncoder !== 'undefined') {\n        const encoder = new TextEncoder();\n        const encoded = encoder.encode(body);\n        return encoded.length.toString();\n      }\n    } else if (ArrayBuffer.isView(body)) {\n      return body.byteLength.toString();\n    }\n\n    return null;\n  }\n\n  buildRequest<Req>(options: FinalRequestOptions<Req>): { req: RequestInit; url: string; timeout: number } {\n    const { method, path, query, headers: headers = {} } = options;\n\n    const body =\n      ArrayBuffer.isView(options.body) || (options.__binaryRequest && typeof options.body === 'string') ?\n        options.body\n      : isMultipartBody(options.body) ? options.body.body\n      : options.body ? JSON.stringify(options.body, null, 2)\n      : null;\n    const contentLength = this.calculateContentLength(body);\n\n    const url = this.buildURL(path!, query);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    const timeout = options.timeout ?? this.timeout;\n    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);\n    const minAgentTimeout = timeout + 1000;\n    if (\n      typeof (httpAgent as any)?.options?.timeout === 'number' &&\n      minAgentTimeout > ((httpAgent as any).options.timeout ?? 0)\n    ) {\n      // Allow any given request to bump our agent active socket timeout.\n      // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\n      // and without mutating agent we would need to create more of them.\n      // This tradeoff optimizes for performance.\n      (httpAgent as any).options.timeout = minAgentTimeout;\n    }\n\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      headers[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const reqHeaders = this.buildHeaders({ options, headers, contentLength });\n\n    const req: RequestInit = {\n      method,\n      ...(body && { body: body as any }),\n      headers: reqHeaders,\n      ...(httpAgent && { agent: httpAgent }),\n      // @ts-ignore node-fetch uses a custom AbortSignal type that is\n      // not compatible with standard web types\n      signal: options.signal ?? null,\n    };\n\n    return { req, url, timeout };\n  }\n\n  private buildHeaders({\n    options,\n    headers,\n    contentLength,\n  }: {\n    options: FinalRequestOptions;\n    headers: Record<string, string | null | undefined>;\n    contentLength: string | null | undefined;\n  }): Record<string, string> {\n    const reqHeaders: Record<string, string> = {};\n    if (contentLength) {\n      reqHeaders['content-length'] = contentLength;\n    }\n\n    const defaultHeaders = this.defaultHeaders(options);\n    applyHeadersMut(reqHeaders, defaultHeaders);\n    applyHeadersMut(reqHeaders, headers);\n\n    // let builtin fetch set the Content-Type for multipart bodies\n    if (isMultipartBody(options.body) && shimsKind !== 'node') {\n      delete reqHeaders['content-type'];\n    }\n\n    this.validateHeaders(reqHeaders, headers);\n\n    return reqHeaders;\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {}\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  protected parseHeaders(headers: HeadersInit | null | undefined): Record<string, string> {\n    return (\n      !headers ? {}\n      : Symbol.iterator in headers ?\n        Object.fromEntries(Array.from(headers as Iterable<string[]>).map((header) => [...header]))\n      : { ...headers }\n    );\n  }\n\n  protected makeStatusError(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    return APIError.generate(status, error, message, headers);\n  }\n\n  request<Req, Rsp>(\n    options: PromiseOrValue<FinalRequestOptions<Req>>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this.makeRequest(options, remainingRetries));\n  }\n\n  private async makeRequest<Req>(\n    optionsInput: PromiseOrValue<FinalRequestOptions<Req>>,\n    retriesRemaining: number | null,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    if (retriesRemaining == null) {\n      retriesRemaining = options.maxRetries ?? this.maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = this.buildRequest(options);\n\n    await this.prepareRequest(req, { url, options });\n\n    debug('request', url, options, req.headers);\n\n    if (options.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n\n    if (response instanceof Error) {\n      if (options.signal?.aborted) {\n        throw new APIUserAbortError();\n      }\n      if (retriesRemaining) {\n        return this.retryRequest(options, retriesRemaining);\n      }\n      if (response.name === 'AbortError') {\n        throw new APIConnectionTimeoutError();\n      }\n      throw new APIConnectionError({ cause: response });\n    }\n\n    const responseHeaders = createResponseHeaders(response.headers);\n\n    if (!response.ok) {\n      if (retriesRemaining && this.shouldRetry(response)) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n        debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\n        return this.retryRequest(options, retriesRemaining, responseHeaders);\n      }\n\n      const errText = await response.text().catch((e) => castToError(e).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\n\n      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\n      throw err;\n    }\n\n    return { response, options, controller };\n  }\n\n  requestAPIList<Item = unknown, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null);\n    return new PagePromise<PageClass, Item>(this, request, Page);\n  }\n\n  buildURL<Req>(path: string, query: Req | null | undefined): string {\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query } as Req;\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return Object.entries(query)\n      .filter(([_, value]) => typeof value !== 'undefined')\n      .map(([key, value]) => {\n        if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n          return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n        }\n        if (value === null) {\n          return `${encodeURIComponent(key)}=`;\n        }\n        throw new OpenAIError(\n          `Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`,\n        );\n      })\n      .join('&');\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    return (\n      this.getRequestClient()\n        // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n        .fetch.call(undefined, url, { signal: controller.signal as any, ...options })\n        .finally(() => {\n          clearTimeout(timeout);\n        })\n    );\n  }\n\n  protected getRequestClient(): RequestClient {\n    return { fetch: this.fetch };\n  }\n\n  private shouldRetry(response: Response): boolean {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.['retry-after'];\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n}\n\nexport type PageInfo = { url: URL } | { params: Record<string, unknown> | null };\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: APIClient;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: APIClient, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  /**\n   * @deprecated Use nextPageInfo instead\n   */\n  abstract nextPageParams(): Partial<Record<string, unknown>> | null;\n  abstract nextPageInfo(): PageInfo | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageInfo() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextInfo = this.nextPageInfo();\n    if (!nextInfo) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n    const nextOptions = { ...this.options };\n    if ('params' in nextInfo && typeof nextOptions.query === 'object') {\n      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\n    } else if ('url' in nextInfo) {\n      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\n      for (const [key, value] of params) {\n        nextInfo.url.searchParams.set(key, value as any);\n      }\n      nextOptions.query = undefined;\n      nextOptions.path = nextInfo.url.toString();\n    }\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages() {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let page: AbstractPage<Item> = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator]() {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: APIClient,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      request,\n      async (props) => new Page(client, props.response, await defaultParseResponse(props), props.options),\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator]() {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport const createResponseHeaders = (\n  headers: Awaited<ReturnType<Fetch>>['headers'],\n): Record<string, string> => {\n  return new Proxy(\n    Object.fromEntries(\n      // @ts-ignore\n      headers.entries(),\n    ),\n    {\n      get(target, name) {\n        const key = name.toString();\n        return target[key.toLowerCase()] || target[key];\n      },\n    },\n  );\n};\n\ntype HTTPMethod = 'get' | 'post' | 'put' | 'patch' | 'delete';\n\nexport type RequestClient = { fetch: Fetch };\nexport type Headers = Record<string, string | null | undefined>;\nexport type DefaultQuery = Record<string, string | undefined>;\nexport type KeysEnum<T> = { [P in keyof Required<T>]: true };\n\nexport type RequestOptions<\n  Req = unknown | Record<string, unknown> | Readable | BlobLike | ArrayBufferView | ArrayBuffer,\n> = {\n  method?: HTTPMethod;\n  path?: string;\n  query?: Req | undefined;\n  body?: Req | null | undefined;\n  headers?: Headers | undefined;\n\n  maxRetries?: number;\n  stream?: boolean | undefined;\n  timeout?: number;\n  httpAgent?: Agent;\n  signal?: AbortSignal | undefined | null;\n  idempotencyKey?: string;\n\n  __binaryRequest?: boolean | undefined;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\n// This is required so that we can determine if a given object matches the RequestOptions\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\n// compiler such that any missing / extraneous keys will cause an error.\nconst requestOptionsKeys: KeysEnum<RequestOptions> = {\n  method: true,\n  path: true,\n  query: true,\n  body: true,\n  headers: true,\n\n  maxRetries: true,\n  stream: true,\n  timeout: true,\n  httpAgent: true,\n  signal: true,\n  idempotencyKey: true,\n\n  __binaryRequest: true,\n  __binaryResponse: true,\n  __streamClass: true,\n};\n\nexport const isRequestOptions = (obj: unknown): obj is RequestOptions => {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    !isEmptyObj(obj) &&\n    Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k))\n  );\n};\n\nexport type FinalRequestOptions<Req = unknown | Record<string, unknown> | Readable | DataView> =\n  RequestOptions<Req> & {\n    method: HTTPMethod;\n    path: string;\n  };\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n  // Check if Node.js\n  if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(process.platform),\n      'X-Stainless-Arch': normalizeArch(process.arch),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nconst getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n\n// https://stackoverflow.com/a/19709846\nconst startsWithSchemeRegexp = new RegExp('^(?:[a-z]+:)?//', 'i');\nconst isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\n\nconst validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  return new Error(err);\n};\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  return value;\n};\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof process !== 'undefined') {\n    return process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof Deno !== 'undefined') {\n    return Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn(obj: Object, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\n/**\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\n * using lower-case for all properties,\n * ignoring any keys with undefined values,\n * and deleting any keys with null values.\n */\nfunction applyHeadersMut(targetHeaders: Headers, newHeaders: Headers): void {\n  for (const k in newHeaders) {\n    if (!hasOwn(newHeaders, k)) continue;\n    const lowerKey = k.toLowerCase();\n    if (!lowerKey) continue;\n\n    const val = newHeaders[k];\n\n    if (val === null) {\n      delete targetHeaders[lowerKey];\n    } else if (val !== undefined) {\n      targetHeaders[lowerKey] = val;\n    }\n  }\n}\n\nexport function debug(action: string, ...args: any[]) {\n  if (typeof process !== 'undefined' && process?.env?.['DEBUG'] === 'true') {\n    console.log(`OpenAI:DEBUG:${action}`, ...args);\n  }\n}\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nconst uuid4 = () => {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n    const r = (Math.random() * 16) | 0;\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n};\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\nexport interface HeadersProtocol {\n  get: (header: string) => string | null | undefined;\n}\nexport type HeadersLike = Record<string, string | string[] | undefined> | HeadersProtocol;\n\nexport const isHeadersProtocol = (headers: any): headers is HeadersProtocol => {\n  return typeof headers?.get === 'function';\n};\n\nexport const getRequiredHeader = (headers: HeadersLike, header: string): string => {\n  const lowerCasedHeader = header.toLowerCase();\n  if (isHeadersProtocol(headers)) {\n    // to deal with the case where the header looks like Stainless-Event-Id\n    const intercapsHeader =\n      header[0]?.toUpperCase() +\n      header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\n    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\n      const value = headers.get(key);\n      if (value) {\n        return value;\n      }\n    }\n  }\n\n  for (const [key, value] of Object.entries(headers)) {\n    if (key.toLowerCase() === lowerCasedHeader) {\n      if (Array.isArray(value)) {\n        if (value.length <= 1) return value[0];\n        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\n        return value[0];\n      }\n      return value;\n    }\n  }\n\n  throw new Error(`Could not find ${header} header`);\n};\n\n/**\n * Encodes a string to Base64 format.\n */\nexport const toBase64 = (str: string | null | undefined): string => {\n  if (!str) return '';\n  if (typeof Buffer !== 'undefined') {\n    return Buffer.from(str).toString('base64');\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(str);\n  }\n\n  throw new OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { AbstractPage, Response, APIClient, FinalRequestOptions, PageInfo } from './core';\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: APIClient, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  /**\n   * This page represents a response that isn't actually paginated at the API level\n   * so there will never be any next page params.\n   */\n  nextPageParams(): null {\n    return null;\n  }\n\n  nextPageInfo(): null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  constructor(\n    client: APIClient,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  nextPageParams(): Partial<CursorPageParams> | null {\n    const info = this.nextPageInfo();\n    if (!info) return null;\n    if ('params' in info) return info.params;\n    const params = Object.fromEntries(info.url.searchParams);\n    if (!Object.keys(params).length) return null;\n    return params;\n  }\n\n  nextPageInfo(): PageInfo | null {\n    const data = this.getPaginatedItems();\n    if (!data.length) {\n      return null;\n    }\n\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return { params: { after: id } };\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { OpenAI } from './index';\n\nexport class APIResource {\n  protected _client: OpenAI;\n\n  constructor(client: OpenAI) {\n    this._client = client;\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../core';\nimport { APIPromise } from '../../core';\nimport { APIResource } from '../../resource';\nimport * as ChatCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../completions';\nimport * as Shared from '../shared';\nimport * as ChatAPI from './chat';\nimport { Stream } from '../../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a model response for the given chat conversation.\n   */\n  create(\n    body: ChatCompletionCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n}\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: ChatCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | null;\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value except for the last chunk which contains the token usage\n   * statistics for the entire request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\nexport type ChatCompletionContentPart = ChatCompletionContentPartText | ChatCompletionContentPartImage;\n\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\nexport type ChatCompletionMessageParam =\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\nexport interface ChatCompletionMessageToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array. All other chunks\n   * will also include a `usage` field, but with a null value.\n   */\n  include_usage?: boolean;\n}\n\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\nexport interface ChatCompletionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption = 'none' | 'auto' | 'required' | ChatCompletionNamedToolChoice;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * @deprecated ChatCompletionMessageParam should be used instead\n */\nexport type CreateChatCompletionRequestMessage = ChatCompletionMessageParam;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * ID of the model to use. See the\n   * [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility)\n   * table for details on which models work with the Chat API.\n   */\n  model: (string & {}) | ChatAPI.ChatModel;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model. `none` means the model\n   * will not call a function and instead generates a message. `auto` means the model\n   * can pick between generating a message or calling a function. Specifying a\n   * particular function via `{\"name\": \"my_function\"}` forces the model to call that\n   * function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the chat\n   * completion.\n   *\n   * The total length of input tokens and generated tokens is limited by the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * An object specifying the format that the model must output. Compatible with\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ChatCompletionCreateParams.ResponseFormat;\n\n  /**\n   * This feature is in Beta. If specified, our system will make a best effort to\n   * sample deterministically, such that repeated requests with the same `seed` and\n   * parameters should return the same result. Determinism is not guaranteed, and you\n   * should refer to the `system_fingerprint` response parameter to monitor changes\n   * in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. Currently, only functions are supported as a\n   * tool. Use this to provide a list of functions the model may generate JSON inputs\n   * for. A max of 128 functions are supported.\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  /**\n   * An object specifying the format that the model must output. Compatible with\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  export interface ResponseFormat {\n    /**\n     * Must be one of `text` or `json_object`.\n     */\n    type?: 'text' | 'json_object';\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParams instead\n */\nexport type CompletionCreateParams = ChatCompletionCreateParams;\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsNonStreaming instead\n */\nexport type CompletionCreateParamsNonStreaming = ChatCompletionCreateParamsNonStreaming;\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsStreaming instead\n */\nexport type CompletionCreateParamsStreaming = ChatCompletionCreateParamsStreaming;\n\nexport namespace Completions {\n  export import ChatCompletion = ChatCompletionsAPI.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = ChatCompletionsAPI.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = ChatCompletionsAPI.ChatCompletionChunk;\n  export import ChatCompletionContentPart = ChatCompletionsAPI.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = ChatCompletionsAPI.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartText = ChatCompletionsAPI.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = ChatCompletionsAPI.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = ChatCompletionsAPI.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = ChatCompletionsAPI.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = ChatCompletionsAPI.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = ChatCompletionsAPI.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = ChatCompletionsAPI.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = ChatCompletionsAPI.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = ChatCompletionsAPI.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = ChatCompletionsAPI.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = ChatCompletionsAPI.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = ChatCompletionsAPI.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = ChatCompletionsAPI.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = ChatCompletionsAPI.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = ChatCompletionsAPI.ChatCompletionUserMessageParam;\n  /**\n   * @deprecated ChatCompletionMessageParam should be used instead\n   */\n  export import CreateChatCompletionRequestMessage = ChatCompletionsAPI.CreateChatCompletionRequestMessage;\n  export import ChatCompletionCreateParams = ChatCompletionsAPI.ChatCompletionCreateParams;\n  export import CompletionCreateParams = ChatCompletionsAPI.CompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsNonStreaming = ChatCompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\n  export import CompletionCreateParamsStreaming = ChatCompletionsAPI.CompletionCreateParamsStreaming;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as ChatAPI from './chat';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel =\n  | 'gpt-4o'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4-0125-preview'\n  | 'gpt-4-turbo-preview'\n  | 'gpt-4-1106-preview'\n  | 'gpt-4-vision-preview'\n  | 'gpt-4'\n  | 'gpt-4-0314'\n  | 'gpt-4-0613'\n  | 'gpt-4-32k'\n  | 'gpt-4-32k-0314'\n  | 'gpt-4-32k-0613'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-16k'\n  | 'gpt-3.5-turbo-0301'\n  | 'gpt-3.5-turbo-0613'\n  | 'gpt-3.5-turbo-1106'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo-16k-0613';\n\nexport namespace Chat {\n  export import ChatModel = ChatAPI.ChatModel;\n  export import Completions = CompletionsAPI.Completions;\n  export import ChatCompletion = CompletionsAPI.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = CompletionsAPI.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = CompletionsAPI.ChatCompletionChunk;\n  export import ChatCompletionContentPart = CompletionsAPI.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = CompletionsAPI.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartText = CompletionsAPI.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = CompletionsAPI.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = CompletionsAPI.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = CompletionsAPI.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = CompletionsAPI.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = CompletionsAPI.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = CompletionsAPI.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = CompletionsAPI.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = CompletionsAPI.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = CompletionsAPI.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = CompletionsAPI.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = CompletionsAPI.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = CompletionsAPI.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = CompletionsAPI.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = CompletionsAPI.ChatCompletionUserMessageParam;\n  /**\n   * @deprecated ChatCompletionMessageParam should be used instead\n   */\n  export import CreateChatCompletionRequestMessage = CompletionsAPI.CreateChatCompletionRequestMessage;\n  export import ChatCompletionCreateParams = CompletionsAPI.ChatCompletionCreateParams;\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = CompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = CompletionsAPI.ChatCompletionCreateParamsStreaming;\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../core';\nimport { APIResource } from '../../resource';\nimport { type Response } from '../../_shims/index';\nimport * as SpeechAPI from './speech';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   */\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\n  }\n}\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models/tts):\n   * `tts-1` or `tts-1-hd`\n   */\n  model: (string & {}) | 'tts-1' | 'tts-1-hd';\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`,\n   * `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are\n   * available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech/voice-options).\n   */\n  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n}\n\nexport namespace Speech {\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../core';\nimport { APIResource } from '../../resource';\nimport * as TranscriptionsAPI from './transcriptions';\nimport { type Uploadable, multipartFormRequestOptions } from '../../core';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription> {\n    return this._client.post('/audio/transcriptions', multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n}\n\nexport interface TranscriptionCreateParams {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | 'whisper-1';\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\n   * improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\n   * should match the audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the transcript output, in one of these options: `json`, `text`,\n   * `srt`, `verbose_json`, or `vtt`.\n   */\n  response_format?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport namespace Transcriptions {\n  export import Transcription = TranscriptionsAPI.Transcription;\n  export import TranscriptionCreateParams = TranscriptionsAPI.TranscriptionCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../core';\nimport { APIResource } from '../../resource';\nimport * as TranslationsAPI from './translations';\nimport { type Uploadable, multipartFormRequestOptions } from '../../core';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   */\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation> {\n    return this._client.post('/audio/translations', multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationCreateParams {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | 'whisper-1';\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the transcript output, in one of these options: `json`, `text`,\n   * `srt`, `verbose_json`, or `vtt`.\n   */\n  response_format?: string;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport namespace Translations {\n  export import Translation = TranslationsAPI.Translation;\n  export import TranslationCreateParams = TranslationsAPI.TranslationCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as SpeechAPI from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport * as TranslationsAPI from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport namespace Audio {\n  export import Transcriptions = TranscriptionsAPI.Transcriptions;\n  export import Transcription = TranscriptionsAPI.Transcription;\n  export import TranscriptionCreateParams = TranscriptionsAPI.TranscriptionCreateParams;\n  export import Translations = TranslationsAPI.Translations;\n  export import Translation = TranslationsAPI.Translation;\n  export import TranslationCreateParams = TranslationsAPI.TranslationCreateParams;\n  export import Speech = SpeechAPI.Speech;\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport * as BatchesAPI from './batches';\nimport { CursorPage, type CursorPageParams } from '../pagination';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.get(`/batches/${batchId}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(query?: BatchListParams, options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(\n    query: BatchListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<BatchesPage, Batch> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post(`/batches/${batchId}/cancel`, options);\n  }\n}\n\nexport class BatchesPage extends CursorPage<Batch> {}\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.\n   * Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000\n   * embedding inputs across all requests in the batch.\n   */\n  endpoint: '/v1/chat/completions' | '/v1/embeddings' | '/v1/completions';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 100 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Optional custom metadata for the batch.\n   */\n  metadata?: Record<string, string> | null;\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nexport namespace Batches {\n  export import Batch = BatchesAPI.Batch;\n  export import BatchError = BatchesAPI.BatchError;\n  export import BatchRequestCounts = BatchesAPI.BatchRequestCounts;\n  export import BatchesPage = BatchesAPI.BatchesPage;\n  export import BatchCreateParams = BatchesAPI.BatchCreateParams;\n  export import BatchListParams = BatchesAPI.BatchListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../core';\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as AssistantsAPI from './assistants';\nimport * as Shared from '../shared';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { CursorPage, type CursorPageParams } from '../../pagination';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   */\n  create(body: AssistantCreateParams, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   */\n  retrieve(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.get(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   */\n  update(\n    assistantId: string,\n    body: AssistantUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Assistant> {\n    return this._client.post(`/assistants/${assistantId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   */\n  list(\n    query?: AssistantListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant>;\n  list(options?: Core.RequestOptions): Core.PagePromise<AssistantsPage, Assistant>;\n  list(\n    query: AssistantListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/assistants', AssistantsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   */\n  del(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<AssistantDeleted> {\n    return this._client.delete(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class AssistantsPage extends CursorPage<Assistant> {}\n\n/**\n * Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) are\n   * being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes/api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for gpt-4\\* models and 5 for gpt-3.5-turbo. This number should be between 1\n     * and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/number-of-chunks-returned)\n     * for more information.\n     */\n    max_num_results?: number;\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n * created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) are\n   * being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object) is\n   * cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/runs/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613';\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model?: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Assistants {\n  export import Assistant = AssistantsAPI.Assistant;\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\n  export import AssistantStreamEvent = AssistantsAPI.AssistantStreamEvent;\n  export import AssistantTool = AssistantsAPI.AssistantTool;\n  export import CodeInterpreterTool = AssistantsAPI.CodeInterpreterTool;\n  export import FileSearchTool = AssistantsAPI.FileSearchTool;\n  export import FunctionTool = AssistantsAPI.FunctionTool;\n  export import MessageStreamEvent = AssistantsAPI.MessageStreamEvent;\n  export import RunStepStreamEvent = AssistantsAPI.RunStepStreamEvent;\n  export import RunStreamEvent = AssistantsAPI.RunStreamEvent;\n  export import ThreadStreamEvent = AssistantsAPI.ThreadStreamEvent;\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\n}\n","import { type ChatCompletionRunner } from './ChatCompletionRunner';\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\nimport { JSONSchema } from './jsonschema';\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\nexport type RunnableFunctionWithParse<Args extends object> = {\n  /**\n   * @param args the return value from `parse`.\n   * @param runner the runner evaluating this callback.\n   * @returns a string to send back to OpenAI.\n   */\n  function: (\n    args: Args,\n    runner: ChatCompletionRunner | ChatCompletionStreamingRunner,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * @param input the raw args from the OpenAI function call.\n   * @returns the parsed arguments to pass to `function`\n   */\n  parse: (input: string) => PromiseOrValue<Args>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n};\n\nexport type RunnableFunctionWithoutParse = {\n  /**\n   * @param args the raw args from the OpenAI function call.\n   * @returns a string to send back to OpenAI\n   */\n  function: (\n    args: string,\n    runner: ChatCompletionRunner | ChatCompletionStreamingRunner,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n};\n\nexport type RunnableFunction<Args extends object | string> =\n  Args extends string ? RunnableFunctionWithoutParse\n  : Args extends object ? RunnableFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunction<Args extends object | string> =\n  Args extends string ? RunnableToolFunctionWithoutParse\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunctionWithoutParse = {\n  type: 'function';\n  function: RunnableFunctionWithoutParse;\n};\nexport type RunnableToolFunctionWithParse<Args extends object> = {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n};\n\nexport function isRunnableFunctionWithParse<Args extends object>(\n  fn: any,\n): fn is RunnableFunctionWithParse<Args> {\n  return typeof (fn as any).parse === 'function';\n}\n\nexport type BaseFunctionsArgs = readonly (object | string)[];\n\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n *\n * @deprecated - please use ParsingToolFunction instead.\n */\nexport class ParsingFunction<Args extends object> {\n  function: RunnableFunctionWithParse<Args>['function'];\n  parse: RunnableFunctionWithParse<Args>['parse'];\n  parameters: RunnableFunctionWithParse<Args>['parameters'];\n  description: RunnableFunctionWithParse<Args>['description'];\n  name?: RunnableFunctionWithParse<Args>['name'];\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.function = input.function;\n    this.parse = input.parse;\n    this.parameters = input.parameters;\n    this.description = input.description;\n    this.name = input.name;\n  }\n}\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nexport class ParsingToolFunction<Args extends object> {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.type = 'function';\n    this.function = input;\n  }\n}\n","import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from \"../resources\";\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isFunctionMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionFunctionMessageParam => {\n  return message?.role === 'function';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n","import * as Core from \"../core\";\nimport { type CompletionUsage } from \"../resources/completions\";\nimport {\n  type Completions,\n  type ChatCompletion,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParams,\n  type ChatCompletionTool,\n} from \"../resources/chat/completions\";\nimport { APIUserAbortError, OpenAIError } from \"../error\";\nimport {\n  type RunnableFunction,\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n} from './RunnableFunction';\nimport { ChatCompletionFunctionRunnerParams, ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingFunctionRunnerParams,\n  ChatCompletionStreamingToolRunnerParams,\n} from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isFunctionMessage, isToolMessage } from './chatCompletionUtils';\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends Core.RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport abstract class AbstractChatCompletionRunner<\n  Events extends CustomEvents<any> = AbstractChatCompletionRunnerEvents,\n> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: { [Event in keyof Events]?: ListenersForEvent<Events, Event> } = {};\n\n  protected _chatCompletions: ChatCompletion[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError);\n    }, 0);\n  }\n\n  protected _addChatCompletion(chatCompletion: ChatCompletion): ChatCompletion {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(message: ChatCompletionMessageParam, emit = true) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if ((isFunctionMessage(message) || isToolMessage(message)) && message.content) {\n        // Note, this assumes that {role: 'tool', content: } is always the result of a call of tool of type=function.\n        this._emit('functionCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.function_call) {\n        this._emit('functionCall', message.function_call);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  protected _connected() {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners: ListenersForEvent<Events, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners: ListenersForEvent<Events, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof Events>(\n    event: Event,\n  ): Promise<\n    EventParameters<Events, Event> extends [infer Param] ? Param\n    : EventParameters<Events, Event> extends [] ? void\n    : EventParameters<Events, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ChatCompletion> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        const { function_call, ...rest } = message;\n        const ret: ChatCompletionMessage = { ...rest, content: message.content ?? null };\n        if (function_call) {\n          ret.function_call = function_call;\n        }\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionCall(): ChatCompletionMessage.FunctionCall | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.function_call) {\n        return message.function_call;\n      }\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionCall(): Promise<ChatCompletionMessage.FunctionCall | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCall();\n  }\n\n  #getFinalFunctionCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isFunctionMessage(message) && message.content != null) {\n        return message.content;\n      }\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  #handleError = (error: unknown) => {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  };\n\n  protected _emit<Event extends keyof Events>(event: Event, ...args: EventParameters<Events, Event>) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: ListenersForEvent<Events, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...args));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal() {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionCall();\n    if (finalFunctionCall) this._emit('finalFunctionCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    completions: Completions,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(chatCompletion);\n  }\n\n  protected async _runChatCompletion(\n    completions: Completions,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(completions, params, options);\n  }\n\n  protected async _runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    completions: Completions,\n    params:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'function' as const;\n    const { function_call = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of params.functions) {\n      functionsByName[f.name || f.function.name] = f;\n    }\n\n    const functions: ChatCompletionCreateParams.Function[] = params.functions.map(\n      (f): ChatCompletionCreateParams.Function => ({\n        name: f.name || f.function.name,\n        parameters: f.parameters as Record<string, unknown>,\n        description: f.description,\n      }),\n    );\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        completions,\n        {\n          ...restParams,\n          function_call,\n          functions,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.function_call) return;\n      const { name, arguments: args } = message.function_call;\n      const fn = functionsByName[name];\n      if (!fn) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\n          .map((f) => JSON.stringify(f.name))\n          .join(', ')}. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(\n          singleFunctionToCall,\n        )} requested. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      }\n\n      let parsed;\n      try {\n        parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n      } catch (error) {\n        this._addMessage({\n          role,\n          name,\n          content: error instanceof Error ? error.message : String(error),\n        });\n        continue;\n      }\n\n      // @ts-expect-error it can't rule out `never` type.\n      const rawContent = await fn.function(parsed, this);\n      const content = this.#stringifyFunctionCallResult(rawContent);\n\n      this._addMessage({ role, name, content });\n\n      if (singleFunctionToCall) return;\n    }\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    completions: Completions,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of params.tools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        params.tools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        completions,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${tools\n            .map((f) => JSON.stringify(f.function.name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\ntype CustomEvents<Event extends string> = {\n  [k in Event]: k extends keyof AbstractChatCompletionRunnerEvents ? AbstractChatCompletionRunnerEvents[k]\n  : (...args: any[]) => void;\n};\n\ntype ListenerForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Event extends (\n  keyof AbstractChatCompletionRunnerEvents\n) ?\n  AbstractChatCompletionRunnerEvents[Event]\n: Events[Event];\n\ntype ListenersForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Array<{\n  listener: ListenerForEvent<Events, Event>;\n  once?: boolean;\n}>;\ntype EventParameters<Events extends CustomEvents<any>, Event extends keyof Events> = Parameters<\n  ListenerForEvent<Events, Event>\n>;\n\nexport interface AbstractChatCompletionRunnerEvents {\n  connect: () => void;\n  functionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  functionCallResult: (content: string) => void;\n  finalFunctionCallResult: (content: string) => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n","import {\n  type Completions,\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from \"../resources/chat/completions\";\nimport { type RunnableFunctions, type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs>;\n};\n\nexport class ChatCompletionRunner extends AbstractChatCompletionRunner<ChatCompletionRunnerEvents> {\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions(\n    completions: Completions,\n    params: ChatCompletionFunctionRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner {\n    const runner = new ChatCompletionRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(completions, params, opts));\n    return runner;\n  }\n\n  static runTools(\n    completions: Completions,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner {\n    const runner = new ChatCompletionRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(completions, params, opts));\n    return runner;\n  }\n\n  override _addMessage(message: ChatCompletionMessageParam) {\n    super._addMessage(message);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n","import * as Core from \"../core\";\nimport { OpenAIError, APIUserAbortError } from \"../error\";\nimport {\n  Completions,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsBase,\n} from \"../resources/chat/completions\";\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from \"../_shims/index\";\nimport { Stream } from \"../streaming\";\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class ChatCompletionStream\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream {\n    const runner = new ChatCompletionStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion(\n    completions: Completions,\n    params: ChatCompletionStreamParams,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream {\n    const runner = new ChatCompletionStream();\n    runner._run(() =>\n      runner._runChatCompletion(\n        completions,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n  #addChunk(chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n    const delta = chunk.choices[0]?.delta?.content;\n    const snapshot = completion.choices[0]?.message;\n    if (delta != null && snapshot?.role === 'assistant' && snapshot?.content) {\n      this._emit('content', delta, snapshot.content);\n    }\n  }\n  #endRequest(): ChatCompletion {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    return finalizeChatCompletion(snapshot);\n  }\n\n  protected override async _createChatCompletion(\n    completions: Completions,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    const stream = await completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, ...rest } = logprobs;\n          Object.assign(choice.logprobs, rest);\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n        }\n      }\n\n      if (finish_reason) choice.finish_reason = finish_reason;\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n      const { content, function_call, role, tool_calls, ...rest } = delta;\n      Object.assign(choice.message, rest);\n\n      if (content) choice.message.content = (choice.message.content || '') + content;\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??= {});\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) tool_call.function!.arguments += fn.arguments;\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion(snapshot: ChatCompletionSnapshot): ChatCompletion {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  return {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) throw new OpenAIError(`missing role for choice ${index}`);\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          if (!name) throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          return {\n            ...choiceRest,\n            message: { content, function_call: { arguments: args, name }, role },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null)\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                if (type == null)\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                if (name == null)\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                if (args == null)\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'function' | 'tool';\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n","import {\n  Completions,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from \"../resources/chat/completions\";\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from \"../_shims/index\";\nimport { RunnableTools, type BaseFunctionsArgs, type RunnableFunctions } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs>;\n};\n\nexport class ChatCompletionStreamingRunner\n  extends ChatCompletionStream\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner {\n    const runner = new ChatCompletionStreamingRunner();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions<T extends (string | object)[]>(\n    completions: Completions,\n    params: ChatCompletionStreamingFunctionRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner {\n    const runner = new ChatCompletionStreamingRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(completions, params, opts));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[]>(\n    completions: Completions,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner {\n    const runner = new ChatCompletionStreamingRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(completions, params, opts));\n    return runner;\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nimport { BaseFunctionsArgs } from '../../../lib/RunnableFunction';\nexport {\n  RunnableFunction,\n  RunnableFunctions,\n  RunnableFunctionWithParse,\n  RunnableFunctionWithoutParse,\n  ParsingFunction,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\n\nexport class Completions extends APIResource {\n  /**\n   * @deprecated - use `runTools` instead.\n   */\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStreamingRunner;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner | ChatCompletionStreamingRunner {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runFunctions(\n        this._client.chat.completions,\n        body as ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n        options,\n      );\n    }\n    return ChatCompletionRunner.runFunctions(\n      this._client.chat.completions,\n      body as ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n      options,\n    );\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionToolRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner;\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStreamingRunner;\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    body:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner | ChatCompletionStreamingRunner {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client.chat.completions,\n        body as ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n        options,\n      );\n    }\n    return ChatCompletionRunner.runTools(\n      this._client.chat.completions,\n      body as ChatCompletionToolRunnerParams<FunctionsArgs>,\n      options,\n    );\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream(body: ChatCompletionStreamParams, options?: Core.RequestOptions): ChatCompletionStream {\n    return ChatCompletionStream.createChatCompletion(this._client.chat.completions, body, options);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport namespace Chat {\n  export import Completions = CompletionsAPI.Completions;\n}\n","import * as Core from \"../core\";\nimport { APIUserAbortError, OpenAIError } from \"../error\";\nimport { Run, RunSubmitToolOutputsParamsBase } from \"../resources/beta/threads/runs/runs\";\nimport { RunCreateParamsBase, Runs } from \"../resources/beta/threads/runs/runs\";\nimport { ThreadCreateAndRunParamsBase, Threads } from \"../resources/beta/threads/threads\";\n\nexport abstract class AbstractAssistantStreamRunner<\n  Events extends CustomEvents<any> = AbstractAssistantRunnerEvents,\n> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: { [Event in keyof Events]?: ListenersForEvent<Events, Event> } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        // this._emitFinal();\n        this._emit('end');\n      }, this.#handleError);\n    }, 0);\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected _connected() {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners: ListenersForEvent<Events, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\n    const listeners: ListenersForEvent<Events, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof Events>(\n    event: Event,\n  ): Promise<\n    EventParameters<Events, Event> extends [infer Param] ? Param\n    : EventParameters<Events, Event> extends [] ? void\n    : EventParameters<Events, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError = (error: unknown) => {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  };\n\n  protected _emit<Event extends keyof Events>(event: Event, ...args: EventParameters<Events, Event>) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: ListenersForEvent<Events, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...args));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected async _threadAssistantStream(\n    body: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, body, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, threadId, runId, params, options);\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    body: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    // this.#validateParams(params);\n\n    const runResult = await thread.createAndRun(\n      { ...body, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addRun(runResult as Run);\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    threadId: string,\n    runId: string,\n    params: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const runResult = await run.submitToolOutputs(\n      threadId,\n      runId,\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addRun(runResult as Run);\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    // this.#validateParams(params);\n\n    const runResult = await run.create(\n      threadId,\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addRun(runResult as Run);\n  }\n}\n\ntype CustomEvents<Event extends string> = {\n  [k in Event]: k extends keyof AbstractAssistantRunnerEvents ? AbstractAssistantRunnerEvents[k]\n  : (...args: any[]) => void;\n};\n\ntype ListenerForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Event extends (\n  keyof AbstractAssistantRunnerEvents\n) ?\n  AbstractAssistantRunnerEvents[Event]\n: Events[Event];\n\ntype ListenersForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Array<{\n  listener: ListenerForEvent<Events, Event>;\n  once?: boolean;\n}>;\ntype EventParameters<Events extends CustomEvents<any>, Event extends keyof Events> = Parameters<\n  ListenerForEvent<Events, Event>\n>;\n\nexport interface AbstractAssistantRunnerEvents {\n  connect: () => void;\n  run: (run: Run) => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n","import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  Messages,\n  MessageContent,\n} from \"../resources/beta/threads/messages\";\nimport * as Core from \"../core\";\nimport { RequestOptions } from \"../core\";\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from \"../resources/beta/threads/runs/runs\";\nimport {\n  AbstractAssistantRunnerEvents,\n  AbstractAssistantStreamRunner,\n} from './AbstractAssistantStreamRunner';\nimport { type ReadableStream } from \"../_shims/index\";\nimport { Stream } from \"../streaming\";\nimport { APIUserAbortError, OpenAIError } from \"../error\";\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from \"../resources/beta/assistants\";\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from \"../resources/beta/threads/runs/steps\";\nimport { ThreadCreateAndRunParamsBase, Threads } from \"../resources/beta/threads/threads\";\nimport MessageDelta = Messages.MessageDelta;\n\nexport interface AssistantStreamEvents extends AbstractAssistantRunnerEvents {\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  end: () => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends AbstractAssistantStreamRunner<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    body: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(threadId, runId, runs, body, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected override async _createToolAssistantStream(\n    run: Runs,\n    threadId: string,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(threadId, runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    body: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(body, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected override async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected override async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (Core.isObj(accValue) && Core.isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as MessagesAPI from './messages';\nimport * as AssistantsAPI from '../assistants';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   */\n  create(\n    threadId: string,\n    body: MessageCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   */\n  retrieve(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<Message> {\n    return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a message.\n   */\n  update(\n    threadId: string,\n    messageId: string,\n    body: MessageUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   */\n  list(\n    threadId: string,\n    query?: MessageListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<MessagesPage, Message>;\n  list(\n    threadId: string,\n    query: MessageListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/messages`, MessagesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Deletes a message.\n   */\n  del(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<MessageDeleted> {\n    return this._client.delete(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class MessagesPage extends CursorPage<Message> {}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent = ImageFileContentBlock | ImageURLContentBlock | TextContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta = ImageFileDeltaBlock | TextDeltaBlock | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nexport namespace Messages {\n  export import Annotation = MessagesAPI.Annotation;\n  export import AnnotationDelta = MessagesAPI.AnnotationDelta;\n  export import FileCitationAnnotation = MessagesAPI.FileCitationAnnotation;\n  export import FileCitationDeltaAnnotation = MessagesAPI.FileCitationDeltaAnnotation;\n  export import FilePathAnnotation = MessagesAPI.FilePathAnnotation;\n  export import FilePathDeltaAnnotation = MessagesAPI.FilePathDeltaAnnotation;\n  export import ImageFile = MessagesAPI.ImageFile;\n  export import ImageFileContentBlock = MessagesAPI.ImageFileContentBlock;\n  export import ImageFileDelta = MessagesAPI.ImageFileDelta;\n  export import ImageFileDeltaBlock = MessagesAPI.ImageFileDeltaBlock;\n  export import ImageURL = MessagesAPI.ImageURL;\n  export import ImageURLContentBlock = MessagesAPI.ImageURLContentBlock;\n  export import ImageURLDelta = MessagesAPI.ImageURLDelta;\n  export import ImageURLDeltaBlock = MessagesAPI.ImageURLDeltaBlock;\n  export import Message = MessagesAPI.Message;\n  export import MessageContent = MessagesAPI.MessageContent;\n  export import MessageContentDelta = MessagesAPI.MessageContentDelta;\n  export import MessageContentPartParam = MessagesAPI.MessageContentPartParam;\n  export import MessageDeleted = MessagesAPI.MessageDeleted;\n  export import MessageDelta = MessagesAPI.MessageDelta;\n  export import MessageDeltaEvent = MessagesAPI.MessageDeltaEvent;\n  export import Text = MessagesAPI.Text;\n  export import TextContentBlock = MessagesAPI.TextContentBlock;\n  export import TextContentBlockParam = MessagesAPI.TextContentBlockParam;\n  export import TextDelta = MessagesAPI.TextDelta;\n  export import TextDeltaBlock = MessagesAPI.TextDeltaBlock;\n  export import MessagesPage = MessagesAPI.MessagesPage;\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\n  export import MessageListParams = MessagesAPI.MessageListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../../core';\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport * as StepsAPI from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\n\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   */\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep> {\n    return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   */\n  list(\n    threadId: string,\n    runId: string,\n    query?: StepListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    query: StepListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, runId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class RunStepsPage extends CursorPage<RunStep> {}\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Steps {\n  export import CodeInterpreterLogs = StepsAPI.CodeInterpreterLogs;\n  export import CodeInterpreterOutputImage = StepsAPI.CodeInterpreterOutputImage;\n  export import CodeInterpreterToolCall = StepsAPI.CodeInterpreterToolCall;\n  export import CodeInterpreterToolCallDelta = StepsAPI.CodeInterpreterToolCallDelta;\n  export import FileSearchToolCall = StepsAPI.FileSearchToolCall;\n  export import FileSearchToolCallDelta = StepsAPI.FileSearchToolCallDelta;\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\n  export import FunctionToolCallDelta = StepsAPI.FunctionToolCallDelta;\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\n  export import RunStep = StepsAPI.RunStep;\n  export import RunStepDelta = StepsAPI.RunStepDelta;\n  export import RunStepDeltaEvent = StepsAPI.RunStepDeltaEvent;\n  export import RunStepDeltaMessageDelta = StepsAPI.RunStepDeltaMessageDelta;\n  export import ToolCall = StepsAPI.ToolCall;\n  export import ToolCallDelta = StepsAPI.ToolCallDelta;\n  export import ToolCallDeltaObject = StepsAPI.ToolCallDeltaObject;\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\n  export import RunStepsPage = StepsAPI.RunStepsPage;\n  export import StepListParams = StepsAPI.StepListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../../core';\nimport { APIPromise } from '../../../../core';\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../core';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport * as RunsAPI from './runs';\nimport * as AssistantsAPI from '../../assistants';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\nimport { Stream } from '../../../../streaming';\n\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   */\n  create(threadId: string, body: RunCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Run>;\n  create(\n    threadId: string,\n    body: RunCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadId: string,\n    body: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadId: string,\n    body: RunCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post(`/threads/${threadId}/runs`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   */\n  retrieve(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.get(`/threads/${threadId}/runs/${runId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a run.\n   */\n  update(\n    threadId: string,\n    runId: string,\n    body: RunUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   */\n  list(\n    threadId: string,\n    query?: RunListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<RunsPage, Run>;\n  list(\n    threadId: string,\n    query: RunListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   */\n  cancel(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(threadId, runId, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: Core.RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   */\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(threadId, runId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(\n      threadId,\n      runId,\n      this._client.beta.threads.runs,\n      body,\n      options,\n    );\n  }\n}\n\nexport class RunsPage extends CursorPage<Run> {}\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCreateAndPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndPollParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndPollParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndPollParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunCreateAndStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface RunSubmitToolOutputsAndPollParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsAndPollParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsAndPollParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport interface RunSubmitToolOutputsStreamParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsStreamParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsStreamParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport namespace Runs {\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\n  export import Run = RunsAPI.Run;\n  export import RunStatus = RunsAPI.RunStatus;\n  export import RunsPage = RunsAPI.RunsPage;\n  export import RunCreateParams = RunsAPI.RunCreateParams;\n  export import RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export import RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\n  export import RunListParams = RunsAPI.RunListParams;\n  export import RunCreateAndPollParams = RunsAPI.RunCreateAndPollParams;\n  export import RunCreateAndStreamParams = RunsAPI.RunCreateAndStreamParams;\n  export import RunStreamParams = RunsAPI.RunStreamParams;\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\n  export import RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export import RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n  export import RunSubmitToolOutputsAndPollParams = RunsAPI.RunSubmitToolOutputsAndPollParams;\n  export import RunSubmitToolOutputsStreamParams = RunsAPI.RunSubmitToolOutputsStreamParams;\n  export import Steps = StepsAPI.Steps;\n  export import CodeInterpreterLogs = StepsAPI.CodeInterpreterLogs;\n  export import CodeInterpreterOutputImage = StepsAPI.CodeInterpreterOutputImage;\n  export import CodeInterpreterToolCall = StepsAPI.CodeInterpreterToolCall;\n  export import CodeInterpreterToolCallDelta = StepsAPI.CodeInterpreterToolCallDelta;\n  export import FileSearchToolCall = StepsAPI.FileSearchToolCall;\n  export import FileSearchToolCallDelta = StepsAPI.FileSearchToolCallDelta;\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\n  export import FunctionToolCallDelta = StepsAPI.FunctionToolCallDelta;\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\n  export import RunStep = StepsAPI.RunStep;\n  export import RunStepDelta = StepsAPI.RunStepDelta;\n  export import RunStepDeltaEvent = StepsAPI.RunStepDeltaEvent;\n  export import RunStepDeltaMessageDelta = StepsAPI.RunStepDeltaMessageDelta;\n  export import ToolCall = StepsAPI.ToolCall;\n  export import ToolCallDelta = StepsAPI.ToolCallDelta;\n  export import ToolCallDeltaObject = StepsAPI.ToolCallDeltaObject;\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\n  export import RunStepsPage = StepsAPI.RunStepsPage;\n  export import StepListParams = StepsAPI.StepListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIPromise } from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport * as ThreadsAPI from './threads';\nimport * as AssistantsAPI from '../assistants';\nimport * as MessagesAPI from './messages';\nimport * as RunsAPI from './runs/runs';\nimport { Stream } from '../../../streaming';\n\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   */\n  create(body?: ThreadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(\n    body: ThreadCreateParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Thread> {\n    if (isRequestOptions(body)) {\n      return this.create({}, body);\n    }\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   */\n  retrieve(threadId: string, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.get(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   */\n  update(threadId: string, body: ThreadUpdateParams, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.post(`/threads/${threadId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a thread.\n   */\n  del(threadId: string, options?: Core.RequestOptions): Core.APIPromise<ThreadDeleted> {\n    return this._client.delete(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   */\n  createAndRun(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.thread_id, run.id, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(\n    body: ThreadCreateAndRunParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * An object describing the expected output of the model. If `json_object` only\n * `function` type `tools` are allowed to be passed to the Run. If `text` the model\n * can return text or any value needed.\n */\nexport interface AssistantResponseFormat {\n  /**\n   * Must be one of `text` or `json_object`.\n   */\n  type?: 'text' | 'json_object';\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption = 'none' | 'auto' | AssistantResponseFormat;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy.\n           */\n          chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n\n        export namespace VectorStore {\n          /**\n           * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n           * `800` and `chunk_overlap_tokens` of `400`.\n           */\n          export interface Auto {\n            /**\n             * Always `auto`.\n             */\n            type: 'auto';\n          }\n\n          export interface Static {\n            static: Static.Static;\n\n            /**\n             * Always `static`.\n             */\n            type: 'static';\n          }\n\n          export namespace Static {\n            export interface Static {\n              /**\n               * The number of tokens that overlap between chunks. The default value is `400`.\n               *\n               * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n               */\n              chunk_overlap_tokens: number;\n\n              /**\n               * The maximum number of tokens in each chunk. The default value is `800`. The\n               * minimum value is `100` and the maximum value is `4096`.\n               */\n              max_chunk_size_tokens: number;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface ThreadCreateAndRunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunStreamParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunStreamParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunStreamParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport namespace Threads {\n  export import AssistantResponseFormat = ThreadsAPI.AssistantResponseFormat;\n  export import AssistantResponseFormatOption = ThreadsAPI.AssistantResponseFormatOption;\n  export import AssistantToolChoice = ThreadsAPI.AssistantToolChoice;\n  export import AssistantToolChoiceFunction = ThreadsAPI.AssistantToolChoiceFunction;\n  export import AssistantToolChoiceOption = ThreadsAPI.AssistantToolChoiceOption;\n  export import Thread = ThreadsAPI.Thread;\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\n  export import ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export import ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n  export import ThreadCreateAndRunPollParams = ThreadsAPI.ThreadCreateAndRunPollParams;\n  export import ThreadCreateAndRunStreamParams = ThreadsAPI.ThreadCreateAndRunStreamParams;\n  export import Runs = RunsAPI.Runs;\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\n  export import Run = RunsAPI.Run;\n  export import RunStatus = RunsAPI.RunStatus;\n  export import RunsPage = RunsAPI.RunsPage;\n  export import RunCreateParams = RunsAPI.RunCreateParams;\n  export import RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export import RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\n  export import RunListParams = RunsAPI.RunListParams;\n  export import RunCreateAndPollParams = RunsAPI.RunCreateAndPollParams;\n  export import RunCreateAndStreamParams = RunsAPI.RunCreateAndStreamParams;\n  export import RunStreamParams = RunsAPI.RunStreamParams;\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\n  export import RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export import RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n  export import RunSubmitToolOutputsAndPollParams = RunsAPI.RunSubmitToolOutputsAndPollParams;\n  export import RunSubmitToolOutputsStreamParams = RunsAPI.RunSubmitToolOutputsStreamParams;\n  export import Messages = MessagesAPI.Messages;\n  export import Annotation = MessagesAPI.Annotation;\n  export import AnnotationDelta = MessagesAPI.AnnotationDelta;\n  export import FileCitationAnnotation = MessagesAPI.FileCitationAnnotation;\n  export import FileCitationDeltaAnnotation = MessagesAPI.FileCitationDeltaAnnotation;\n  export import FilePathAnnotation = MessagesAPI.FilePathAnnotation;\n  export import FilePathDeltaAnnotation = MessagesAPI.FilePathDeltaAnnotation;\n  export import ImageFile = MessagesAPI.ImageFile;\n  export import ImageFileContentBlock = MessagesAPI.ImageFileContentBlock;\n  export import ImageFileDelta = MessagesAPI.ImageFileDelta;\n  export import ImageFileDeltaBlock = MessagesAPI.ImageFileDeltaBlock;\n  export import ImageURL = MessagesAPI.ImageURL;\n  export import ImageURLContentBlock = MessagesAPI.ImageURLContentBlock;\n  export import ImageURLDelta = MessagesAPI.ImageURLDelta;\n  export import ImageURLDeltaBlock = MessagesAPI.ImageURLDeltaBlock;\n  export import Message = MessagesAPI.Message;\n  export import MessageContent = MessagesAPI.MessageContent;\n  export import MessageContentDelta = MessagesAPI.MessageContentDelta;\n  export import MessageContentPartParam = MessagesAPI.MessageContentPartParam;\n  export import MessageDeleted = MessagesAPI.MessageDeleted;\n  export import MessageDelta = MessagesAPI.MessageDelta;\n  export import MessageDeltaEvent = MessagesAPI.MessageDeltaEvent;\n  export import Text = MessagesAPI.Text;\n  export import TextContentBlock = MessagesAPI.TextContentBlock;\n  export import TextContentBlockParam = MessagesAPI.TextContentBlockParam;\n  export import TextDelta = MessagesAPI.TextDelta;\n  export import TextDeltaBlock = MessagesAPI.TextDeltaBlock;\n  export import MessagesPage = MessagesAPI.MessagesPage;\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\n  export import MessageListParams = MessagesAPI.MessageListParams;\n}\n","/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { sleep, Uploadable } from '../../../core';\nimport * as FilesAPI from './files';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreId: string,\n    query?: FileListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.list(vectorStoreId, {}, query);\n    }\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  del(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n    while (true) {\n      const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions,\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n}\n\nexport class VectorStoreFilesPage extends CursorPage<VectorStoreFile> {}\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoreFile.Static | VectorStoreFile.Other;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'internal_error' | 'file_not_found' | 'parsing_error' | 'unhandled_mime_type';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  export interface Static {\n    static: Static.Static;\n\n    /**\n     * Always `static`.\n     */\n    type: 'static';\n  }\n\n  export namespace Static {\n    export interface Static {\n      /**\n       * The number of tokens that overlap between chunks. The default value is `400`.\n       *\n       * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n       */\n      chunk_overlap_tokens: number;\n\n      /**\n       * The maximum number of tokens in each chunk. The default value is `800`. The\n       * minimum value is `100` and the maximum value is `4096`.\n       */\n      max_chunk_size_tokens: number;\n    }\n  }\n\n  /**\n   * This is returned when the chunking strategy is unknown. Typically, this is\n   * because the file was indexed before the `chunking_strategy` concept was\n   * introduced in the API.\n   */\n  export interface Other {\n    /**\n     * Always `other`.\n     */\n    type: 'other';\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy.\n   */\n  chunking_strategy?:\n    | FileCreateParams.AutoChunkingStrategyRequestParam\n    | FileCreateParams.StaticChunkingStrategyRequestParam;\n}\n\nexport namespace FileCreateParams {\n  /**\n   * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n   * `800` and `chunk_overlap_tokens` of `400`.\n   */\n  export interface AutoChunkingStrategyRequestParam {\n    /**\n     * Always `auto`.\n     */\n    type: 'auto';\n  }\n\n  export interface StaticChunkingStrategyRequestParam {\n    static: StaticChunkingStrategyRequestParam.Static;\n\n    /**\n     * Always `static`.\n     */\n    type: 'static';\n  }\n\n  export namespace StaticChunkingStrategyRequestParam {\n    export interface Static {\n      /**\n       * The number of tokens that overlap between chunks. The default value is `400`.\n       *\n       * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n       */\n      chunk_overlap_tokens: number;\n\n      /**\n       * The maximum number of tokens in each chunk. The default value is `800`. The\n       * minimum value is `100` and the maximum value is `4096`.\n       */\n      max_chunk_size_tokens: number;\n    }\n  }\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Files {\n  export import VectorStoreFile = FilesAPI.VectorStoreFile;\n  export import VectorStoreFileDeleted = FilesAPI.VectorStoreFileDeleted;\n  export import VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { sleep } from '../../../core';\nimport { Uploadable } from '../../../core';\nimport { allSettledWithThrow } from '../../../lib/Util';\nimport * as FileBatchesAPI from './file-batches';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport { type CursorPageParams } from '../../../pagination';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/file_batches/${batchId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query?: FileBatchListFilesParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query: FileBatchListFilesParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.listFiles(vectorStoreId, batchId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/vector_stores/${vectorStoreId}/file_batches/${batchId}/files`,\n      VectorStoreFilesPage,\n      { query, ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(vectorStoreId, batchId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: Core.RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files === null || files.length == 0) {\n      throw new Error('No files provided to process.');\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n    //We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    //This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    //Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    //Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids: Array<string>;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy.\n   */\n  chunking_strategy?:\n    | FileBatchCreateParams.AutoChunkingStrategyRequestParam\n    | FileBatchCreateParams.StaticChunkingStrategyRequestParam;\n}\n\nexport namespace FileBatchCreateParams {\n  /**\n   * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n   * `800` and `chunk_overlap_tokens` of `400`.\n   */\n  export interface AutoChunkingStrategyRequestParam {\n    /**\n     * Always `auto`.\n     */\n    type: 'auto';\n  }\n\n  export interface StaticChunkingStrategyRequestParam {\n    static: StaticChunkingStrategyRequestParam.Static;\n\n    /**\n     * Always `static`.\n     */\n    type: 'static';\n  }\n\n  export namespace StaticChunkingStrategyRequestParam {\n    export interface Static {\n      /**\n       * The number of tokens that overlap between chunks. The default value is `400`.\n       *\n       * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n       */\n      chunk_overlap_tokens: number;\n\n      /**\n       * The maximum number of tokens in each chunk. The default value is `800`. The\n       * minimum value is `100` and the maximum value is `4096`.\n       */\n      max_chunk_size_tokens: number;\n    }\n  }\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace FileBatches {\n  export import VectorStoreFileBatch = FileBatchesAPI.VectorStoreFileBatch;\n  export import FileBatchCreateParams = FileBatchesAPI.FileBatchCreateParams;\n  export import FileBatchListFilesParams = FileBatchesAPI.FileBatchListFilesParams;\n}\n\nexport { VectorStoreFilesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as VectorStoresAPI from './vector-stores';\nimport * as FileBatchesAPI from './file-batches';\nimport * as FilesAPI from './files';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.get(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreId: string,\n    body: VectorStoreUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStore> {\n    return this._client.post(`/vector_stores/${vectorStoreId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query?: VectorStoreListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(options?: Core.RequestOptions): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(\n    query: VectorStoreListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/vector_stores', VectorStoresPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  del(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStoreDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class VectorStoresPage extends CursorPage<VectorStore> {}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoreCreateParams.Auto | VectorStoreCreateParams.Static;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n   * `800` and `chunk_overlap_tokens` of `400`.\n   */\n  export interface Auto {\n    /**\n     * Always `auto`.\n     */\n    type: 'auto';\n  }\n\n  export interface Static {\n    static: Static.Static;\n\n    /**\n     * Always `static`.\n     */\n    type: 'static';\n  }\n\n  export namespace Static {\n    export interface Static {\n      /**\n       * The number of tokens that overlap between chunks. The default value is `400`.\n       *\n       * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n       */\n      chunk_overlap_tokens: number;\n\n      /**\n       * The maximum number of tokens in each chunk. The default value is `800`. The\n       * minimum value is `100` and the maximum value is `4096`.\n       */\n      max_chunk_size_tokens: number;\n    }\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace VectorStores {\n  export import VectorStore = VectorStoresAPI.VectorStore;\n  export import VectorStoreDeleted = VectorStoresAPI.VectorStoreDeleted;\n  export import VectorStoresPage = VectorStoresAPI.VectorStoresPage;\n  export import VectorStoreCreateParams = VectorStoresAPI.VectorStoreCreateParams;\n  export import VectorStoreUpdateParams = VectorStoresAPI.VectorStoreUpdateParams;\n  export import VectorStoreListParams = VectorStoresAPI.VectorStoreListParams;\n  export import Files = FilesAPI.Files;\n  export import VectorStoreFile = FilesAPI.VectorStoreFile;\n  export import VectorStoreFileDeleted = FilesAPI.VectorStoreFileDeleted;\n  export import VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n  export import FileBatches = FileBatchesAPI.FileBatches;\n  export import VectorStoreFileBatch = FileBatchesAPI.VectorStoreFileBatch;\n  export import FileBatchCreateParams = FileBatchesAPI.FileBatchCreateParams;\n  export import FileBatchListFilesParams = FileBatchesAPI.FileBatchListFilesParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as AssistantsAPI from './assistants';\nimport * as ChatAPI from './chat/chat';\nimport * as ThreadsAPI from './threads/threads';\nimport * as VectorStoresAPI from './vector-stores/vector-stores';\n\nexport class Beta extends APIResource {\n  vectorStores: VectorStoresAPI.VectorStores = new VectorStoresAPI.VectorStores(this._client);\n  chat: ChatAPI.Chat = new ChatAPI.Chat(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nexport namespace Beta {\n  export import VectorStores = VectorStoresAPI.VectorStores;\n  export import VectorStore = VectorStoresAPI.VectorStore;\n  export import VectorStoreDeleted = VectorStoresAPI.VectorStoreDeleted;\n  export import VectorStoresPage = VectorStoresAPI.VectorStoresPage;\n  export import VectorStoreCreateParams = VectorStoresAPI.VectorStoreCreateParams;\n  export import VectorStoreUpdateParams = VectorStoresAPI.VectorStoreUpdateParams;\n  export import VectorStoreListParams = VectorStoresAPI.VectorStoreListParams;\n  export import Chat = ChatAPI.Chat;\n  export import Assistants = AssistantsAPI.Assistants;\n  export import Assistant = AssistantsAPI.Assistant;\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\n  export import AssistantStreamEvent = AssistantsAPI.AssistantStreamEvent;\n  export import AssistantTool = AssistantsAPI.AssistantTool;\n  export import CodeInterpreterTool = AssistantsAPI.CodeInterpreterTool;\n  export import FileSearchTool = AssistantsAPI.FileSearchTool;\n  export import FunctionTool = AssistantsAPI.FunctionTool;\n  export import MessageStreamEvent = AssistantsAPI.MessageStreamEvent;\n  export import RunStepStreamEvent = AssistantsAPI.RunStepStreamEvent;\n  export import RunStreamEvent = AssistantsAPI.RunStreamEvent;\n  export import ThreadStreamEvent = AssistantsAPI.ThreadStreamEvent;\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\n  export import Threads = ThreadsAPI.Threads;\n  export import AssistantResponseFormat = ThreadsAPI.AssistantResponseFormat;\n  export import AssistantResponseFormatOption = ThreadsAPI.AssistantResponseFormatOption;\n  export import AssistantToolChoice = ThreadsAPI.AssistantToolChoice;\n  export import AssistantToolChoiceFunction = ThreadsAPI.AssistantToolChoiceFunction;\n  export import AssistantToolChoiceOption = ThreadsAPI.AssistantToolChoiceOption;\n  export import Thread = ThreadsAPI.Thread;\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\n  export import ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export import ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n  export import ThreadCreateAndRunPollParams = ThreadsAPI.ThreadCreateAndRunPollParams;\n  export import ThreadCreateAndRunStreamParams = ThreadsAPI.ThreadCreateAndRunStreamParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIPromise } from '../core';\nimport { APIResource } from '../resource';\nimport * as CompletionsAPI from './completions';\nimport * as ChatCompletionsAPI from './chat/completions';\nimport { Stream } from '../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\n  create(\n    body: CompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<Record<string, number>>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return  `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport namespace Completions {\n  export import Completion = CompletionsAPI.Completion;\n  export import CompletionChoice = CompletionsAPI.CompletionChoice;\n  export import CompletionUsage = CompletionsAPI.CompletionUsage;\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport * as EmbeddingsAPI from './embeddings';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   */\n  create(\n    body: EmbeddingCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<CreateEmbeddingResponse> {\n    return this._client.post('/embeddings', { body, ...options });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: (string & {}) | 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace Embeddings {\n  export import CreateEmbeddingResponse = EmbeddingsAPI.CreateEmbeddingResponse;\n  export import Embedding = EmbeddingsAPI.Embedding;\n  export import EmbeddingCreateParams = EmbeddingsAPI.EmbeddingCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport { type Response } from '../_shims/index';\nimport { sleep } from '../core';\nimport { APIConnectionTimeoutError } from '../error';\nimport * as FilesAPI from './files';\nimport { type Uploadable, multipartFormRequestOptions } from '../core';\nimport { Page } from '../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and the size of all files uploaded by one organization can be up\n   * to 100 GB.\n   *\n   * The Assistants API supports files up to 2 million tokens and of specific file\n   * types. See the\n   * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for\n   * details.\n   *\n   * The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   * required formats for fine-tuning\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * models.\n   *\n   * The Batch API only supports `.jsonl` files up to 100 MB in size. The input also\n   * has a specific required\n   * [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.post('/files', multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.get(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns a list of files that belong to the user's organization.\n   */\n  list(query?: FileListParams, options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FileObjectsPage, FileObject> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\n  }\n\n  /**\n   * Delete a file.\n   */\n  del(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileDeleted> {\n    return this._client.delete(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileId: string, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.get(`/files/${fileId}/content`, { ...options, __binaryResponse: true });\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   *\n   * @deprecated The `.content()` method should be used instead\n   */\n  retrieveContent(fileId: string, options?: Core.RequestOptions): Core.APIPromise<string> {\n    return this._client.get(`/files/${fileId}/content`, {\n      ...options,\n      headers: { Accept: 'application/json', ...options?.headers },\n    });\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class FileObjectsPage extends Page<FileObject> {}\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\n   * and `vision`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision';\n\n  /**\n   * @deprecated: Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * @deprecated: Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * Use \"assistants\" for\n   * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\n   * [Message](https://platform.openai.com/docs/api-reference/messages) files,\n   * \"vision\" for Assistants image file inputs, \"batch\" for\n   * [Batch API](https://platform.openai.com/docs/guides/batch), and \"fine-tune\" for\n   * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n   */\n  purpose: 'assistants' | 'batch' | 'fine-tune' | 'vision';\n}\n\nexport interface FileListParams {\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nexport namespace Files {\n  export import FileContent = FilesAPI.FileContent;\n  export import FileDeleted = FilesAPI.FileDeleted;\n  export import FileObject = FilesAPI.FileObject;\n  export import FileObjectsPage = FilesAPI.FileObjectsPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as CheckpointsAPI from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   */\n  list(\n    fineTuningJobId: string,\n    query?: CheckpointListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    query: CheckpointListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    if (isRequestOptions(query)) {\n      return this.list(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/fine_tuning/jobs/${fineTuningJobId}/checkpoints`,\n      FineTuningJobCheckpointsPage,\n      { query, ...options },\n    );\n  }\n}\n\nexport class FineTuningJobCheckpointsPage extends CursorPage<FineTuningJobCheckpoint> {}\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nexport namespace Checkpoints {\n  export import FineTuningJobCheckpoint = CheckpointsAPI.FineTuningJobCheckpoint;\n  export import FineTuningJobCheckpointsPage = CheckpointsAPI.FineTuningJobCheckpointsPage;\n  export import CheckpointListParams = CheckpointsAPI.CheckpointListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as JobsAPI from './jobs';\nimport * as CheckpointsAPI from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  create(body: JobCreateParams, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  retrieve(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   */\n  list(\n    query?: JobListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(\n    query: JobListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   */\n  cancel(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   */\n  listEvents(\n    fineTuningJobId: string,\n    query?: JobListEventsParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    query: JobListEventsParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    if (isRequestOptions(query)) {\n      return this.listEvents(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\n      query,\n      ...options,\n    });\n  }\n}\n\nexport class FineTuningJobsPage extends CursorPage<FineTuningJob> {}\n\nexport class FineTuningJobEventsPage extends CursorPage<FineTuningJobEvent> {}\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  export interface Hyperparameters {\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset. \"auto\" decides the optimal number of epochs based\n     * on the size of the dataset. If setting the number manually, we support any\n     * number between 1 and 50 epochs.\n     */\n    n_epochs: 'auto' | number;\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  id: string;\n\n  created_at: number;\n\n  level: 'info' | 'warn' | 'error';\n\n  message: string;\n\n  object: 'fine_tuning.job.event';\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 18 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nexport namespace Jobs {\n  export import FineTuningJob = JobsAPI.FineTuningJob;\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\n  export import FineTuningJobIntegration = JobsAPI.FineTuningJobIntegration;\n  export import FineTuningJobWandbIntegration = JobsAPI.FineTuningJobWandbIntegration;\n  export import FineTuningJobWandbIntegrationObject = JobsAPI.FineTuningJobWandbIntegrationObject;\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\n  export import JobCreateParams = JobsAPI.JobCreateParams;\n  export import JobListParams = JobsAPI.JobListParams;\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\n  export import Checkpoints = CheckpointsAPI.Checkpoints;\n  export import FineTuningJobCheckpoint = CheckpointsAPI.FineTuningJobCheckpoint;\n  export import FineTuningJobCheckpointsPage = CheckpointsAPI.FineTuningJobCheckpointsPage;\n  export import CheckpointListParams = CheckpointsAPI.CheckpointListParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as JobsAPI from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n}\n\nexport namespace FineTuning {\n  export import Jobs = JobsAPI.Jobs;\n  export import FineTuningJob = JobsAPI.FineTuningJob;\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\n  export import FineTuningJobIntegration = JobsAPI.FineTuningJobIntegration;\n  export import FineTuningJobWandbIntegration = JobsAPI.FineTuningJobWandbIntegration;\n  export import FineTuningJobWandbIntegrationObject = JobsAPI.FineTuningJobWandbIntegrationObject;\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\n  export import JobCreateParams = JobsAPI.JobCreateParams;\n  export import JobListParams = JobsAPI.JobListParams;\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport * as ImagesAPI from './images';\nimport { type Uploadable, multipartFormRequestOptions } from '../core';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image.\n   */\n  createVariation(\n    body: ImageCreateVariationParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/variations', multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an edited or extended image given an original image and a prompt.\n   */\n  edit(body: ImageEditParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/edits', multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an image given a prompt.\n   */\n  generate(body: ImageGenerateParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/generations', { body, ...options });\n  }\n}\n\n/**\n * Represents the url or the content of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image, if `response_format` is\n   * `b64_json`.\n   */\n  b64_json?: string;\n\n  /**\n   * The prompt that was used to generate the image, if there was any revision to the\n   * prompt.\n   */\n  revised_prompt?: string;\n\n  /**\n   * The URL of the generated image, if `response_format` is `url` (default).\n   */\n  url?: string;\n}\n\nexport interface ImagesResponse {\n  created: number;\n\n  data: Array<Image>;\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | 'dall-e-2' | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageEditParams {\n  /**\n   * The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask\n   * is not provided, image must have transparency, which will be used as the mask.\n   */\n  image: Uploadable;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters.\n   */\n  prompt: string;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | 'dall-e-2' | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageGenerateParams {\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2` and 4000 characters for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * The model to use for image generation.\n   */\n  model?: (string & {}) | 'dall-e-2' | 'dall-e-3' | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `hd` creates images with finer\n   * details and greater consistency across the image. This param is only supported\n   * for `dall-e-3`.\n   */\n  quality?: 'standard' | 'hd';\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or\n   * `1024x1792` for `dall-e-3` models.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792' | null;\n\n  /**\n   * The style of the generated images. Must be one of `vivid` or `natural`. Vivid\n   * causes the model to lean towards generating hyper-real and dramatic images.\n   * Natural causes the model to produce more natural, less hyper-real looking\n   * images. This param is only supported for `dall-e-3`.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace Images {\n  export import Image = ImagesAPI.Image;\n  export import ImagesResponse = ImagesAPI.ImagesResponse;\n  export import ImageCreateVariationParams = ImagesAPI.ImageCreateVariationParams;\n  export import ImageEditParams = ImagesAPI.ImageEditParams;\n  export import ImageGenerateParams = ImagesAPI.ImageGenerateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport * as ModelsAPI from './models';\nimport { Page } from '../pagination';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: Core.RequestOptions): Core.APIPromise<Model> {\n    return this._client.get(`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: Core.RequestOptions): Core.PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', ModelsPage, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  del(model: string, options?: Core.RequestOptions): Core.APIPromise<ModelDeleted> {\n    return this._client.delete(`/models/${model}`, options);\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class ModelsPage extends Page<Model> {}\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nexport namespace Models {\n  export import Model = ModelsAPI.Model;\n  export import ModelDeleted = ModelsAPI.ModelDeleted;\n  export import ModelsPage = ModelsAPI.ModelsPage;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport * as ModerationsAPI from './moderations';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text is potentially harmful.\n   */\n  create(\n    body: ModerationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * The input text to classify\n   */\n  input: string | Array<string>;\n\n  /**\n   * Two content moderations models are available: `text-moderation-stable` and\n   * `text-moderation-latest`.\n   *\n   * The default is `text-moderation-latest` which will be automatically upgraded\n   * over time. This ensures you are always using our most accurate model. If you use\n   * `text-moderation-stable`, we will provide advanced notice before updating the\n   * model. Accuracy of `text-moderation-stable` may be slightly lower than for\n   * `text-moderation-latest`.\n   */\n  model?: (string & {}) | 'text-moderation-latest' | 'text-moderation-stable';\n}\n\nexport namespace Moderations {\n  export import Moderation = ModerationsAPI.Moderation;\n  export import ModerationCreateResponse = ModerationsAPI.ModerationCreateResponse;\n  export import ModerationCreateParams = ModerationsAPI.ModerationCreateParams;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from './core';\nimport * as Errors from './error';\nimport { type Agent, type RequestInit } from './_shims/index';\nimport * as Uploads from './uploads';\nimport * as Pagination from './pagination';\nimport * as API from './resources/index';\n\nexport interface ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   */\n  timeout?: number;\n\n  /**\n   * An HTTP agent used to manage HTTP(S) connections.\n   *\n   * If not provided, an agent will be constructed by default in the Node.js environment,\n   * otherwise no agent is used.\n   */\n  httpAgent?: Agent;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we use `node-fetch` on Node.js and otherwise expect that `fetch` is\n   * defined globally.\n   */\n  fetch?: Core.Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `undefined` or `null` in request options.\n   */\n  defaultHeaders?: Core.Headers;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Core.DefaultQuery;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean;\n}\n\n/** API Client for interfacing with the OpenAI API. */\nexport class OpenAI extends Core.APIClient {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n\n  private _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('OPENAI_API_KEY'),\n    organization = Core.readEnv('OPENAI_ORG_ID') ?? null,\n    project = Core.readEnv('OPENAI_PROJECT_ID') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\",\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && Core.isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    super({\n      baseURL: options.baseURL!,\n      timeout: options.timeout ?? 600000 /* 10 minutes */,\n      httpAgent: options.httpAgent,\n      maxRetries: options.maxRetries,\n      fetch: options.fetch,\n    });\n    this._options = options;\n\n    this.apiKey = apiKey;\n    this.organization = organization;\n    this.project = project;\n  }\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n\n  protected override defaultQuery(): Core.DefaultQuery | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected override defaultHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {\n      ...super.defaultHeaders(opts),\n      'OpenAI-Organization': this.organization,\n      'OpenAI-Project': this.project,\n      ...this._options.defaultHeaders,\n    };\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return { Authorization: `Bearer ${this.apiKey}` };\n  }\n\n  static OpenAI = this;\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n\n  static toFile = Uploads.toFile;\n  static fileFromPath = Uploads.fileFromPath;\n}\n\nexport const {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n} = Errors;\n\nexport import toFile = Uploads.toFile;\nexport import fileFromPath = Uploads.fileFromPath;\n\nexport namespace OpenAI {\n  export import RequestOptions = Core.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export import PageResponse = Pagination.PageResponse;\n\n  export import CursorPage = Pagination.CursorPage;\n  export import CursorPageParams = Pagination.CursorPageParams;\n  export import CursorPageResponse = Pagination.CursorPageResponse;\n\n  export import Completions = API.Completions;\n  export import Completion = API.Completion;\n  export import CompletionChoice = API.CompletionChoice;\n  export import CompletionUsage = API.CompletionUsage;\n  export import CompletionCreateParams = API.CompletionCreateParams;\n  export import CompletionCreateParamsNonStreaming = API.CompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsStreaming = API.CompletionCreateParamsStreaming;\n\n  export import Chat = API.Chat;\n  export import ChatModel = API.ChatModel;\n  export import ChatCompletion = API.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = API.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = API.ChatCompletionChunk;\n  export import ChatCompletionContentPart = API.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = API.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartText = API.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = API.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = API.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = API.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = API.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = API.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = API.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = API.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = API.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = API.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = API.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = API.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = API.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = API.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = API.ChatCompletionUserMessageParam;\n  export import ChatCompletionCreateParams = API.ChatCompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = API.ChatCompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = API.ChatCompletionCreateParamsStreaming;\n\n  export import Embeddings = API.Embeddings;\n  export import CreateEmbeddingResponse = API.CreateEmbeddingResponse;\n  export import Embedding = API.Embedding;\n  export import EmbeddingCreateParams = API.EmbeddingCreateParams;\n\n  export import Files = API.Files;\n  export import FileContent = API.FileContent;\n  export import FileDeleted = API.FileDeleted;\n  export import FileObject = API.FileObject;\n  export import FileObjectsPage = API.FileObjectsPage;\n  export import FileCreateParams = API.FileCreateParams;\n  export import FileListParams = API.FileListParams;\n\n  export import Images = API.Images;\n  export import Image = API.Image;\n  export import ImagesResponse = API.ImagesResponse;\n  export import ImageCreateVariationParams = API.ImageCreateVariationParams;\n  export import ImageEditParams = API.ImageEditParams;\n  export import ImageGenerateParams = API.ImageGenerateParams;\n\n  export import Audio = API.Audio;\n\n  export import Moderations = API.Moderations;\n  export import Moderation = API.Moderation;\n  export import ModerationCreateResponse = API.ModerationCreateResponse;\n  export import ModerationCreateParams = API.ModerationCreateParams;\n\n  export import Models = API.Models;\n  export import Model = API.Model;\n  export import ModelDeleted = API.ModelDeleted;\n  export import ModelsPage = API.ModelsPage;\n\n  export import FineTuning = API.FineTuning;\n\n  export import Beta = API.Beta;\n\n  export import Batches = API.Batches;\n  export import Batch = API.Batch;\n  export import BatchError = API.BatchError;\n  export import BatchRequestCounts = API.BatchRequestCounts;\n  export import BatchesPage = API.BatchesPage;\n  export import BatchCreateParams = API.BatchCreateParams;\n  export import BatchListParams = API.BatchListParams;\n\n  export import ErrorObject = API.ErrorObject;\n  export import FunctionDefinition = API.FunctionDefinition;\n  export import FunctionParameters = API.FunctionParameters;\n}\n\n// ---------------------- Azure ----------------------\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  private _azureADTokenProvider: (() => Promise<string>) | undefined;\n  private _deployment: string | undefined;\n  apiVersion: string = '';\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = Core.readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    // define a sentinel value to avoid any typing issues\n    apiKey ??= API_KEY_SENTINEL;\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this._azureADTokenProvider = azureADTokenProvider;\n    this.apiVersion = apiVersion;\n    this._deployment = deployment;\n  }\n\n  override buildRequest(options: Core.FinalRequestOptions<unknown>): {\n    req: RequestInit;\n    url: string;\n    timeout: number;\n  } {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!Core.isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this._deployment || options.body['model'];\n      delete options.body['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options);\n  }\n\n  private async _getAzureADToken(): Promise<string | undefined> {\n    if (typeof this._azureADTokenProvider === 'function') {\n      const token = await this._azureADTokenProvider();\n      if (!token || typeof token !== 'string') {\n        throw new Errors.OpenAIError(\n          `Expected 'azureADTokenProvider' argument to return a string but it returned ${token}`,\n        );\n      }\n      return token;\n    }\n    return undefined;\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {};\n  }\n\n  protected override async prepareOptions(opts: Core.FinalRequestOptions<unknown>): Promise<void> {\n    if (opts.headers?.['Authorization'] || opts.headers?.['api-key']) {\n      return super.prepareOptions(opts);\n    }\n    const token = await this._getAzureADToken();\n    opts.headers ??= {};\n    if (token) {\n      opts.headers['Authorization'] = `Bearer ${token}`;\n    } else if (this.apiKey !== API_KEY_SENTINEL) {\n      opts.headers['api-key'] = this.apiKey;\n    } else {\n      throw new Errors.OpenAIError('Unable to handle auth');\n    }\n    return super.prepareOptions(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n]);\n\nconst API_KEY_SENTINEL = '<Missing Key>';\n\n// ---------------------- End Azure ----------------------\n\nexport default OpenAI;\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAIA,QAAI,IAAI;AACR,QAAI,IAAI,IAAI;AACZ,QAAI,IAAI,IAAI;AACZ,QAAI,IAAI,IAAI;AACZ,QAAI,IAAI,IAAI;AACZ,QAAI,IAAI,IAAI;AAgBZ,WAAO,UAAU,SAAU,KAAK,SAAS;AACvC,gBAAU,WAAW,CAAC;AACtB,UAAI,OAAO,OAAO;AAClB,UAAI,SAAS,YAAY,IAAI,SAAS,GAAG;AACvC,eAAO,MAAM,GAAG;AAAA,MAClB,WAAW,SAAS,YAAY,SAAS,GAAG,GAAG;AAC7C,eAAO,QAAQ,OAAO,QAAQ,GAAG,IAAI,SAAS,GAAG;AAAA,MACnD;AACA,YAAM,IAAI;AAAA,QACR,0DACE,KAAK,UAAU,GAAG;AAAA,MACtB;AAAA,IACF;AAUA,aAAS,MAAMA,MAAK;AAClB,MAAAA,OAAM,OAAOA,IAAG;AAChB,UAAIA,KAAI,SAAS,KAAK;AACpB;AAAA,MACF;AACA,UAAI,QAAQ,mIAAmI;AAAA,QAC7IA;AAAA,MACF;AACA,UAAI,CAAC,OAAO;AACV;AAAA,MACF;AACA,UAAI,IAAI,WAAW,MAAM,CAAC,CAAC;AAC3B,UAAI,QAAQ,MAAM,CAAC,KAAK,MAAM,YAAY;AAC1C,cAAQ,MAAM;AAAA,QACZ,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO,IAAI;AAAA,QACb,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AACH,iBAAO;AAAA,QACT;AACE,iBAAO;AAAA,MACX;AAAA,IACF;AAUA,aAAS,SAAS,IAAI;AACpB,UAAI,QAAQ,KAAK,IAAI,EAAE;AACvB,UAAI,SAAS,GAAG;AACd,eAAO,KAAK,MAAM,KAAK,CAAC,IAAI;AAAA,MAC9B;AACA,UAAI,SAAS,GAAG;AACd,eAAO,KAAK,MAAM,KAAK,CAAC,IAAI;AAAA,MAC9B;AACA,UAAI,SAAS,GAAG;AACd,eAAO,KAAK,MAAM,KAAK,CAAC,IAAI;AAAA,MAC9B;AACA,UAAI,SAAS,GAAG;AACd,eAAO,KAAK,MAAM,KAAK,CAAC,IAAI;AAAA,MAC9B;AACA,aAAO,KAAK;AAAA,IACd;AAUA,aAAS,QAAQ,IAAI;AACnB,UAAI,QAAQ,KAAK,IAAI,EAAE;AACvB,UAAI,SAAS,GAAG;AACd,eAAO,OAAO,IAAI,OAAO,GAAG,KAAK;AAAA,MACnC;AACA,UAAI,SAAS,GAAG;AACd,eAAO,OAAO,IAAI,OAAO,GAAG,MAAM;AAAA,MACpC;AACA,UAAI,SAAS,GAAG;AACd,eAAO,OAAO,IAAI,OAAO,GAAG,QAAQ;AAAA,MACtC;AACA,UAAI,SAAS,GAAG;AACd,eAAO,OAAO,IAAI,OAAO,GAAG,QAAQ;AAAA,MACtC;AACA,aAAO,KAAK;AAAA,IACd;AAMA,aAAS,OAAO,IAAI,OAAO,GAAG,MAAM;AAClC,UAAI,WAAW,SAAS,IAAI;AAC5B,aAAO,KAAK,MAAM,KAAK,CAAC,IAAI,MAAM,QAAQ,WAAW,MAAM;AAAA,IAC7D;AAAA;AAAA;;;ACjKA;AAAA;AAAA;AAYA,QAAI,OAAO,UAAQ,MAAM;AACzB,QAAI,KAAK;AAET,WAAO,UAAU,SAAU,GAAG;AAC5B,UAAI,OAAO,MAAM;AAAU,eAAO;AAClC,UAAI,IAAI,GAAG,CAAC;AACZ,UAAI,MAAM,QAAW;AACnB,YAAI,MAAM,IAAI,MAAM,KAAK,OAAO,oCAAoC,CAAC,CAAC;AACtE,gBAAQ,KAAK,IAAI,KAAK;AAAA,MACxB;AACA,aAAO;AAAA,IACT;AAAA;AAAA;;;ACvBA;AAAA;AAAA;AAEA,WAAO,UAAU;AAAA;AAAA,MAEf,YAAY,OAAO,0BAA0B;AAAA,MAC7C,WAAW,OAAO,yBAAyB;AAAA,MAC3C,aAAa,OAAO,2BAA2B;AAAA,MAC/C,yBAAyB,OAAO,sCAAsC;AAAA;AAAA,MAEtE,qBAAqB,OAAO,kCAAkC;AAAA,MAC9D,aAAa,OAAO,2BAA2B;AAAA,MAC/C,sBAAsB,OAAO,mCAAmC;AAAA,MAChE,+BAA+B,OAAO,2CAA2C;AAAA,IACnF;AAAA;AAAA;;;ACbA;AAAA;AAAA;AAEA,QAAM,gBAAgB,UAAQ,MAAM,EAAE;AACtC,QAAM,KAAK;AACX,QAAMC,SAAQ,UAAQ,MAAM,EAAE,SAAS,gBAAgB;AACvD,QAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,IAAI;AAOJ,QAAI,8BAA8B;AAClC,QAAM,eAAe,SAAS,QAAQ,QAAQ,MAAM,KAAK,CAAC,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC;AAC3E,QAAI,gBAAgB,MAAM,gBAAgB,IAAI;AAC5C,oCAA8B;AAAA,IAChC,WAAW,gBAAgB,IAAI;AAC7B,oCAA8B;AAAA,IAChC;AAEA,aAASC,WAAU,SAAS;AAC1B,cAAQ,IAAI,kCAAkC,OAAO;AAAA,IACvD;AAEA,QAAM,QAAN,cAAoB,cAAc;AAAA,MAChC,YAAY,SAAS;AACnB,kBAAU,WAAW,CAAC;AACtB,gBAAQ,YAAY,QAAQ,cAAc;AAG1C,YAAI,QAAQ,sBAAsB,QAAW;AAC3C,kBAAQ,oBAAoB;AAAA,QAC9B;AAEA,YAAI,QAAQ,kBAAkB;AAC5B,UAAAA,WAAU,sFAAsF;AAChG,kBAAQ,oBAAoB,QAAQ;AACpC,iBAAO,QAAQ;AAAA,QACjB;AAEA,YAAI,QAAQ,4BAA4B;AACtC,UAAAA,WAAU,gGAAgG;AAC1G,kBAAQ,oBAAoB,QAAQ;AACpC,iBAAO,QAAQ;AAAA,QACjB;AAIA,YAAI,QAAQ,YAAY,QAAW;AAEjC,kBAAQ,UAAU,KAAK,IAAI,QAAQ,oBAAoB,GAAG,GAAI;AAAA,QAChE;AAGA,gBAAQ,UAAU,GAAG,QAAQ,OAAO;AACpC,gBAAQ,oBAAoB,GAAG,QAAQ,iBAAiB;AACxD,gBAAQ,kBAAkB,QAAQ,kBAAkB,GAAG,QAAQ,eAAe,IAAI;AAElF,cAAM,OAAO;AAEb,aAAK,UAAU,IAAI;AAGnB,aAAK,oBAAoB;AACzB,aAAK,6BAA6B;AAElC,aAAK,yBAAyB;AAC9B,aAAK,kCAAkC;AAEvC,aAAK,mBAAmB;AACxB,aAAK,4BAA4B;AAGjC,aAAK,mBAAmB;AACxB,aAAK,4BAA4B;AAGjC,aAAK,eAAe;AACpB,aAAK,wBAAwB;AAG7B,aAAK,qBAAqB;AAC1B,aAAK,8BAA8B;AAEnC,aAAK,GAAG,QAAQ,YAAU;AAIxB,gBAAM,UAAU,KAAK,kBAAkB,MAAM;AAC7C,cAAI,UAAU,KAAK,OAAO,YAAY,SAAS;AAC7C,mBAAO,WAAW,OAAO;AAAA,UAC3B;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,IAAI,6BAA6B;AAC/B,QAAAA,WAAU,oGAAoG;AAC9G,eAAO,KAAK,QAAQ;AAAA,MACtB;AAAA,MAEA,IAAI,UAAU;AACZ,QAAAA,WAAU,uEAAuE;AACjF,eAAO,KAAK,QAAQ;AAAA,MACtB;AAAA,MAEA,IAAI,kBAAkB;AACpB,QAAAA,WAAU,uFAAuF;AACjG,eAAO,KAAK,QAAQ;AAAA,MACtB;AAAA,MAEA,kBAAkB,QAAQ;AAMxB,YAAI,oBAAoB,KAAK,QAAQ;AACrC,cAAM,kBAAkB,KAAK,QAAQ;AACrC,YAAI,iBAAiB;AAEnB,gBAAM,YAAY,KAAK,IAAI,IAAI,OAAO,mBAAmB;AACzD,gBAAM,OAAO,kBAAkB;AAC/B,cAAI,QAAQ,GAAG;AACb,mBAAO;AAAA,UACT;AACA,cAAI,qBAAqB,OAAO,mBAAmB;AACjD,gCAAoB;AAAA,UACtB;AAAA,QACF;AAEA,YAAI,mBAAmB;AAIrB,gBAAM,0BAA0B,OAAO,qBAAqB,OAAO;AACnE,iBAAO,2BAA2B;AAAA,QACpC;AAAA,MACF;AAAA,MAEA,gBAAgB,QAAQ;AACtB,cAAM,SAAS,MAAM,gBAAgB,MAAM;AAE3C,YAAI,CAAC;AAAQ,iBAAO;AAEpB,cAAM,gBAAgB,KAAK,kBAAkB,MAAM;AACnD,YAAI,OAAO,kBAAkB,aAAa;AACxC,iBAAO;AAAA,QACT;AACA,YAAI,iBAAiB,GAAG;AACtB,UAAAD;AAAA,YAAM;AAAA,YACJ,OAAO,WAAW;AAAA,YAAG,OAAO,oBAAoB;AAAA,YAAG,OAAO,6BAA6B;AAAA,YAAG;AAAA,UAAa;AACzG,iBAAO;AAAA,QACT;AACA,YAAI,OAAO,YAAY,eAAe;AACpC,iBAAO,WAAW,aAAa;AAAA,QACjC;AACA,eAAO;AAAA,MACT;AAAA;AAAA,MAGA,eAAe,MAAM;AAEnB,cAAM,YAAY,GAAG,IAAI;AACzB,cAAM,SAAS,KAAK,CAAC;AACrB,cAAM,MAAM,KAAK,CAAC;AAClB,YAAI,eAAe;AACnB,cAAM,eAAe,KAAK,QAAQ;AAClC,YAAI,iBAAiB,MAAM,MAAM,cAAc;AAE7C,iBAAO,WAAW,YAAY;AAC9B,UAAAA,OAAM,4BAA4B,OAAO,WAAW,GAAG,YAAY;AAAA,QACrE;AACA,eAAO,oBAAoB;AAC3B,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAAG,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,UACvF,iBAAiB,MAAM;AAAA,QAAC;AAAA,MAC5B;AAAA,MAEA,CAAC,SAAS,IAAI;AACZ,cAAM,KAAK,KAAK,UAAU;AAC1B,YAAI,KAAK,UAAU,MAAM,OAAO;AAAkB,eAAK,UAAU,IAAI;AACrE,eAAO;AAAA,MACT;AAAA,MAEA,CAAC,WAAW,EAAE,QAAQ,SAAS;AAI7B,YAAI,QAAQ,SAAS;AACnB,gBAAM,UAAU,iBAAiB,MAAM;AACvC,cAAI,CAAC,SAAS;AACZ,mBAAO,WAAW,QAAQ,OAAO;AAAA,UACnC;AAAA,QACF;AAEA,YAAI,KAAK,QAAQ,WAAW;AAG1B,iBAAO,WAAW,IAAI;AAAA,QACxB;AACA,aAAK;AACL,YAAI,KAAK,QAAQ,iBAAiB;AAChC,iBAAO,mBAAmB,IAAI,KAAK,IAAI;AAAA,QACzC;AAEA,eAAO,WAAW,IAAI,QAAQ,KAAK,SAAS,EAAE,CAAC,IAAI,QAAQ,SAAS,IAAI,MAAM,cAAc,CAAC,EAAE,CAAC;AAChG,eAAO,oBAAoB,IAAI;AAC/B,eAAO,6BAA6B,IAAI;AACxC,yBAAiB,MAAM,QAAQ,OAAO;AAAA,MACxC;AAAA,MAEA,iBAAiB,SAAS,UAAU;AAClC,YAAI,SAAS;AACb,cAAM,cAAc,CAAC,KAAK,WAAW;AACnC,cAAI;AAAQ;AACZ,mBAAS;AAET,cAAI,KAAK;AACP,iBAAK;AACL,mBAAO,SAAS,GAAG;AAAA,UACrB;AACA,eAAK,WAAW,EAAE,QAAQ,OAAO;AACjC,mBAAS,KAAK,MAAM;AAAA,QACtB;AAEA,cAAM,YAAY,MAAM,iBAAiB,SAAS,WAAW;AAC7D,YAAI;AAAW,sBAAY,MAAM,SAAS;AAC1C,eAAO;AAAA,MACT;AAAA,MAEA,IAAI,gBAAgB;AAClB,cAAM,UAAU,KAAK,sBAAsB,KAAK,8BAC9C,KAAK,2BAA2B,KAAK,mCACrC,KAAK,qBAAqB,KAAK,6BAC/B,KAAK,qBAAqB,KAAK,6BAC/B,KAAK,uBAAuB,KAAK,+BACjC,KAAK,iBAAiB,KAAK;AAC7B,YAAI,SAAS;AACX,eAAK,6BAA6B,KAAK;AACvC,eAAK,kCAAkC,KAAK;AAC5C,eAAK,4BAA4B,KAAK;AACtC,eAAK,4BAA4B,KAAK;AACtC,eAAK,8BAA8B,KAAK;AACxC,eAAK,wBAAwB,KAAK;AAAA,QACpC;AACA,eAAO;AAAA,MACT;AAAA,MAEA,mBAAmB;AACjB,eAAO;AAAA,UACL,mBAAmB,KAAK;AAAA,UACxB,wBAAwB,KAAK;AAAA,UAC7B,kBAAkB,KAAK;AAAA,UACvB,kBAAkB,KAAK;AAAA,UACvB,oBAAoB,KAAK;AAAA,UACzB,cAAc,KAAK;AAAA,UACnB,aAAaE,SAAQ,KAAK,WAAW;AAAA,UACrC,SAASA,SAAQ,KAAK,OAAO;AAAA,UAC7B,UAAUA,SAAQ,KAAK,QAAQ;AAAA,QACjC;AAAA,MACF;AAAA,IACF;AAIA,aAAS,iBAAiB,QAAQ;AAChC,aAAO,OAAO,WAAW,OAAO;AAAA,IAClC;AAEA,aAAS,iBAAiB,OAAO,QAAQ,SAAS;AAChD,MAAAF,OAAM,2BAA2B,OAAO,WAAW,GAAG,iBAAiB,MAAM,CAAC;AAG9E,eAAS,SAAS;AAIhB,YAAI,CAAC,OAAO,gBAAgB,OAAO,oBAAoB,MAAM;AAAG;AAEhE,eAAO,6BAA6B;AACpC,cAAM;AACN,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAAG,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,QAAC;AAG1F,cAAM,OAAO,MAAM,QAAQ,OAAO;AAClC,YAAI,OAAO,YAAY,MAAM,SAAS,IAAI,KAAK,MAAM,SAAS,IAAI,EAAE,QAAQ;AAE1E,iBAAO,oBAAoB;AAC3B,UAAAA;AAAA,YAAM;AAAA,YACJ,OAAO,WAAW;AAAA,YAAG,OAAO,oBAAoB;AAAA,YAAG,OAAO,6BAA6B;AAAA,UAAC;AAAA,QAC5F;AAAA,MACF;AACA,aAAO,GAAG,QAAQ,MAAM;AAExB,eAAS,QAAQ,SAAS;AACxB,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAAG,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,UAAG;AAAA,QAAO;AACnG,cAAM;AAAA,MACR;AACA,aAAO,GAAG,SAAS,OAAO;AAG1B,eAAS,YAAY;AAGnB,cAAM,gBAAgB,OAAO,UAAU,SAAS,EAAE;AAMlD,cAAM,UAAU,iBAAiB,MAAM;AACvC,cAAM,MAAM,OAAO;AACnB,cAAM,0BAA0B,OAAO,IAAI,UAAU,SAAS,EAAE,UAAU;AAC1E,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAAG,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,UACvF;AAAA,UAAS;AAAA,UAAe;AAAA,UAA6B,CAAC,CAAC;AAAA,UAAK;AAAA,QAAuB;AACrF,YAAIA,OAAM,SAAS;AACjB,UAAAA,OAAM,yBAAyB,OAAO,UAAU,SAAS,EAAE,IAAI,OAAK,EAAE,IAAI,EAAE,KAAK,IAAI,CAAC;AAAA,QACxF;AACA,cAAM;AACN,cAAM,OAAO,MAAM,QAAQ,OAAO;AAClC,YAAI,MAAM,YAAY,IAAI,KAAK,MAAM,YAAY,IAAI,EAAE,QAAQ,MAAM,MAAM,IAAI;AAE7E,iBAAO,QAAQ;AAGf,gBAAM,aAAa,QAAQ,OAAO;AAClC,UAAAA,OAAM,+BAA+B,OAAO,WAAW,CAAC;AAAA,QAC1D,OAAO;AAUL,cAAI,4BAA4B,GAAG;AACjC,kBAAM,QAAQ,IAAI,MAAM,gBAAgB;AACxC,kBAAM,OAAO;AACb,kBAAM,UAAU;AAGhB,mBAAO,QAAQ,KAAK;AACpB,kBAAM,aAAa,QAAQ,OAAO;AAClC,YAAAA,OAAM,iCAAiC,OAAO,WAAW,CAAC;AAAA,UAC5D;AAAA,QACF;AAAA,MACF;AACA,aAAO,GAAG,WAAW,SAAS;AAE9B,eAAS,QAAQ,KAAK;AACpB,cAAM,gBAAgB,OAAO,UAAU,OAAO,EAAE;AAChD,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAAG,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,UACvF;AAAA,UAAK;AAAA,QAAa;AACpB,cAAM;AACN,YAAI,kBAAkB,GAAG;AAEvB,UAAAA,OAAM,gCAAgC,OAAO,WAAW,CAAC;AACzD,iBAAO,eAAe,SAAS,OAAO;AACtC,iBAAO,KAAK,SAAS,GAAG;AAAA,QAC1B;AAAA,MACF;AACA,aAAO,GAAG,SAAS,OAAO;AAE1B,eAAS,WAAW;AAClB,QAAAA;AAAA,UAAM;AAAA,UACJ,OAAO,WAAW;AAAA,UAClB,OAAO,oBAAoB;AAAA,UAAG,OAAO,6BAA6B;AAAA,QAAC;AAIrE,eAAO,eAAe,SAAS,OAAO;AACtC,eAAO,eAAe,SAAS,OAAO;AACtC,eAAO,eAAe,QAAQ,MAAM;AACpC,eAAO,eAAe,WAAW,SAAS;AAC1C,eAAO,eAAe,eAAe,QAAQ;AAAA,MAC/C;AACA,aAAO,GAAG,eAAe,QAAQ;AAAA,IACnC;AAEA,WAAO,UAAU;AAEjB,aAASE,SAAQ,KAAK;AACpB,YAAM,MAAM,CAAC;AACb,iBAAW,OAAO,KAAK;AACrB,YAAI,GAAG,IAAI,IAAI,GAAG,EAAE;AAAA,MACtB;AACA,aAAO;AAAA,IACT;AAAA;AAAA;;;ACjZA;AAAA;AAAA;AAEA,QAAM,qBAAqB,UAAQ,OAAO,EAAE;AAC5C,QAAM,YAAY;AAClB,QAAM;AAAA,MACJ;AAAA,MACA;AAAA,IACF,IAAI;AAEJ,QAAM,aAAN,cAAyB,UAAU;AAAA,MACjC,YAAY,SAAS;AACnB,cAAM,OAAO;AAEb,aAAK,cAAc;AACnB,aAAK,WAAW;AAChB,aAAK,oBAAoB,KAAK,QAAQ;AAEtC,YAAI,KAAK,sBAAsB,QAAW;AACxC,eAAK,oBAAoB;AAAA,QAC3B;AAEA,aAAK,gBAAgB;AAAA,UACnB,KAAK,CAAC;AAAA,UACN,MAAM,CAAC;AAAA,QACT;AAAA,MACF;AAAA,MAEA,iBAAiB,SAAS,UAAU;AAClC,cAAM,SAAS,KAAK,uBAAuB,EAAE,SAAS,QAAQ;AAC9D,aAAK,WAAW,EAAE,QAAQ,OAAO;AACjC,eAAO;AAAA,MACT;AAAA,IACF;AAGA,eAAW,UAAU,uBAAuB,IAAI,mBAAmB,UAAU;AAE7E;AAAA,MACE;AAAA,MACA;AAAA,MACA;AAAA;AAAA,MAEA;AAAA,IACF,EAAE,QAAQ,SAAS,QAAQ;AAEzB,UAAI,OAAO,mBAAmB,UAAU,MAAM,MAAM,YAAY;AAC9D,mBAAW,UAAU,MAAM,IAAI,mBAAmB,UAAU,MAAM;AAAA,MACpE;AAAA,IACF,CAAC;AAED,WAAO,UAAU;AAAA;AAAA;;;AClDjB;AAAA;AAAA;AAEA,WAAO,UAAU;AACjB,WAAO,QAAQ,aAAa;AAC5B,WAAO,QAAQ,YAAY;AAAA;AAAA;;;;;;;;;;eCJX,OAAI;AAClB,eAAO;MACT;ACCM,eAAU,aAAa,GAAM;AACjC,eAAQ,OAAO,MAAM,YAAY,MAAM,QAAS,OAAO,MAAM;MAC/D;AAEO,YAAM,iCAUP;AAEU,eAAA,gBAAgB,IAAc,MAAY;AACxD,YAAI;AACF,iBAAO,eAAe,IAAI,QAAQ;YAChC,OAAO;YACP,cAAc;UACf,CAAA;iBACDC,KAAM;;MAIV;AC1BA,YAAM,kBAAkB;AACxB,YAAM,sBAAsB,QAAQ,UAAU;AAC9C,YAAM,wBAAwB,QAAQ,OAAO,KAAK,eAAe;AAG3D,eAAU,WAAc,UAGrB;AACP,eAAO,IAAI,gBAAgB,QAAQ;MACrC;AAGM,eAAU,oBAAuB,OAAyB;AAC9D,eAAO,WAAW,aAAW,QAAQ,KAAK,CAAC;MAC7C;AAGM,eAAU,oBAA+B,QAAW;AACxD,eAAO,sBAAsB,MAAM;MACrC;eAEgB,mBACd,SACA,aACA,YAA8D;AAG9D,eAAO,oBAAoB,KAAK,SAAS,aAAa,UAAU;MAClE;eAKgB,YACd,SACA,aACA,YAAsD;AACtD,2BACE,mBAAmB,SAAS,aAAa,UAAU,GACnD,QACA,8BAA8B;MAElC;AAEgB,eAAA,gBAAmB,SAAqB,aAAmD;AACzG,oBAAY,SAAS,WAAW;MAClC;AAEgB,eAAA,cAAc,SAA2B,YAAqD;AAC5G,oBAAY,SAAS,QAAW,UAAU;MAC5C;eAEgB,qBACd,SACA,oBACA,kBAAoE;AACpE,eAAO,mBAAmB,SAAS,oBAAoB,gBAAgB;MACzE;AAEM,eAAU,0BAA0B,SAAyB;AACjE,2BAAmB,SAAS,QAAW,8BAA8B;MACvE;AAEA,UAAI,kBAAkD,cAAW;AAC/D,YAAI,OAAO,mBAAmB,YAAY;AACxC,4BAAkB;eACb;AACL,gBAAM,kBAAkB,oBAAoB,MAAS;AACrD,4BAAkB,QAAM,mBAAmB,iBAAiB,EAAE;;AAEhE,eAAO,gBAAgB,QAAQ;MACjC;eAIgB,YAAmC,GAAiC,GAAM,MAAO;AAC/F,YAAI,OAAO,MAAM,YAAY;AAC3B,gBAAM,IAAI,UAAU,4BAA4B;;AAElD,eAAO,SAAS,UAAU,MAAM,KAAK,GAAG,GAAG,IAAI;MACjD;eAEgB,YAAmC,GACA,GACA,MAAO;AAIxD,YAAI;AACF,iBAAO,oBAAoB,YAAY,GAAG,GAAG,IAAI,CAAC;iBAC3C,OAAO;AACd,iBAAO,oBAAoB,KAAK;;MAEpC;AC5FA,YAAM,uBAAuB;YAahB,YAAW;QAMtB,cAAA;AAHQ,eAAO,UAAG;AACV,eAAK,QAAG;AAId,eAAK,SAAS;YACZ,WAAW,CAAA;YACX,OAAO;;AAET,eAAK,QAAQ,KAAK;AAIlB,eAAK,UAAU;AAEf,eAAK,QAAQ;;QAGf,IAAI,SAAM;AACR,iBAAO,KAAK;;;;;;QAOd,KAAK,SAAU;AACb,gBAAM,UAAU,KAAK;AACrB,cAAI,UAAU;AAEd,cAAI,QAAQ,UAAU,WAAW,uBAAuB,GAAG;AACzD,sBAAU;cACR,WAAW,CAAA;cACX,OAAO;;;AAMX,kBAAQ,UAAU,KAAK,OAAO;AAC9B,cAAI,YAAY,SAAS;AACvB,iBAAK,QAAQ;AACb,oBAAQ,QAAQ;;AAElB,YAAE,KAAK;;;;QAKT,QAAK;AAGH,gBAAM,WAAW,KAAK;AACtB,cAAI,WAAW;AACf,gBAAM,YAAY,KAAK;AACvB,cAAI,YAAY,YAAY;AAE5B,gBAAM,WAAW,SAAS;AAC1B,gBAAM,UAAU,SAAS,SAAS;AAElC,cAAI,cAAc,sBAAsB;AAGtC,uBAAW,SAAS;AACpB,wBAAY;;AAId,YAAE,KAAK;AACP,eAAK,UAAU;AACf,cAAI,aAAa,UAAU;AACzB,iBAAK,SAAS;;AAIhB,mBAAS,SAAS,IAAI;AAEtB,iBAAO;;;;;;;;;;QAWT,QAAQ,UAA8B;AACpC,cAAI,IAAI,KAAK;AACb,cAAI,OAAO,KAAK;AAChB,cAAI,WAAW,KAAK;AACpB,iBAAO,MAAM,SAAS,UAAU,KAAK,UAAU,QAAW;AACxD,gBAAI,MAAM,SAAS,QAAQ;AAGzB,qBAAO,KAAK;AACZ,yBAAW,KAAK;AAChB,kBAAI;AACJ,kBAAI,SAAS,WAAW,GAAG;AACzB;;;AAGJ,qBAAS,SAAS,CAAC,CAAC;AACpB,cAAE;;;;;QAMN,OAAI;AAGF,gBAAM,QAAQ,KAAK;AACnB,gBAAM,SAAS,KAAK;AACpB,iBAAO,MAAM,UAAU,MAAM;;MAEhC;AC1IM,YAAM,aAAa,OAAO,gBAAgB;AAC1C,YAAM,aAAa,OAAO,gBAAgB;AAC1C,YAAM,cAAc,OAAO,iBAAiB;AAC5C,YAAM,YAAY,OAAO,eAAe;AACxC,YAAM,eAAe,OAAO,kBAAkB;ACCrC,eAAA,sCAAyC,QAAiC,QAAyB;AACjH,eAAO,uBAAuB;AAC9B,eAAO,UAAU;AAEjB,YAAI,OAAO,WAAW,YAAY;AAChC,+CAAqC,MAAM;mBAClC,OAAO,WAAW,UAAU;AACrC,yDAA+C,MAAM;eAChD;AAGL,yDAA+C,QAAQ,OAAO,YAAY;;MAE9E;AAKgB,eAAA,kCAAkC,QAAmC,QAAW;AAC9F,cAAM,SAAS,OAAO;AAEtB,eAAO,qBAAqB,QAAQ,MAAM;MAC5C;AAEM,eAAU,mCAAmC,QAAiC;AAClF,cAAM,SAAS,OAAO;AAItB,YAAI,OAAO,WAAW,YAAY;AAChC,2CACE,QACA,IAAI,UAAU,kFAAkF,CAAC;eAC9F;AACL,oDACE,QACA,IAAI,UAAU,kFAAkF,CAAC;;AAGrG,eAAO,0BAA0B,YAAY,EAAC;AAE9C,eAAO,UAAU;AACjB,eAAO,uBAAuB;MAChC;AAIM,eAAU,oBAAoB,MAAY;AAC9C,eAAO,IAAI,UAAU,YAAY,OAAO,mCAAmC;MAC7E;AAIM,eAAU,qCAAqC,QAAiC;AACpF,eAAO,iBAAiB,WAAW,CAAC,SAAS,WAAU;AACrD,iBAAO,yBAAyB;AAChC,iBAAO,wBAAwB;QACjC,CAAC;MACH;AAEgB,eAAA,+CAA+C,QAAmC,QAAW;AAC3G,6CAAqC,MAAM;AAC3C,yCAAiC,QAAQ,MAAM;MACjD;AAEM,eAAU,+CAA+C,QAAiC;AAC9F,6CAAqC,MAAM;AAC3C,0CAAkC,MAAM;MAC1C;AAEgB,eAAA,iCAAiC,QAAmC,QAAW;AAC7F,YAAI,OAAO,0BAA0B,QAAW;AAC9C;;AAGF,kCAA0B,OAAO,cAAc;AAC/C,eAAO,sBAAsB,MAAM;AACnC,eAAO,yBAAyB;AAChC,eAAO,wBAAwB;MACjC;AAEgB,eAAA,0CAA0C,QAAmC,QAAW;AAItG,uDAA+C,QAAQ,MAAM;MAC/D;AAEM,eAAU,kCAAkC,QAAiC;AACjF,YAAI,OAAO,2BAA2B,QAAW;AAC/C;;AAGF,eAAO,uBAAuB,MAAS;AACvC,eAAO,yBAAyB;AAChC,eAAO,wBAAwB;MACjC;AClGA,YAAM,iBAAyC,OAAO,YAAY,SAAU,GAAC;AAC3E,eAAO,OAAO,MAAM,YAAY,SAAS,CAAC;MAC5C;ACFA,YAAM,YAA+B,KAAK,SAAS,SAAU,GAAC;AAC5D,eAAO,IAAI,IAAI,KAAK,KAAK,CAAC,IAAI,KAAK,MAAM,CAAC;MAC5C;ACDM,eAAU,aAAa,GAAM;AACjC,eAAO,OAAO,MAAM,YAAY,OAAO,MAAM;MAC/C;AAEgB,eAAA,iBAAiB,KACA,SAAe;AAC9C,YAAI,QAAQ,UAAa,CAAC,aAAa,GAAG,GAAG;AAC3C,gBAAM,IAAI,UAAU,GAAG,OAAO,oBAAoB;;MAEtD;AAKgB,eAAA,eAAe,GAAY,SAAe;AACxD,YAAI,OAAO,MAAM,YAAY;AAC3B,gBAAM,IAAI,UAAU,GAAG,OAAO,qBAAqB;;MAEvD;AAGM,eAAU,SAAS,GAAM;AAC7B,eAAQ,OAAO,MAAM,YAAY,MAAM,QAAS,OAAO,MAAM;MAC/D;AAEgB,eAAA,aAAa,GACA,SAAe;AAC1C,YAAI,CAAC,SAAS,CAAC,GAAG;AAChB,gBAAM,IAAI,UAAU,GAAG,OAAO,oBAAoB;;MAEtD;eAEgB,uBAA0B,GACA,UACA,SAAe;AACvD,YAAI,MAAM,QAAW;AACnB,gBAAM,IAAI,UAAU,aAAa,QAAQ,oBAAoB,OAAO,IAAI;;MAE5E;eAEgB,oBAAuB,GACA,OACA,SAAe;AACpD,YAAI,MAAM,QAAW;AACnB,gBAAM,IAAI,UAAU,GAAG,KAAK,oBAAoB,OAAO,IAAI;;MAE/D;AAGM,eAAU,0BAA0B,OAAc;AACtD,eAAO,OAAO,KAAK;MACrB;AAEA,eAAS,mBAAmB,GAAS;AACnC,eAAO,MAAM,IAAI,IAAI;MACvB;AAEA,eAAS,YAAY,GAAS;AAC5B,eAAO,mBAAmB,UAAU,CAAC,CAAC;MACxC;AAGgB,eAAA,wCAAwC,OAAgB,SAAe;AACrF,cAAM,aAAa;AACnB,cAAM,aAAa,OAAO;AAE1B,YAAI,IAAI,OAAO,KAAK;AACpB,YAAI,mBAAmB,CAAC;AAExB,YAAI,CAAC,eAAe,CAAC,GAAG;AACtB,gBAAM,IAAI,UAAU,GAAG,OAAO,yBAAyB;;AAGzD,YAAI,YAAY,CAAC;AAEjB,YAAI,IAAI,cAAc,IAAI,YAAY;AACpC,gBAAM,IAAI,UAAU,GAAG,OAAO,qCAAqC,UAAU,OAAO,UAAU,aAAa;;AAG7G,YAAI,CAAC,eAAe,CAAC,KAAK,MAAM,GAAG;AACjC,iBAAO;;AAQT,eAAO;MACT;AC3FgB,eAAA,qBAAqB,GAAY,SAAe;AAC9D,YAAI,CAAC,iBAAiB,CAAC,GAAG;AACxB,gBAAM,IAAI,UAAU,GAAG,OAAO,2BAA2B;;MAE7D;ACwBM,eAAU,mCAAsC,QAAsB;AAC1E,eAAO,IAAI,4BAA4B,MAAM;MAC/C;AAIgB,eAAA,6BAAgC,QACA,aAA2B;AAIxE,eAAO,QAA4C,cAAc,KAAK,WAAW;MACpF;eAEgB,iCAAoC,QAA2B,OAAsB,MAAa;AAChH,cAAM,SAAS,OAAO;AAItB,cAAM,cAAc,OAAO,cAAc,MAAK;AAC9C,YAAI,MAAM;AACR,sBAAY,YAAW;eAClB;AACL,sBAAY,YAAY,KAAM;;MAElC;AAEM,eAAU,iCAAoC,QAAyB;AAC3E,eAAQ,OAAO,QAA2C,cAAc;MAC1E;AAEM,eAAU,+BAA+B,QAAsB;AACnE,cAAM,SAAS,OAAO;AAEtB,YAAI,WAAW,QAAW;AACxB,iBAAO;;AAGT,YAAI,CAAC,8BAA8B,MAAM,GAAG;AAC1C,iBAAO;;AAGT,eAAO;MACT;YAiBa,4BAA2B;QAYtC,YAAY,QAAyB;AACnC,iCAAuB,QAAQ,GAAG,6BAA6B;AAC/D,+BAAqB,QAAQ,iBAAiB;AAE9C,cAAI,uBAAuB,MAAM,GAAG;AAClC,kBAAM,IAAI,UAAU,6EAA6E;;AAGnG,gDAAsC,MAAM,MAAM;AAElD,eAAK,gBAAgB,IAAI,YAAW;;;;;;QAOtC,IAAI,SAAM;AACR,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,QAAQ,CAAC;;AAGvE,iBAAO,KAAK;;;;;QAMd,OAAO,SAAc,QAAS;AAC5B,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,QAAQ,CAAC;;AAGvE,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,oBAAoB,QAAQ,CAAC;;AAG1D,iBAAO,kCAAkC,MAAM,MAAM;;;;;;;QAQvD,OAAI;AACF,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,MAAM,CAAC;;AAGrE,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,oBAAoB,WAAW,CAAC;;AAG7D,cAAI;AACJ,cAAI;AACJ,gBAAM,UAAU,WAA+C,CAAC,SAAS,WAAU;AACjF,6BAAiB;AACjB,4BAAgB;UAClB,CAAC;AACD,gBAAM,cAA8B;YAClC,aAAa,WAAS,eAAe,EAAE,OAAO,OAAO,MAAM,MAAK,CAAE;YAClE,aAAa,MAAM,eAAe,EAAE,OAAO,QAAW,MAAM,KAAI,CAAE;YAClE,aAAa,OAAK,cAAc,CAAC;;AAEnC,0CAAgC,MAAM,WAAW;AACjD,iBAAO;;;;;;;;;;;QAYT,cAAW;AACT,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,kBAAM,iCAAiC,aAAa;;AAGtD,cAAI,KAAK,yBAAyB,QAAW;AAC3C;;AAGF,6CAAmC,IAAI;;MAE1C;AAED,aAAO,iBAAiB,4BAA4B,WAAW;QAC7D,QAAQ,EAAE,YAAY,KAAI;QAC1B,MAAM,EAAE,YAAY,KAAI;QACxB,aAAa,EAAE,YAAY,KAAI;QAC/B,QAAQ,EAAE,YAAY,KAAI;MAC3B,CAAA;AACD,sBAAgB,4BAA4B,UAAU,QAAQ,QAAQ;AACtE,sBAAgB,4BAA4B,UAAU,MAAM,MAAM;AAClE,sBAAgB,4BAA4B,UAAU,aAAa,aAAa;AAChF,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,4BAA4B,WAAW,OAAO,aAAa;UAC/E,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIM,eAAU,8BAAuC,GAAM;AAC3D,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,eAAe,GAAG;AAC7D,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEgB,eAAA,gCAAmC,QACA,aAA2B;AAC5E,cAAM,SAAS,OAAO;AAItB,eAAO,aAAa;AAEpB,YAAI,OAAO,WAAW,UAAU;AAC9B,sBAAY,YAAW;mBACd,OAAO,WAAW,WAAW;AACtC,sBAAY,YAAY,OAAO,YAAY;eACtC;AAEL,iBAAO,0BAA0B,SAAS,EAAE,WAA+B;;MAE/E;AAEM,eAAU,mCAAmC,QAAmC;AACpF,2CAAmC,MAAM;AACzC,cAAM,IAAI,IAAI,UAAU,qBAAqB;AAC7C,qDAA6C,QAAQ,CAAC;MACxD;AAEgB,eAAA,6CAA6C,QAAqC,GAAM;AACtG,cAAM,eAAe,OAAO;AAC5B,eAAO,gBAAgB,IAAI,YAAW;AACtC,qBAAa,QAAQ,iBAAc;AACjC,sBAAY,YAAY,CAAC;QAC3B,CAAC;MACH;AAIA,eAAS,iCAAiC,MAAY;AACpD,eAAO,IAAI,UACT,yCAAyC,IAAI,oDAAoD;MACrG;ACjQO,YAAM,yBACX,OAAO,eAAe,OAAO,eAAe,mBAAe;MAAA,CAAkC,EAAE,SAAS;YC6B7F,gCAA+B;QAM1C,YAAY,QAAwC,eAAsB;AAHlE,eAAe,kBAA4D;AAC3E,eAAW,cAAG;AAGpB,eAAK,UAAU;AACf,eAAK,iBAAiB;;QAGxB,OAAI;AACF,gBAAM,YAAY,MAAM,KAAK,WAAU;AACvC,eAAK,kBAAkB,KAAK,kBAC1B,qBAAqB,KAAK,iBAAiB,WAAW,SAAS,IAC/D,UAAS;AACX,iBAAO,KAAK;;QAGd,OAAO,OAAU;AACf,gBAAM,cAAc,MAAM,KAAK,aAAa,KAAK;AACjD,iBAAO,KAAK,kBACV,qBAAqB,KAAK,iBAAiB,aAAa,WAAW,IACnE,YAAW;;QAGP,aAAU;AAChB,cAAI,KAAK,aAAa;AACpB,mBAAO,QAAQ,QAAQ,EAAE,OAAO,QAAW,MAAM,KAAI,CAAE;;AAGzD,gBAAM,SAAS,KAAK;AAGpB,cAAI;AACJ,cAAI;AACJ,gBAAM,UAAU,WAA+C,CAAC,SAAS,WAAU;AACjF,6BAAiB;AACjB,4BAAgB;UAClB,CAAC;AACD,gBAAM,cAA8B;YAClC,aAAa,WAAQ;AACnB,mBAAK,kBAAkB;AAGvBC,8BAAe,MAAM,eAAe,EAAE,OAAO,OAAO,MAAM,MAAK,CAAE,CAAC;;YAEpE,aAAa,MAAK;AAChB,mBAAK,kBAAkB;AACvB,mBAAK,cAAc;AACnB,iDAAmC,MAAM;AACzC,6BAAe,EAAE,OAAO,QAAW,MAAM,KAAI,CAAE;;YAEjD,aAAa,YAAS;AACpB,mBAAK,kBAAkB;AACvB,mBAAK,cAAc;AACnB,iDAAmC,MAAM;AACzC,4BAAc,MAAM;;;AAGxB,0CAAgC,QAAQ,WAAW;AACnD,iBAAO;;QAGD,aAAa,OAAU;AAC7B,cAAI,KAAK,aAAa;AACpB,mBAAO,QAAQ,QAAQ,EAAE,OAAO,MAAM,KAAI,CAAE;;AAE9C,eAAK,cAAc;AAEnB,gBAAM,SAAS,KAAK;AAIpB,cAAI,CAAC,KAAK,gBAAgB;AACxB,kBAAM,SAAS,kCAAkC,QAAQ,KAAK;AAC9D,+CAAmC,MAAM;AACzC,mBAAO,qBAAqB,QAAQ,OAAO,EAAE,OAAO,MAAM,KAAI,EAAG;;AAGnE,6CAAmC,MAAM;AACzC,iBAAO,oBAAoB,EAAE,OAAO,MAAM,KAAI,CAAE;;MAEnD;AAWD,YAAM,uCAAiF;QACrF,OAAI;AACF,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,uCAAuC,MAAM,CAAC;;AAE3E,iBAAO,KAAK,mBAAmB,KAAI;;QAGrC,OAAuD,OAAU;AAC/D,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,uCAAuC,QAAQ,CAAC;;AAE7E,iBAAO,KAAK,mBAAmB,OAAO,KAAK;;;AAG/C,aAAO,eAAe,sCAAsC,sBAAsB;AAIlE,eAAA,mCAAsC,QACA,eAAsB;AAC1E,cAAM,SAAS,mCAAsC,MAAM;AAC3D,cAAM,OAAO,IAAI,gCAAgC,QAAQ,aAAa;AACtE,cAAM,WAAmD,OAAO,OAAO,oCAAoC;AAC3G,iBAAS,qBAAqB;AAC9B,eAAO;MACT;AAEA,eAAS,8BAAuC,GAAM;AACpD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,oBAAoB,GAAG;AAClE,iBAAO;;AAGT,YAAI;AAEF,iBAAQ,EAA+C,8BACrD;iBACFD,KAAM;AACN,iBAAO;;MAEX;AAIA,eAAS,uCAAuC,MAAY;AAC1D,eAAO,IAAI,UAAU,+BAA+B,IAAI,mDAAmD;MAC7G;AC9KA,YAAM,cAAmC,OAAO,SAAS,SAAU,GAAC;AAElE,eAAO,MAAM;MACf;;ACQM,eAAU,oBAAqC,UAAW;AAG9D,eAAO,SAAS,MAAK;MACvB;AAEM,eAAU,mBAAmB,MACA,YACA,KACA,WACA,GAAS;AAC1C,YAAI,WAAW,IAAI,EAAE,IAAI,IAAI,WAAW,KAAK,WAAW,CAAC,GAAG,UAAU;MACxE;AAEO,UAAI,sBAAsB,CAAC,MAA+B;AAC/D,YAAI,OAAO,EAAE,aAAa,YAAY;AACpC,gCAAsB,YAAU,OAAO,SAAQ;mBACtC,OAAO,oBAAoB,YAAY;AAChD,gCAAsB,YAAU,gBAAgB,QAAQ,EAAE,UAAU,CAAC,MAAM,EAAC,CAAE;eACzE;AAEL,gCAAsB,YAAU;;AAElC,eAAO,oBAAoB,CAAC;MAC9B;AAMO,UAAI,mBAAmB,CAAC,MAA2B;AACxD,YAAI,OAAO,EAAE,aAAa,WAAW;AACnC,6BAAmB,YAAU,OAAO;eAC/B;AAEL,6BAAmB,YAAU,OAAO,eAAe;;AAErD,eAAO,iBAAiB,CAAC;MAC3B;eAEgB,iBAAiB,QAAqB,OAAe,KAAW;AAG9E,YAAI,OAAO,OAAO;AAChB,iBAAO,OAAO,MAAM,OAAO,GAAG;;AAEhC,cAAM,SAAS,MAAM;AACrB,cAAM,QAAQ,IAAI,YAAY,MAAM;AACpC,2BAAmB,OAAO,GAAG,QAAQ,OAAO,MAAM;AAClD,eAAO;MACT;AAMgB,eAAA,UAAsC,UAAa,MAAO;AACxE,cAAM,OAAO,SAAS,IAAI;AAC1B,YAAI,SAAS,UAAa,SAAS,MAAM;AACvC,iBAAO;;AAET,YAAI,OAAO,SAAS,YAAY;AAC9B,gBAAM,IAAI,UAAU,GAAG,OAAO,IAAI,CAAC,oBAAoB;;AAEzD,eAAO;MACT;AAgBM,eAAU,4BAA+B,oBAAyC;AAKtF,cAAM,eAAe;UACnB,CAAC,OAAO,QAAQ,GAAG,MAAM,mBAAmB;;AAG9C,cAAM,gBAAiB,mBAAe;AACpC,iBAAO,OAAO;UACf;AAED,cAAM,aAAa,cAAc;AACjC,eAAO,EAAE,UAAU,eAAe,YAAY,MAAM,MAAK;MAC3D;AAGO,YAAM,uBACX,MAAAA,MAAA,OAAO,mBAAa,QAAAA,QAAA,SAAAA,OACpB,KAAA,OAAO,SAAG,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA,QAAG,sBAAsB,OAAC,QAAA,OAAA,SAAA,KACpC;AAeF,eAAS,YACP,KACA,OAAO,QACP,QAAqC;AAGrC,YAAI,WAAW,QAAW;AACxB,cAAI,SAAS,SAAS;AACpB,qBAAS,UAAU,KAAyB,mBAAmB;AAC/D,gBAAI,WAAW,QAAW;AACxB,oBAAM,aAAa,UAAU,KAAoB,OAAO,QAAQ;AAChE,oBAAM,qBAAqB,YAAY,KAAoB,QAAQ,UAAU;AAC7E,qBAAO,4BAA4B,kBAAkB;;iBAElD;AACL,qBAAS,UAAU,KAAoB,OAAO,QAAQ;;;AAG1D,YAAI,WAAW,QAAW;AACxB,gBAAM,IAAI,UAAU,4BAA4B;;AAElD,cAAM,WAAW,YAAY,QAAQ,KAAK,CAAA,CAAE;AAC5C,YAAI,CAAC,aAAa,QAAQ,GAAG;AAC3B,gBAAM,IAAI,UAAU,2CAA2C;;AAEjE,cAAM,aAAa,SAAS;AAC5B,eAAO,EAAE,UAAU,YAAY,MAAM,MAAK;MAC5C;AAIM,eAAU,aAAgB,gBAAsC;AACpE,cAAM,SAAS,YAAY,eAAe,YAAY,eAAe,UAAU,CAAA,CAAE;AACjF,YAAI,CAAC,aAAa,MAAM,GAAG;AACzB,gBAAM,IAAI,UAAU,kDAAkD;;AAExE,eAAO;MACT;AAEM,eAAU,iBACd,YAA4C;AAG5C,eAAO,QAAQ,WAAW,IAAI;MAChC;AAEM,eAAU,cAAiB,YAAkC;AAEjE,eAAO,WAAW;MACpB;AChLM,eAAU,oBAAoB,GAAS;AAC3C,YAAI,OAAO,MAAM,UAAU;AACzB,iBAAO;;AAGT,YAAI,YAAY,CAAC,GAAG;AAClB,iBAAO;;AAGT,YAAI,IAAI,GAAG;AACT,iBAAO;;AAGT,eAAO;MACT;AAEM,eAAU,kBAAkB,GAA6B;AAC7D,cAAM,SAAS,iBAAiB,EAAE,QAAQ,EAAE,YAAY,EAAE,aAAa,EAAE,UAAU;AACnF,eAAO,IAAI,WAAW,MAAM;MAC9B;ACTM,eAAU,aAAgB,WAAuC;AAIrE,cAAM,OAAO,UAAU,OAAO,MAAK;AACnC,kBAAU,mBAAmB,KAAK;AAClC,YAAI,UAAU,kBAAkB,GAAG;AACjC,oBAAU,kBAAkB;;AAG9B,eAAO,KAAK;MACd;eAEgB,qBAAwB,WAAyC,OAAU,MAAY;AAGrG,YAAI,CAAC,oBAAoB,IAAI,KAAK,SAAS,UAAU;AACnD,gBAAM,IAAI,WAAW,sDAAsD;;AAG7E,kBAAU,OAAO,KAAK,EAAE,OAAO,KAAI,CAAE;AACrC,kBAAU,mBAAmB;MAC/B;AAEM,eAAU,eAAkB,WAAuC;AAIvE,cAAM,OAAO,UAAU,OAAO,KAAI;AAClC,eAAO,KAAK;MACd;AAEM,eAAU,WAAc,WAA4B;AAGxD,kBAAU,SAAS,IAAI,YAAW;AAClC,kBAAU,kBAAkB;MAC9B;ACxBA,eAAS,sBAAsB,MAAc;AAC3C,eAAO,SAAS;MAClB;AAEM,eAAU,WAAW,MAAqB;AAC9C,eAAO,sBAAsB,KAAK,WAAW;MAC/C;AAEM,eAAU,2BAAsD,MAAmC;AACvG,YAAI,sBAAsB,IAAI,GAAG;AAC/B,iBAAO;;AAET,eAAQ,KAA0C;MACpD;YCSa,0BAAyB;QAMpC,cAAA;AACE,gBAAM,IAAI,UAAU,qBAAqB;;;;;QAM3C,IAAI,OAAI;AACN,cAAI,CAAC,4BAA4B,IAAI,GAAG;AACtC,kBAAM,+BAA+B,MAAM;;AAG7C,iBAAO,KAAK;;QAWd,QAAQ,cAAgC;AACtC,cAAI,CAAC,4BAA4B,IAAI,GAAG;AACtC,kBAAM,+BAA+B,SAAS;;AAEhD,iCAAuB,cAAc,GAAG,SAAS;AACjD,yBAAe,wCAAwC,cAAc,iBAAiB;AAEtF,cAAI,KAAK,4CAA4C,QAAW;AAC9D,kBAAM,IAAI,UAAU,wCAAwC;;AAG9D,cAAI,iBAAiB,KAAK,MAAO,MAAM,GAAG;AACxC,kBAAM,IAAI,UAAU,iFAAiF;;AAMvG,8CAAoC,KAAK,yCAAyC,YAAY;;QAWhG,mBAAmB,MAAgC;AACjD,cAAI,CAAC,4BAA4B,IAAI,GAAG;AACtC,kBAAM,+BAA+B,oBAAoB;;AAE3D,iCAAuB,MAAM,GAAG,oBAAoB;AAEpD,cAAI,CAAC,YAAY,OAAO,IAAI,GAAG;AAC7B,kBAAM,IAAI,UAAU,8CAA8C;;AAGpE,cAAI,KAAK,4CAA4C,QAAW;AAC9D,kBAAM,IAAI,UAAU,wCAAwC;;AAG9D,cAAI,iBAAiB,KAAK,MAAM,GAAG;AACjC,kBAAM,IAAI,UAAU,+EAAgF;;AAGtG,yDAA+C,KAAK,yCAAyC,IAAI;;MAEpG;AAED,aAAO,iBAAiB,0BAA0B,WAAW;QAC3D,SAAS,EAAE,YAAY,KAAI;QAC3B,oBAAoB,EAAE,YAAY,KAAI;QACtC,MAAM,EAAE,YAAY,KAAI;MACzB,CAAA;AACD,sBAAgB,0BAA0B,UAAU,SAAS,SAAS;AACtE,sBAAgB,0BAA0B,UAAU,oBAAoB,oBAAoB;AAC5F,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,0BAA0B,WAAW,OAAO,aAAa;UAC7E,OAAO;UACP,cAAc;QACf,CAAA;MACH;YAyCa,6BAA4B;QA4BvC,cAAA;AACE,gBAAM,IAAI,UAAU,qBAAqB;;;;;QAM3C,IAAI,cAAW;AACb,cAAI,CAAC,+BAA+B,IAAI,GAAG;AACzC,kBAAM,wCAAwC,aAAa;;AAG7D,iBAAO,2CAA2C,IAAI;;;;;;QAOxD,IAAI,cAAW;AACb,cAAI,CAAC,+BAA+B,IAAI,GAAG;AACzC,kBAAM,wCAAwC,aAAa;;AAG7D,iBAAO,2CAA2C,IAAI;;;;;;QAOxD,QAAK;AACH,cAAI,CAAC,+BAA+B,IAAI,GAAG;AACzC,kBAAM,wCAAwC,OAAO;;AAGvD,cAAI,KAAK,iBAAiB;AACxB,kBAAM,IAAI,UAAU,4DAA4D;;AAGlF,gBAAM,QAAQ,KAAK,8BAA8B;AACjD,cAAI,UAAU,YAAY;AACxB,kBAAM,IAAI,UAAU,kBAAkB,KAAK,2DAA2D;;AAGxG,4CAAkC,IAAI;;QAQxC,QAAQ,OAAiC;AACvC,cAAI,CAAC,+BAA+B,IAAI,GAAG;AACzC,kBAAM,wCAAwC,SAAS;;AAGzD,iCAAuB,OAAO,GAAG,SAAS;AAC1C,cAAI,CAAC,YAAY,OAAO,KAAK,GAAG;AAC9B,kBAAM,IAAI,UAAU,oCAAoC;;AAE1D,cAAI,MAAM,eAAe,GAAG;AAC1B,kBAAM,IAAI,UAAU,qCAAqC;;AAE3D,cAAI,MAAM,OAAO,eAAe,GAAG;AACjC,kBAAM,IAAI,UAAU,8CAA8C;;AAGpE,cAAI,KAAK,iBAAiB;AACxB,kBAAM,IAAI,UAAU,8BAA8B;;AAGpD,gBAAM,QAAQ,KAAK,8BAA8B;AACjD,cAAI,UAAU,YAAY;AACxB,kBAAM,IAAI,UAAU,kBAAkB,KAAK,gEAAgE;;AAG7G,8CAAoC,MAAM,KAAK;;;;;QAMjD,MAAM,IAAS,QAAS;AACtB,cAAI,CAAC,+BAA+B,IAAI,GAAG;AACzC,kBAAM,wCAAwC,OAAO;;AAGvD,4CAAkC,MAAM,CAAC;;;QAI3C,CAAC,WAAW,EAAE,QAAW;AACvB,4DAAkD,IAAI;AAEtD,qBAAW,IAAI;AAEf,gBAAM,SAAS,KAAK,iBAAiB,MAAM;AAC3C,sDAA4C,IAAI;AAChD,iBAAO;;;QAIT,CAAC,SAAS,EAAE,aAA+C;AACzD,gBAAM,SAAS,KAAK;AAGpB,cAAI,KAAK,kBAAkB,GAAG;AAG5B,iEAAqD,MAAM,WAAW;AACtE;;AAGF,gBAAM,wBAAwB,KAAK;AACnC,cAAI,0BAA0B,QAAW;AACvC,gBAAI;AACJ,gBAAI;AACF,uBAAS,IAAI,YAAY,qBAAqB;qBACvC,SAAS;AAChB,0BAAY,YAAY,OAAO;AAC/B;;AAGF,kBAAM,qBAAgD;cACpD;cACA,kBAAkB;cAClB,YAAY;cACZ,YAAY;cACZ,aAAa;cACb,aAAa;cACb,aAAa;cACb,iBAAiB;cACjB,YAAY;;AAGd,iBAAK,kBAAkB,KAAK,kBAAkB;;AAGhD,uCAA6B,QAAQ,WAAW;AAChD,uDAA6C,IAAI;;;QAInD,CAAC,YAAY,IAAC;AACZ,cAAI,KAAK,kBAAkB,SAAS,GAAG;AACrC,kBAAM,gBAAgB,KAAK,kBAAkB,KAAI;AACjD,0BAAc,aAAa;AAE3B,iBAAK,oBAAoB,IAAI,YAAW;AACxC,iBAAK,kBAAkB,KAAK,aAAa;;;MAG9C;AAED,aAAO,iBAAiB,6BAA6B,WAAW;QAC9D,OAAO,EAAE,YAAY,KAAI;QACzB,SAAS,EAAE,YAAY,KAAI;QAC3B,OAAO,EAAE,YAAY,KAAI;QACzB,aAAa,EAAE,YAAY,KAAI;QAC/B,aAAa,EAAE,YAAY,KAAI;MAChC,CAAA;AACD,sBAAgB,6BAA6B,UAAU,OAAO,OAAO;AACrE,sBAAgB,6BAA6B,UAAU,SAAS,SAAS;AACzE,sBAAgB,6BAA6B,UAAU,OAAO,OAAO;AACrE,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,6BAA6B,WAAW,OAAO,aAAa;UAChF,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIM,eAAU,+BAA+B,GAAM;AACnD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,+BAA+B,GAAG;AAC7E,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,4BAA4B,GAAM;AACzC,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,yCAAyC,GAAG;AACvF,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,6CAA6C,YAAwC;AAC5F,cAAM,aAAa,2CAA2C,UAAU;AACxE,YAAI,CAAC,YAAY;AACf;;AAGF,YAAI,WAAW,UAAU;AACvB,qBAAW,aAAa;AACxB;;AAKF,mBAAW,WAAW;AAGtB,cAAM,cAAc,WAAW,eAAc;AAC7C,oBACE,aACA,MAAK;AACH,qBAAW,WAAW;AAEtB,cAAI,WAAW,YAAY;AACzB,uBAAW,aAAa;AACxB,yDAA6C,UAAU;;AAGzD,iBAAO;WAET,OAAI;AACF,4CAAkC,YAAY,CAAC;AAC/C,iBAAO;QACT,CAAC;MAEL;AAEA,eAAS,kDAAkD,YAAwC;AACjG,0DAAkD,UAAU;AAC5D,mBAAW,oBAAoB,IAAI,YAAW;MAChD;AAEA,eAAS,qDACP,QACA,oBAAyC;AAKzC,YAAI,OAAO;AACX,YAAI,OAAO,WAAW,UAAU;AAE9B,iBAAO;;AAGT,cAAM,aAAa,sDAAyD,kBAAkB;AAC9F,YAAI,mBAAmB,eAAe,WAAW;AAC/C,2CAAiC,QAAQ,YAAgD,IAAI;eACxF;AAEL,+CAAqC,QAAQ,YAAY,IAAI;;MAEjE;AAEA,eAAS,sDACP,oBAAyC;AAEzC,cAAM,cAAc,mBAAmB;AACvC,cAAM,cAAc,mBAAmB;AAKvC,eAAO,IAAI,mBAAmB,gBAC5B,mBAAmB,QAAQ,mBAAmB,YAAY,cAAc,WAAW;MACvF;AAEA,eAAS,gDAAgD,YACA,QACA,YACA,YAAkB;AACzE,mBAAW,OAAO,KAAK,EAAE,QAAQ,YAAY,WAAU,CAAE;AACzD,mBAAW,mBAAmB;MAChC;AAEA,eAAS,sDAAsD,YACA,QACA,YACA,YAAkB;AAC/E,YAAI;AACJ,YAAI;AACF,wBAAc,iBAAiB,QAAQ,YAAY,aAAa,UAAU;iBACnE,QAAQ;AACf,4CAAkC,YAAY,MAAM;AACpD,gBAAM;;AAER,wDAAgD,YAAY,aAAa,GAAG,UAAU;MACxF;AAEA,eAAS,2DAA2D,YACA,iBAAmC;AAErG,YAAI,gBAAgB,cAAc,GAAG;AACnC,gEACE,YACA,gBAAgB,QAChB,gBAAgB,YAChB,gBAAgB,WAAW;;AAG/B,yDAAiD,UAAU;MAC7D;AAEA,eAAS,4DAA4D,YACA,oBAAsC;AACzG,cAAM,iBAAiB,KAAK,IAAI,WAAW,iBACX,mBAAmB,aAAa,mBAAmB,WAAW;AAC9F,cAAM,iBAAiB,mBAAmB,cAAc;AAExD,YAAI,4BAA4B;AAChC,YAAI,QAAQ;AAEZ,cAAM,iBAAiB,iBAAiB,mBAAmB;AAC3D,cAAM,kBAAkB,iBAAiB;AAGzC,YAAI,mBAAmB,mBAAmB,aAAa;AACrD,sCAA4B,kBAAkB,mBAAmB;AACjE,kBAAQ;;AAGV,cAAM,QAAQ,WAAW;AAEzB,eAAO,4BAA4B,GAAG;AACpC,gBAAM,cAAc,MAAM,KAAI;AAE9B,gBAAM,cAAc,KAAK,IAAI,2BAA2B,YAAY,UAAU;AAE9E,gBAAM,YAAY,mBAAmB,aAAa,mBAAmB;AACrE,6BAAmB,mBAAmB,QAAQ,WAAW,YAAY,QAAQ,YAAY,YAAY,WAAW;AAEhH,cAAI,YAAY,eAAe,aAAa;AAC1C,kBAAM,MAAK;iBACN;AACL,wBAAY,cAAc;AAC1B,wBAAY,cAAc;;AAE5B,qBAAW,mBAAmB;AAE9B,iEAAuD,YAAY,aAAa,kBAAkB;AAElG,uCAA6B;;AAS/B,eAAO;MACT;AAEA,eAAS,uDAAuD,YACA,MACA,oBAAsC;AAGpG,2BAAmB,eAAe;MACpC;AAEA,eAAS,6CAA6C,YAAwC;AAG5F,YAAI,WAAW,oBAAoB,KAAK,WAAW,iBAAiB;AAClE,sDAA4C,UAAU;AACtD,8BAAoB,WAAW,6BAA6B;eACvD;AACL,uDAA6C,UAAU;;MAE3D;AAEA,eAAS,kDAAkD,YAAwC;AACjG,YAAI,WAAW,iBAAiB,MAAM;AACpC;;AAGF,mBAAW,aAAa,0CAA0C;AAClE,mBAAW,aAAa,QAAQ;AAChC,mBAAW,eAAe;MAC5B;AAEA,eAAS,iEAAiE,YAAwC;AAGhH,eAAO,WAAW,kBAAkB,SAAS,GAAG;AAC9C,cAAI,WAAW,oBAAoB,GAAG;AACpC;;AAGF,gBAAM,qBAAqB,WAAW,kBAAkB,KAAI;AAG5D,cAAI,4DAA4D,YAAY,kBAAkB,GAAG;AAC/F,6DAAiD,UAAU;AAE3D,iEACE,WAAW,+BACX,kBAAkB;;;MAI1B;AAEA,eAAS,0DAA0D,YAAwC;AACzG,cAAM,SAAS,WAAW,8BAA8B;AAExD,eAAO,OAAO,cAAc,SAAS,GAAG;AACtC,cAAI,WAAW,oBAAoB,GAAG;AACpC;;AAEF,gBAAM,cAAc,OAAO,cAAc,MAAK;AAC9C,+DAAqD,YAAY,WAAW;;MAEhF;AAEM,eAAU,qCACd,YACA,MACA,KACA,iBAAmC;AAEnC,cAAM,SAAS,WAAW;AAE1B,cAAM,OAAO,KAAK;AAClB,cAAM,cAAc,2BAA2B,IAAI;AAEnD,cAAM,EAAE,YAAY,WAAU,IAAK;AAEnC,cAAM,cAAc,MAAM;AAI1B,YAAI;AACJ,YAAI;AACF,mBAAS,oBAAoB,KAAK,MAAM;iBACjC,GAAG;AACV,0BAAgB,YAAY,CAAC;AAC7B;;AAGF,cAAM,qBAAgD;UACpD;UACA,kBAAkB,OAAO;UACzB;UACA;UACA,aAAa;UACb;UACA;UACA,iBAAiB;UACjB,YAAY;;AAGd,YAAI,WAAW,kBAAkB,SAAS,GAAG;AAC3C,qBAAW,kBAAkB,KAAK,kBAAkB;AAMpD,2CAAiC,QAAQ,eAAe;AACxD;;AAGF,YAAI,OAAO,WAAW,UAAU;AAC9B,gBAAM,YAAY,IAAI,KAAK,mBAAmB,QAAQ,mBAAmB,YAAY,CAAC;AACtF,0BAAgB,YAAY,SAAS;AACrC;;AAGF,YAAI,WAAW,kBAAkB,GAAG;AAClC,cAAI,4DAA4D,YAAY,kBAAkB,GAAG;AAC/F,kBAAM,aAAa,sDAAyD,kBAAkB;AAE9F,yDAA6C,UAAU;AAEvD,4BAAgB,YAAY,UAAU;AACtC;;AAGF,cAAI,WAAW,iBAAiB;AAC9B,kBAAM,IAAI,IAAI,UAAU,yDAAyD;AACjF,8CAAkC,YAAY,CAAC;AAE/C,4BAAgB,YAAY,CAAC;AAC7B;;;AAIJ,mBAAW,kBAAkB,KAAK,kBAAkB;AAEpD,yCAAoC,QAAQ,eAAe;AAC3D,qDAA6C,UAAU;MACzD;AAEA,eAAS,iDAAiD,YACA,iBAAmC;AAG3F,YAAI,gBAAgB,eAAe,QAAQ;AACzC,2DAAiD,UAAU;;AAG7D,cAAM,SAAS,WAAW;AAC1B,YAAI,4BAA4B,MAAM,GAAG;AACvC,iBAAO,qCAAqC,MAAM,IAAI,GAAG;AACvD,kBAAM,qBAAqB,iDAAiD,UAAU;AACtF,iEAAqD,QAAQ,kBAAkB;;;MAGrF;AAEA,eAAS,mDAAmD,YACA,cACA,oBAAsC;AAGhG,+DAAuD,YAAY,cAAc,kBAAkB;AAEnG,YAAI,mBAAmB,eAAe,QAAQ;AAC5C,qEAA2D,YAAY,kBAAkB;AACzF,2EAAiE,UAAU;AAC3E;;AAGF,YAAI,mBAAmB,cAAc,mBAAmB,aAAa;AAGnE;;AAGF,yDAAiD,UAAU;AAE3D,cAAM,gBAAgB,mBAAmB,cAAc,mBAAmB;AAC1E,YAAI,gBAAgB,GAAG;AACrB,gBAAM,MAAM,mBAAmB,aAAa,mBAAmB;AAC/D,gEACE,YACA,mBAAmB,QACnB,MAAM,eACN,aAAa;;AAIjB,2BAAmB,eAAe;AAClC,6DAAqD,WAAW,+BAA+B,kBAAkB;AAEjH,yEAAiE,UAAU;MAC7E;AAEA,eAAS,4CAA4C,YAA0C,cAAoB;AACjH,cAAM,kBAAkB,WAAW,kBAAkB,KAAI;AAGzD,0DAAkD,UAAU;AAE5D,cAAM,QAAQ,WAAW,8BAA8B;AACvD,YAAI,UAAU,UAAU;AAEtB,2DAAiD,YAAY,eAAe;eACvE;AAGL,6DAAmD,YAAY,cAAc,eAAe;;AAG9F,qDAA6C,UAAU;MACzD;AAEA,eAAS,iDACP,YAAwC;AAGxC,cAAM,aAAa,WAAW,kBAAkB,MAAK;AACrD,eAAO;MACT;AAEA,eAAS,2CAA2C,YAAwC;AAC1F,cAAM,SAAS,WAAW;AAE1B,YAAI,OAAO,WAAW,YAAY;AAChC,iBAAO;;AAGT,YAAI,WAAW,iBAAiB;AAC9B,iBAAO;;AAGT,YAAI,CAAC,WAAW,UAAU;AACxB,iBAAO;;AAGT,YAAI,+BAA+B,MAAM,KAAK,iCAAiC,MAAM,IAAI,GAAG;AAC1F,iBAAO;;AAGT,YAAI,4BAA4B,MAAM,KAAK,qCAAqC,MAAM,IAAI,GAAG;AAC3F,iBAAO;;AAGT,cAAM,cAAc,2CAA2C,UAAU;AAEzE,YAAI,cAAe,GAAG;AACpB,iBAAO;;AAGT,eAAO;MACT;AAEA,eAAS,4CAA4C,YAAwC;AAC3F,mBAAW,iBAAiB;AAC5B,mBAAW,mBAAmB;MAChC;AAIM,eAAU,kCAAkC,YAAwC;AACxF,cAAM,SAAS,WAAW;AAE1B,YAAI,WAAW,mBAAmB,OAAO,WAAW,YAAY;AAC9D;;AAGF,YAAI,WAAW,kBAAkB,GAAG;AAClC,qBAAW,kBAAkB;AAE7B;;AAGF,YAAI,WAAW,kBAAkB,SAAS,GAAG;AAC3C,gBAAM,uBAAuB,WAAW,kBAAkB,KAAI;AAC9D,cAAI,qBAAqB,cAAc,qBAAqB,gBAAgB,GAAG;AAC7E,kBAAM,IAAI,IAAI,UAAU,yDAAyD;AACjF,8CAAkC,YAAY,CAAC;AAE/C,kBAAM;;;AAIV,oDAA4C,UAAU;AACtD,4BAAoB,MAAM;MAC5B;AAEgB,eAAA,oCACd,YACA,OAAiC;AAEjC,cAAM,SAAS,WAAW;AAE1B,YAAI,WAAW,mBAAmB,OAAO,WAAW,YAAY;AAC9D;;AAGF,cAAM,EAAE,QAAQ,YAAY,WAAU,IAAK;AAC3C,YAAI,iBAAiB,MAAM,GAAG;AAC5B,gBAAM,IAAI,UAAU,sDAAuD;;AAE7E,cAAM,oBAAoB,oBAAoB,MAAM;AAEpD,YAAI,WAAW,kBAAkB,SAAS,GAAG;AAC3C,gBAAM,uBAAuB,WAAW,kBAAkB,KAAI;AAC9D,cAAI,iBAAiB,qBAAqB,MAAM,GAAG;AACjD,kBAAM,IAAI,UACR,4FAA6F;;AAGjG,4DAAkD,UAAU;AAC5D,+BAAqB,SAAS,oBAAoB,qBAAqB,MAAM;AAC7E,cAAI,qBAAqB,eAAe,QAAQ;AAC9C,uEAA2D,YAAY,oBAAoB;;;AAI/F,YAAI,+BAA+B,MAAM,GAAG;AAC1C,oEAA0D,UAAU;AACpE,cAAI,iCAAiC,MAAM,MAAM,GAAG;AAElD,4DAAgD,YAAY,mBAAmB,YAAY,UAAU;iBAChG;AAEL,gBAAI,WAAW,kBAAkB,SAAS,GAAG;AAE3C,+DAAiD,UAAU;;AAE7D,kBAAM,kBAAkB,IAAI,WAAW,mBAAmB,YAAY,UAAU;AAChF,6CAAiC,QAAQ,iBAA0C,KAAK;;mBAEjF,4BAA4B,MAAM,GAAG;AAE9C,0DAAgD,YAAY,mBAAmB,YAAY,UAAU;AACrG,2EAAiE,UAAU;eACtE;AAEL,0DAAgD,YAAY,mBAAmB,YAAY,UAAU;;AAGvG,qDAA6C,UAAU;MACzD;AAEgB,eAAA,kCAAkC,YAA0C,GAAM;AAChG,cAAM,SAAS,WAAW;AAE1B,YAAI,OAAO,WAAW,YAAY;AAChC;;AAGF,0DAAkD,UAAU;AAE5D,mBAAW,UAAU;AACrB,oDAA4C,UAAU;AACtD,4BAAoB,QAAQ,CAAC;MAC/B;AAEgB,eAAA,qDACd,YACA,aAA+C;AAI/C,cAAM,QAAQ,WAAW,OAAO,MAAK;AACrC,mBAAW,mBAAmB,MAAM;AAEpC,qDAA6C,UAAU;AAEvD,cAAM,OAAO,IAAI,WAAW,MAAM,QAAQ,MAAM,YAAY,MAAM,UAAU;AAC5E,oBAAY,YAAY,IAA6B;MACvD;AAEM,eAAU,2CACd,YAAwC;AAExC,YAAI,WAAW,iBAAiB,QAAQ,WAAW,kBAAkB,SAAS,GAAG;AAC/E,gBAAM,kBAAkB,WAAW,kBAAkB,KAAI;AACzD,gBAAM,OAAO,IAAI,WAAW,gBAAgB,QAChB,gBAAgB,aAAa,gBAAgB,aAC7C,gBAAgB,aAAa,gBAAgB,WAAW;AAEpF,gBAAM,cAAyC,OAAO,OAAO,0BAA0B,SAAS;AAChG,yCAA+B,aAAa,YAAY,IAA6B;AACrF,qBAAW,eAAe;;AAE5B,eAAO,WAAW;MACpB;AAEA,eAAS,2CAA2C,YAAwC;AAC1F,cAAM,QAAQ,WAAW,8BAA8B;AAEvD,YAAI,UAAU,WAAW;AACvB,iBAAO;;AAET,YAAI,UAAU,UAAU;AACtB,iBAAO;;AAGT,eAAO,WAAW,eAAe,WAAW;MAC9C;AAEgB,eAAA,oCAAoC,YAA0C,cAAoB;AAGhH,cAAM,kBAAkB,WAAW,kBAAkB,KAAI;AACzD,cAAM,QAAQ,WAAW,8BAA8B;AAEvD,YAAI,UAAU,UAAU;AACtB,cAAI,iBAAiB,GAAG;AACtB,kBAAM,IAAI,UAAU,kEAAkE;;eAEnF;AAEL,cAAI,iBAAiB,GAAG;AACtB,kBAAM,IAAI,UAAU,iFAAiF;;AAEvG,cAAI,gBAAgB,cAAc,eAAe,gBAAgB,YAAY;AAC3E,kBAAM,IAAI,WAAW,2BAA2B;;;AAIpD,wBAAgB,SAAS,oBAAoB,gBAAgB,MAAM;AAEnE,oDAA4C,YAAY,YAAY;MACtE;AAEgB,eAAA,+CAA+C,YACA,MAAgC;AAI7F,cAAM,kBAAkB,WAAW,kBAAkB,KAAI;AACzD,cAAM,QAAQ,WAAW,8BAA8B;AAEvD,YAAI,UAAU,UAAU;AACtB,cAAI,KAAK,eAAe,GAAG;AACzB,kBAAM,IAAI,UAAU,kFAAmF;;eAEpG;AAEL,cAAI,KAAK,eAAe,GAAG;AACzB,kBAAM,IAAI,UACR,iGAAkG;;;AAKxG,YAAI,gBAAgB,aAAa,gBAAgB,gBAAgB,KAAK,YAAY;AAChF,gBAAM,IAAI,WAAW,yDAAyD;;AAEhF,YAAI,gBAAgB,qBAAqB,KAAK,OAAO,YAAY;AAC/D,gBAAM,IAAI,WAAW,4DAA4D;;AAEnF,YAAI,gBAAgB,cAAc,KAAK,aAAa,gBAAgB,YAAY;AAC9E,gBAAM,IAAI,WAAW,yDAAyD;;AAGhF,cAAM,iBAAiB,KAAK;AAC5B,wBAAgB,SAAS,oBAAoB,KAAK,MAAM;AACxD,oDAA4C,YAAY,cAAc;MACxE;AAEgB,eAAA,kCAAkC,QACA,YACA,gBACA,eACA,iBACA,eACA,uBAAyC;AAOzF,mBAAW,gCAAgC;AAE3C,mBAAW,aAAa;AACxB,mBAAW,WAAW;AAEtB,mBAAW,eAAe;AAG1B,mBAAW,SAAS,WAAW,kBAAkB;AACjD,mBAAW,UAAU;AAErB,mBAAW,kBAAkB;AAC7B,mBAAW,WAAW;AAEtB,mBAAW,eAAe;AAE1B,mBAAW,iBAAiB;AAC5B,mBAAW,mBAAmB;AAE9B,mBAAW,yBAAyB;AAEpC,mBAAW,oBAAoB,IAAI,YAAW;AAE9C,eAAO,4BAA4B;AAEnC,cAAM,cAAc,eAAc;AAClC,oBACE,oBAAoB,WAAW,GAC/B,MAAK;AACH,qBAAW,WAAW;AAKtB,uDAA6C,UAAU;AACvD,iBAAO;WAET,OAAI;AACF,4CAAkC,YAAY,CAAC;AAC/C,iBAAO;QACT,CAAC;MAEL;eAEgB,sDACd,QACA,sBACA,eAAqB;AAErB,cAAM,aAA2C,OAAO,OAAO,6BAA6B,SAAS;AAErG,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI,qBAAqB,UAAU,QAAW;AAC5C,2BAAiB,MAAM,qBAAqB,MAAO,UAAU;eACxD;AACL,2BAAiB,MAAM;;AAEzB,YAAI,qBAAqB,SAAS,QAAW;AAC3C,0BAAgB,MAAM,qBAAqB,KAAM,UAAU;eACtD;AACL,0BAAgB,MAAM,oBAAoB,MAAS;;AAErD,YAAI,qBAAqB,WAAW,QAAW;AAC7C,4BAAkB,YAAU,qBAAqB,OAAQ,MAAM;eAC1D;AACL,4BAAkB,MAAM,oBAAoB,MAAS;;AAGvD,cAAM,wBAAwB,qBAAqB;AACnD,YAAI,0BAA0B,GAAG;AAC/B,gBAAM,IAAI,UAAU,8CAA8C;;AAGpE,0CACE,QAAQ,YAAY,gBAAgB,eAAe,iBAAiB,eAAe,qBAAqB;MAE5G;AAEA,eAAS,+BAA+B,SACA,YACA,MAAgC;AAKtE,gBAAQ,0CAA0C;AAClD,gBAAQ,QAAQ;MAClB;AAIA,eAAS,+BAA+B,MAAY;AAClD,eAAO,IAAI,UACT,uCAAuC,IAAI,kDAAkD;MACjG;AAIA,eAAS,wCAAwC,MAAY;AAC3D,eAAO,IAAI,UACT,0CAA0C,IAAI,qDAAqD;MACvG;AC1nCgB,eAAA,qBAAqB,SACA,SAAe;AAClD,yBAAiB,SAAS,OAAO;AACjC,cAAM,OAAO,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AACtB,eAAO;UACL,MAAM,SAAS,SAAY,SAAY,gCAAgC,MAAM,GAAG,OAAO,yBAAyB;;MAEpH;AAEA,eAAS,gCAAgC,MAAc,SAAe;AACpE,eAAO,GAAG,IAAI;AACd,YAAI,SAAS,QAAQ;AACnB,gBAAM,IAAI,UAAU,GAAG,OAAO,KAAK,IAAI,iEAAiE;;AAE1G,eAAO;MACT;AAEgB,eAAA,uBACd,SACA,SAAe;;AAEf,yBAAiB,SAAS,OAAO;AACjC,cAAM,OAAMA,MAAA,YAAA,QAAA,YAAA,SAAA,SAAA,QAAS,SAAO,QAAAA,QAAA,SAAAA,MAAA;AAC5B,eAAO;UACL,KAAK,wCACH,KACA,GAAG,OAAO,wBAAwB;;MAGxC;ACKM,eAAU,gCAAgC,QAA0B;AACxE,eAAO,IAAI,yBAAyB,MAAoC;MAC1E;AAIgB,eAAA,iCACd,QACA,iBAAmC;AAKlC,eAAO,QAAsC,kBAAkB,KAAK,eAAe;MACtF;eAEgB,qCAAqC,QACA,OACA,MAAa;AAChE,cAAM,SAAS,OAAO;AAItB,cAAM,kBAAkB,OAAO,kBAAkB,MAAK;AACtD,YAAI,MAAM;AACR,0BAAgB,YAAY,KAAK;eAC5B;AACL,0BAAgB,YAAY,KAAK;;MAErC;AAEM,eAAU,qCAAqC,QAA0B;AAC7E,eAAQ,OAAO,QAAqC,kBAAkB;MACxE;AAEM,eAAU,4BAA4B,QAA0B;AACpE,cAAM,SAAS,OAAO;AAEtB,YAAI,WAAW,QAAW;AACxB,iBAAO;;AAGT,YAAI,CAAC,2BAA2B,MAAM,GAAG;AACvC,iBAAO;;AAGT,eAAO;MACT;YAiBa,yBAAwB;QAYnC,YAAY,QAAkC;AAC5C,iCAAuB,QAAQ,GAAG,0BAA0B;AAC5D,+BAAqB,QAAQ,iBAAiB;AAE9C,cAAI,uBAAuB,MAAM,GAAG;AAClC,kBAAM,IAAI,UAAU,6EAA6E;;AAGnG,cAAI,CAAC,+BAA+B,OAAO,yBAAyB,GAAG;AACrE,kBAAM,IAAI,UAAU,6FACV;;AAGZ,gDAAsC,MAAM,MAAM;AAElD,eAAK,oBAAoB,IAAI,YAAW;;;;;;QAO1C,IAAI,SAAM;AACR,cAAI,CAAC,2BAA2B,IAAI,GAAG;AACrC,mBAAO,oBAAoB,8BAA8B,QAAQ,CAAC;;AAGpE,iBAAO,KAAK;;;;;QAMd,OAAO,SAAc,QAAS;AAC5B,cAAI,CAAC,2BAA2B,IAAI,GAAG;AACrC,mBAAO,oBAAoB,8BAA8B,QAAQ,CAAC;;AAGpE,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,oBAAoB,QAAQ,CAAC;;AAG1D,iBAAO,kCAAkC,MAAM,MAAM;;QAYvD,KACE,MACA,aAAqE,CAAA,GAAE;AAEvE,cAAI,CAAC,2BAA2B,IAAI,GAAG;AACrC,mBAAO,oBAAoB,8BAA8B,MAAM,CAAC;;AAGlE,cAAI,CAAC,YAAY,OAAO,IAAI,GAAG;AAC7B,mBAAO,oBAAoB,IAAI,UAAU,mCAAmC,CAAC;;AAE/E,cAAI,KAAK,eAAe,GAAG;AACzB,mBAAO,oBAAoB,IAAI,UAAU,oCAAoC,CAAC;;AAEhF,cAAI,KAAK,OAAO,eAAe,GAAG;AAChC,mBAAO,oBAAoB,IAAI,UAAU,6CAA6C,CAAC;;AAEzF,cAAI,iBAAiB,KAAK,MAAM,GAAG;AACjC,mBAAO,oBAAoB,IAAI,UAAU,iCAAkC,CAAC;;AAG9E,cAAI;AACJ,cAAI;AACF,sBAAU,uBAAuB,YAAY,SAAS;mBAC/C,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAE9B,gBAAM,MAAM,QAAQ;AACpB,cAAI,QAAQ,GAAG;AACb,mBAAO,oBAAoB,IAAI,UAAU,oCAAoC,CAAC;;AAEhF,cAAI,CAAC,WAAW,IAAI,GAAG;AACrB,gBAAI,MAAO,KAA+B,QAAQ;AAChD,qBAAO,oBAAoB,IAAI,WAAW,yDAA0D,CAAC;;qBAE9F,MAAM,KAAK,YAAY;AAChC,mBAAO,oBAAoB,IAAI,WAAW,6DAA8D,CAAC;;AAG3G,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,oBAAoB,WAAW,CAAC;;AAG7D,cAAI;AACJ,cAAI;AACJ,gBAAM,UAAU,WAA4C,CAAC,SAAS,WAAU;AAC9E,6BAAiB;AACjB,4BAAgB;UAClB,CAAC;AACD,gBAAM,kBAAsC;YAC1C,aAAa,WAAS,eAAe,EAAE,OAAO,OAAO,MAAM,MAAK,CAAE;YAClE,aAAa,WAAS,eAAe,EAAE,OAAO,OAAO,MAAM,KAAI,CAAE;YACjE,aAAa,OAAK,cAAc,CAAC;;AAEnC,uCAA6B,MAAM,MAAM,KAAK,eAAe;AAC7D,iBAAO;;;;;;;;;;;QAYT,cAAW;AACT,cAAI,CAAC,2BAA2B,IAAI,GAAG;AACrC,kBAAM,8BAA8B,aAAa;;AAGnD,cAAI,KAAK,yBAAyB,QAAW;AAC3C;;AAGF,0CAAgC,IAAI;;MAEvC;AAED,aAAO,iBAAiB,yBAAyB,WAAW;QAC1D,QAAQ,EAAE,YAAY,KAAI;QAC1B,MAAM,EAAE,YAAY,KAAI;QACxB,aAAa,EAAE,YAAY,KAAI;QAC/B,QAAQ,EAAE,YAAY,KAAI;MAC3B,CAAA;AACD,sBAAgB,yBAAyB,UAAU,QAAQ,QAAQ;AACnE,sBAAgB,yBAAyB,UAAU,MAAM,MAAM;AAC/D,sBAAgB,yBAAyB,UAAU,aAAa,aAAa;AAC7E,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,yBAAyB,WAAW,OAAO,aAAa;UAC5E,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIM,eAAU,2BAA2B,GAAM;AAC/C,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,mBAAmB,GAAG;AACjE,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEM,eAAU,6BACd,QACA,MACA,KACA,iBAAmC;AAEnC,cAAM,SAAS,OAAO;AAItB,eAAO,aAAa;AAEpB,YAAI,OAAO,WAAW,WAAW;AAC/B,0BAAgB,YAAY,OAAO,YAAY;eAC1C;AACL,+CACE,OAAO,2BACP,MACA,KACA,eAAe;;MAGrB;AAEM,eAAU,gCAAgC,QAAgC;AAC9E,2CAAmC,MAAM;AACzC,cAAM,IAAI,IAAI,UAAU,qBAAqB;AAC7C,sDAA8C,QAAQ,CAAC;MACzD;AAEgB,eAAA,8CAA8C,QAAkC,GAAM;AACpG,cAAM,mBAAmB,OAAO;AAChC,eAAO,oBAAoB,IAAI,YAAW;AAC1C,yBAAiB,QAAQ,qBAAkB;AACzC,0BAAgB,YAAY,CAAC;QAC/B,CAAC;MACH;AAIA,eAAS,8BAA8B,MAAY;AACjD,eAAO,IAAI,UACT,sCAAsC,IAAI,iDAAiD;MAC/F;ACjUgB,eAAA,qBAAqB,UAA2B,YAAkB;AAChF,cAAM,EAAE,cAAa,IAAK;AAE1B,YAAI,kBAAkB,QAAW;AAC/B,iBAAO;;AAGT,YAAI,YAAY,aAAa,KAAK,gBAAgB,GAAG;AACnD,gBAAM,IAAI,WAAW,uBAAuB;;AAG9C,eAAO;MACT;AAEM,eAAU,qBAAwB,UAA4B;AAClE,cAAM,EAAE,KAAI,IAAK;AAEjB,YAAI,CAAC,MAAM;AACT,iBAAO,MAAM;;AAGf,eAAO;MACT;ACtBgB,eAAA,uBAA0B,MACA,SAAe;AACvD,yBAAiB,MAAM,OAAO;AAC9B,cAAM,gBAAgB,SAAI,QAAJ,SAAA,SAAA,SAAA,KAAM;AAC5B,cAAM,OAAO,SAAI,QAAJ,SAAA,SAAA,SAAA,KAAM;AACnB,eAAO;UACL,eAAe,kBAAkB,SAAY,SAAY,0BAA0B,aAAa;UAChG,MAAM,SAAS,SAAY,SAAY,2BAA2B,MAAM,GAAG,OAAO,yBAAyB;;MAE/G;AAEA,eAAS,2BAA8B,IACA,SAAe;AACpD,uBAAe,IAAI,OAAO;AAC1B,eAAO,WAAS,0BAA0B,GAAG,KAAK,CAAC;MACrD;ACNgB,eAAA,sBAAyB,UACA,SAAe;AACtD,yBAAiB,UAAU,OAAO;AAClC,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,OAAO,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACvB,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,eAAO;UACL,OAAO,UAAU,SACf,SACA,mCAAmC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UAC3F,OAAO,UAAU,SACf,SACA,mCAAmC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UAC3F,OAAO,UAAU,SACf,SACA,mCAAmC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UAC3F,OAAO,UAAU,SACf,SACA,mCAAmC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UAC3F;;MAEJ;AAEA,eAAS,mCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,WAAgB,YAAY,IAAI,UAAU,CAAC,MAAM,CAAC;MAC5D;AAEA,eAAS,mCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,MAAM,YAAY,IAAI,UAAU,CAAA,CAAE;MAC3C;AAEA,eAAS,mCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,eAAgD,YAAY,IAAI,UAAU,CAAC,UAAU,CAAC;MAChG;AAEA,eAAS,mCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,OAAU,eAAgD,YAAY,IAAI,UAAU,CAAC,OAAO,UAAU,CAAC;MACjH;ACrEgB,eAAA,qBAAqB,GAAY,SAAe;AAC9D,YAAI,CAAC,iBAAiB,CAAC,GAAG;AACxB,gBAAM,IAAI,UAAU,GAAG,OAAO,2BAA2B;;MAE7D;AC2BM,eAAU,cAAc,OAAc;AAC1C,YAAI,OAAO,UAAU,YAAY,UAAU,MAAM;AAC/C,iBAAO;;AAET,YAAI;AACF,iBAAO,OAAQ,MAAsB,YAAY;iBACjDA,KAAM;AAEN,iBAAO;;MAEX;AAsBA,YAAM,0BAA0B,OAAQ,oBAA4B;eAOpD,wBAAqB;AACnC,YAAI,yBAAyB;AAC3B,iBAAO,IAAK,gBAA8C;;AAE5D,eAAO;MACT;MCnBA,MAAM,eAAc;QAuBlB,YAAY,oBAA0D,CAAA,GAC1D,cAAqD,CAAA,GAAE;AACjE,cAAI,sBAAsB,QAAW;AACnC,gCAAoB;iBACf;AACL,yBAAa,mBAAmB,iBAAiB;;AAGnD,gBAAM,WAAW,uBAAuB,aAAa,kBAAkB;AACvE,gBAAM,iBAAiB,sBAAsB,mBAAmB,iBAAiB;AAEjF,mCAAyB,IAAI;AAE7B,gBAAM,OAAO,eAAe;AAC5B,cAAI,SAAS,QAAW;AACtB,kBAAM,IAAI,WAAW,2BAA2B;;AAGlD,gBAAM,gBAAgB,qBAAqB,QAAQ;AACnD,gBAAM,gBAAgB,qBAAqB,UAAU,CAAC;AAEtD,iEAAuD,MAAM,gBAAgB,eAAe,aAAa;;;;;QAM3G,IAAI,SAAM;AACR,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAME,4BAA0B,QAAQ;;AAG1C,iBAAO,uBAAuB,IAAI;;;;;;;;;;;QAYpC,MAAM,SAAc,QAAS;AAC3B,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,mBAAO,oBAAoBA,4BAA0B,OAAO,CAAC;;AAG/D,cAAI,uBAAuB,IAAI,GAAG;AAChC,mBAAO,oBAAoB,IAAI,UAAU,iDAAiD,CAAC;;AAG7F,iBAAO,oBAAoB,MAAM,MAAM;;;;;;;;;;QAWzC,QAAK;AACH,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,mBAAO,oBAAoBA,4BAA0B,OAAO,CAAC;;AAG/D,cAAI,uBAAuB,IAAI,GAAG;AAChC,mBAAO,oBAAoB,IAAI,UAAU,iDAAiD,CAAC;;AAG7F,cAAI,oCAAoC,IAAI,GAAG;AAC7C,mBAAO,oBAAoB,IAAI,UAAU,wCAAwC,CAAC;;AAGpF,iBAAO,oBAAoB,IAAI;;;;;;;;;;QAWjC,YAAS;AACP,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMA,4BAA0B,WAAW;;AAG7C,iBAAO,mCAAmC,IAAI;;MAEjD;AAED,aAAO,iBAAiB,eAAe,WAAW;QAChD,OAAO,EAAE,YAAY,KAAI;QACzB,OAAO,EAAE,YAAY,KAAI;QACzB,WAAW,EAAE,YAAY,KAAI;QAC7B,QAAQ,EAAE,YAAY,KAAI;MAC3B,CAAA;AACD,sBAAgB,eAAe,UAAU,OAAO,OAAO;AACvD,sBAAgB,eAAe,UAAU,OAAO,OAAO;AACvD,sBAAgB,eAAe,UAAU,WAAW,WAAW;AAC/D,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,eAAe,WAAW,OAAO,aAAa;UAClE,OAAO;UACP,cAAc;QACf,CAAA;MACH;AA0BA,eAAS,mCAAsC,QAAyB;AACtE,eAAO,IAAI,4BAA4B,MAAM;MAC/C;AAGA,eAAS,qBAAwB,gBACA,gBACA,gBACA,gBACA,gBAAgB,GAChB,gBAAgD,MAAM,GAAC;AAGtF,cAAM,SAA4B,OAAO,OAAO,eAAe,SAAS;AACxE,iCAAyB,MAAM;AAE/B,cAAM,aAAiD,OAAO,OAAO,gCAAgC,SAAS;AAE9G,6CAAqC,QAAQ,YAAY,gBAAgB,gBAAgB,gBACpD,gBAAgB,eAAe,aAAa;AACjF,eAAO;MACT;AAEA,eAAS,yBAA4B,QAAyB;AAC5D,eAAO,SAAS;AAIhB,eAAO,eAAe;AAEtB,eAAO,UAAU;AAIjB,eAAO,4BAA4B;AAInC,eAAO,iBAAiB,IAAI,YAAW;AAIvC,eAAO,wBAAwB;AAI/B,eAAO,gBAAgB;AAIvB,eAAO,wBAAwB;AAG/B,eAAO,uBAAuB;AAG9B,eAAO,gBAAgB;MACzB;AAEA,eAAS,iBAAiB,GAAU;AAClC,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,2BAA2B,GAAG;AACzE,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,uBAAuB,QAAsB;AAGpD,YAAI,OAAO,YAAY,QAAW;AAChC,iBAAO;;AAGT,eAAO;MACT;AAEA,eAAS,oBAAoB,QAAwB,QAAW;;AAC9D,YAAI,OAAO,WAAW,YAAY,OAAO,WAAW,WAAW;AAC7D,iBAAO,oBAAoB,MAAS;;AAEtC,eAAO,0BAA0B,eAAe;AAChD,SAAAF,MAAA,OAAO,0BAA0B,sBAAgB,QAAAA,QAAA,SAAA,SAAAA,IAAE,MAAM,MAAM;AAK/D,cAAM,QAAQ,OAAO;AAErB,YAAI,UAAU,YAAY,UAAU,WAAW;AAC7C,iBAAO,oBAAoB,MAAS;;AAEtC,YAAI,OAAO,yBAAyB,QAAW;AAC7C,iBAAO,OAAO,qBAAqB;;AAKrC,YAAI,qBAAqB;AACzB,YAAI,UAAU,YAAY;AACxB,+BAAqB;AAErB,mBAAS;;AAGX,cAAM,UAAU,WAAsB,CAAC,SAAS,WAAU;AACxD,iBAAO,uBAAuB;YAC5B,UAAU;YACV,UAAU;YACV,SAAS;YACT,SAAS;YACT,qBAAqB;;QAEzB,CAAC;AACD,eAAO,qBAAsB,WAAW;AAExC,YAAI,CAAC,oBAAoB;AACvB,sCAA4B,QAAQ,MAAM;;AAG5C,eAAO;MACT;AAEA,eAAS,oBAAoB,QAA2B;AACtD,cAAM,QAAQ,OAAO;AACrB,YAAI,UAAU,YAAY,UAAU,WAAW;AAC7C,iBAAO,oBAAoB,IAAI,UAC7B,kBAAkB,KAAK,2DAA2D,CAAC;;AAMvF,cAAM,UAAU,WAAsB,CAAC,SAAS,WAAU;AACxD,gBAAM,eAA6B;YACjC,UAAU;YACV,SAAS;;AAGX,iBAAO,gBAAgB;QACzB,CAAC;AAED,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,UAAa,OAAO,iBAAiB,UAAU,YAAY;AACxE,2CAAiC,MAAM;;AAGzC,6CAAqC,OAAO,yBAAyB;AAErE,eAAO;MACT;AAIA,eAAS,8BAA8B,QAAsB;AAI3D,cAAM,UAAU,WAAsB,CAAC,SAAS,WAAU;AACxD,gBAAM,eAA6B;YACjC,UAAU;YACV,SAAS;;AAGX,iBAAO,eAAe,KAAK,YAAY;QACzC,CAAC;AAED,eAAO;MACT;AAEA,eAAS,gCAAgC,QAAwB,OAAU;AACzE,cAAM,QAAQ,OAAO;AAErB,YAAI,UAAU,YAAY;AACxB,sCAA4B,QAAQ,KAAK;AACzC;;AAIF,qCAA6B,MAAM;MACrC;AAEA,eAAS,4BAA4B,QAAwB,QAAW;AAItE,cAAM,aAAa,OAAO;AAG1B,eAAO,SAAS;AAChB,eAAO,eAAe;AACtB,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,QAAW;AACxB,gEAAsD,QAAQ,MAAM;;AAGtE,YAAI,CAAC,yCAAyC,MAAM,KAAK,WAAW,UAAU;AAC5E,uCAA6B,MAAM;;MAEvC;AAEA,eAAS,6BAA6B,QAAsB;AAG1D,eAAO,SAAS;AAChB,eAAO,0BAA0B,UAAU,EAAC;AAE5C,cAAM,cAAc,OAAO;AAC3B,eAAO,eAAe,QAAQ,kBAAe;AAC3C,uBAAa,QAAQ,WAAW;QAClC,CAAC;AACD,eAAO,iBAAiB,IAAI,YAAW;AAEvC,YAAI,OAAO,yBAAyB,QAAW;AAC7C,4DAAkD,MAAM;AACxD;;AAGF,cAAM,eAAe,OAAO;AAC5B,eAAO,uBAAuB;AAE9B,YAAI,aAAa,qBAAqB;AACpC,uBAAa,QAAQ,WAAW;AAChC,4DAAkD,MAAM;AACxD;;AAGF,cAAM,UAAU,OAAO,0BAA0B,UAAU,EAAE,aAAa,OAAO;AACjF,oBACE,SACA,MAAK;AACH,uBAAa,SAAQ;AACrB,4DAAkD,MAAM;AACxD,iBAAO;QACT,GACA,CAAC,WAAe;AACd,uBAAa,QAAQ,MAAM;AAC3B,4DAAkD,MAAM;AACxD,iBAAO;QACT,CAAC;MACL;AAEA,eAAS,kCAAkC,QAAsB;AAE/D,eAAO,sBAAuB,SAAS,MAAS;AAChD,eAAO,wBAAwB;MACjC;AAEA,eAAS,2CAA2C,QAAwB,OAAU;AAEpF,eAAO,sBAAuB,QAAQ,KAAK;AAC3C,eAAO,wBAAwB;AAI/B,wCAAgC,QAAQ,KAAK;MAC/C;AAEA,eAAS,kCAAkC,QAAsB;AAE/D,eAAO,sBAAuB,SAAS,MAAS;AAChD,eAAO,wBAAwB;AAE/B,cAAM,QAAQ,OAAO;AAIrB,YAAI,UAAU,YAAY;AAExB,iBAAO,eAAe;AACtB,cAAI,OAAO,yBAAyB,QAAW;AAC7C,mBAAO,qBAAqB,SAAQ;AACpC,mBAAO,uBAAuB;;;AAIlC,eAAO,SAAS;AAEhB,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,QAAW;AACxB,4CAAkC,MAAM;;MAK5C;AAEA,eAAS,2CAA2C,QAAwB,OAAU;AAEpF,eAAO,sBAAuB,QAAQ,KAAK;AAC3C,eAAO,wBAAwB;AAK/B,YAAI,OAAO,yBAAyB,QAAW;AAC7C,iBAAO,qBAAqB,QAAQ,KAAK;AACzC,iBAAO,uBAAuB;;AAEhC,wCAAgC,QAAQ,KAAK;MAC/C;AAGA,eAAS,oCAAoC,QAAsB;AACjE,YAAI,OAAO,kBAAkB,UAAa,OAAO,0BAA0B,QAAW;AACpF,iBAAO;;AAGT,eAAO;MACT;AAEA,eAAS,yCAAyC,QAAsB;AACtE,YAAI,OAAO,0BAA0B,UAAa,OAAO,0BAA0B,QAAW;AAC5F,iBAAO;;AAGT,eAAO;MACT;AAEA,eAAS,uCAAuC,QAAsB;AAGpE,eAAO,wBAAwB,OAAO;AACtC,eAAO,gBAAgB;MACzB;AAEA,eAAS,4CAA4C,QAAsB;AAGzE,eAAO,wBAAwB,OAAO,eAAe,MAAK;MAC5D;AAEA,eAAS,kDAAkD,QAAsB;AAE/E,YAAI,OAAO,kBAAkB,QAAW;AAGtC,iBAAO,cAAc,QAAQ,OAAO,YAAY;AAChD,iBAAO,gBAAgB;;AAEzB,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,QAAW;AACxB,2CAAiC,QAAQ,OAAO,YAAY;;MAEhE;AAEA,eAAS,iCAAiC,QAAwB,cAAqB;AAIrF,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,UAAa,iBAAiB,OAAO,eAAe;AACjE,cAAI,cAAc;AAChB,2CAA+B,MAAM;iBAChC;AAGL,6CAAiC,MAAM;;;AAI3C,eAAO,gBAAgB;MACzB;YAOa,4BAA2B;QAoBtC,YAAY,QAAyB;AACnC,iCAAuB,QAAQ,GAAG,6BAA6B;AAC/D,+BAAqB,QAAQ,iBAAiB;AAE9C,cAAI,uBAAuB,MAAM,GAAG;AAClC,kBAAM,IAAI,UAAU,6EAA6E;;AAGnG,eAAK,uBAAuB;AAC5B,iBAAO,UAAU;AAEjB,gBAAM,QAAQ,OAAO;AAErB,cAAI,UAAU,YAAY;AACxB,gBAAI,CAAC,oCAAoC,MAAM,KAAK,OAAO,eAAe;AACxE,kDAAoC,IAAI;mBACnC;AACL,4DAA8C,IAAI;;AAGpD,iDAAqC,IAAI;qBAChC,UAAU,YAAY;AAC/B,0DAA8C,MAAM,OAAO,YAAY;AACvE,iDAAqC,IAAI;qBAChC,UAAU,UAAU;AAC7B,0DAA8C,IAAI;AAClD,2DAA+C,IAAI;iBAC9C;AAGL,kBAAM,cAAc,OAAO;AAC3B,0DAA8C,MAAM,WAAW;AAC/D,2DAA+C,MAAM,WAAW;;;;;;;QAQpE,IAAI,SAAM;AACR,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,QAAQ,CAAC;;AAGvE,iBAAO,KAAK;;;;;;;;;;QAWd,IAAI,cAAW;AACb,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,kBAAM,iCAAiC,aAAa;;AAGtD,cAAI,KAAK,yBAAyB,QAAW;AAC3C,kBAAM,2BAA2B,aAAa;;AAGhD,iBAAO,0CAA0C,IAAI;;;;;;;;;;QAWvD,IAAI,QAAK;AACP,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,OAAO,CAAC;;AAGtE,iBAAO,KAAK;;;;;QAMd,MAAM,SAAc,QAAS;AAC3B,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,OAAO,CAAC;;AAGtE,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,2BAA2B,OAAO,CAAC;;AAGhE,iBAAO,iCAAiC,MAAM,MAAM;;;;;QAMtD,QAAK;AACH,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,OAAO,CAAC;;AAGtE,gBAAM,SAAS,KAAK;AAEpB,cAAI,WAAW,QAAW;AACxB,mBAAO,oBAAoB,2BAA2B,OAAO,CAAC;;AAGhE,cAAI,oCAAoC,MAAM,GAAG;AAC/C,mBAAO,oBAAoB,IAAI,UAAU,wCAAwC,CAAC;;AAGpF,iBAAO,iCAAiC,IAAI;;;;;;;;;;;;QAa9C,cAAW;AACT,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,kBAAM,iCAAiC,aAAa;;AAGtD,gBAAM,SAAS,KAAK;AAEpB,cAAI,WAAW,QAAW;AACxB;;AAKF,6CAAmC,IAAI;;QAazC,MAAM,QAAW,QAAU;AACzB,cAAI,CAAC,8BAA8B,IAAI,GAAG;AACxC,mBAAO,oBAAoB,iCAAiC,OAAO,CAAC;;AAGtE,cAAI,KAAK,yBAAyB,QAAW;AAC3C,mBAAO,oBAAoB,2BAA2B,UAAU,CAAC;;AAGnE,iBAAO,iCAAiC,MAAM,KAAK;;MAEtD;AAED,aAAO,iBAAiB,4BAA4B,WAAW;QAC7D,OAAO,EAAE,YAAY,KAAI;QACzB,OAAO,EAAE,YAAY,KAAI;QACzB,aAAa,EAAE,YAAY,KAAI;QAC/B,OAAO,EAAE,YAAY,KAAI;QACzB,QAAQ,EAAE,YAAY,KAAI;QAC1B,aAAa,EAAE,YAAY,KAAI;QAC/B,OAAO,EAAE,YAAY,KAAI;MAC1B,CAAA;AACD,sBAAgB,4BAA4B,UAAU,OAAO,OAAO;AACpE,sBAAgB,4BAA4B,UAAU,OAAO,OAAO;AACpE,sBAAgB,4BAA4B,UAAU,aAAa,aAAa;AAChF,sBAAgB,4BAA4B,UAAU,OAAO,OAAO;AACpE,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,4BAA4B,WAAW,OAAO,aAAa;UAC/E,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,8BAAuC,GAAM;AACpD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,sBAAsB,GAAG;AACpE,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAIA,eAAS,iCAAiC,QAAqC,QAAW;AACxF,cAAM,SAAS,OAAO;AAItB,eAAO,oBAAoB,QAAQ,MAAM;MAC3C;AAEA,eAAS,iCAAiC,QAAmC;AAC3E,cAAM,SAAS,OAAO;AAItB,eAAO,oBAAoB,MAAM;MACnC;AAEA,eAAS,qDAAqD,QAAmC;AAC/F,cAAM,SAAS,OAAO;AAItB,cAAM,QAAQ,OAAO;AACrB,YAAI,oCAAoC,MAAM,KAAK,UAAU,UAAU;AACrE,iBAAO,oBAAoB,MAAS;;AAGtC,YAAI,UAAU,WAAW;AACvB,iBAAO,oBAAoB,OAAO,YAAY;;AAKhD,eAAO,iCAAiC,MAAM;MAChD;AAEA,eAAS,uDAAuD,QAAqC,OAAU;AAC7G,YAAI,OAAO,wBAAwB,WAAW;AAC5C,2CAAiC,QAAQ,KAAK;eACzC;AACL,oDAA0C,QAAQ,KAAK;;MAE3D;AAEA,eAAS,sDAAsD,QAAqC,OAAU;AAC5G,YAAI,OAAO,uBAAuB,WAAW;AAC3C,0CAAgC,QAAQ,KAAK;eACxC;AACL,mDAAyC,QAAQ,KAAK;;MAE1D;AAEA,eAAS,0CAA0C,QAAmC;AACpF,cAAM,SAAS,OAAO;AACtB,cAAM,QAAQ,OAAO;AAErB,YAAI,UAAU,aAAa,UAAU,YAAY;AAC/C,iBAAO;;AAGT,YAAI,UAAU,UAAU;AACtB,iBAAO;;AAGT,eAAO,8CAA8C,OAAO,yBAAyB;MACvF;AAEA,eAAS,mCAAmC,QAAmC;AAC7E,cAAM,SAAS,OAAO;AAItB,cAAM,gBAAgB,IAAI,UACxB,kFAAkF;AAEpF,8DAAsD,QAAQ,aAAa;AAI3E,+DAAuD,QAAQ,aAAa;AAE5E,eAAO,UAAU;AACjB,eAAO,uBAAuB;MAChC;AAEA,eAAS,iCAAoC,QAAwC,OAAQ;AAC3F,cAAM,SAAS,OAAO;AAItB,cAAM,aAAa,OAAO;AAE1B,cAAM,YAAY,4CAA4C,YAAY,KAAK;AAE/E,YAAI,WAAW,OAAO,sBAAsB;AAC1C,iBAAO,oBAAoB,2BAA2B,UAAU,CAAC;;AAGnE,cAAM,QAAQ,OAAO;AACrB,YAAI,UAAU,WAAW;AACvB,iBAAO,oBAAoB,OAAO,YAAY;;AAEhD,YAAI,oCAAoC,MAAM,KAAK,UAAU,UAAU;AACrE,iBAAO,oBAAoB,IAAI,UAAU,0DAA0D,CAAC;;AAEtG,YAAI,UAAU,YAAY;AACxB,iBAAO,oBAAoB,OAAO,YAAY;;AAKhD,cAAM,UAAU,8BAA8B,MAAM;AAEpD,6CAAqC,YAAY,OAAO,SAAS;AAEjE,eAAO;MACT;AAEA,YAAM,gBAA+B,CAAA;YASxB,gCAA+B;QAwB1C,cAAA;AACE,gBAAM,IAAI,UAAU,qBAAqB;;;;;;;;;QAU3C,IAAI,cAAW;AACb,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMG,uCAAqC,aAAa;;AAE1D,iBAAO,KAAK;;;;;QAMd,IAAI,SAAM;AACR,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMA,uCAAqC,QAAQ;;AAErD,cAAI,KAAK,qBAAqB,QAAW;AAIvC,kBAAM,IAAI,UAAU,mEAAmE;;AAEzF,iBAAO,KAAK,iBAAiB;;;;;;;;;QAU/B,MAAM,IAAS,QAAS;AACtB,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMA,uCAAqC,OAAO;;AAEpD,gBAAM,QAAQ,KAAK,0BAA0B;AAC7C,cAAI,UAAU,YAAY;AAGxB;;AAGF,+CAAqC,MAAM,CAAC;;;QAI9C,CAAC,UAAU,EAAE,QAAW;AACtB,gBAAM,SAAS,KAAK,gBAAgB,MAAM;AAC1C,yDAA+C,IAAI;AACnD,iBAAO;;;QAIT,CAAC,UAAU,IAAC;AACV,qBAAW,IAAI;;MAElB;AAED,aAAO,iBAAiB,gCAAgC,WAAW;QACjE,aAAa,EAAE,YAAY,KAAI;QAC/B,QAAQ,EAAE,YAAY,KAAI;QAC1B,OAAO,EAAE,YAAY,KAAI;MAC1B,CAAA;AACD,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,gCAAgC,WAAW,OAAO,aAAa;UACnF,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,kCAAkC,GAAM;AAC/C,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,2BAA2B,GAAG;AACzE,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,qCAAwC,QACA,YACA,gBACA,gBACA,gBACA,gBACA,eACA,eAA6C;AAI5F,mBAAW,4BAA4B;AACvC,eAAO,4BAA4B;AAGnC,mBAAW,SAAS;AACpB,mBAAW,kBAAkB;AAC7B,mBAAW,UAAU;AAErB,mBAAW,eAAe;AAC1B,mBAAW,mBAAmB,sBAAqB;AACnD,mBAAW,WAAW;AAEtB,mBAAW,yBAAyB;AACpC,mBAAW,eAAe;AAE1B,mBAAW,kBAAkB;AAC7B,mBAAW,kBAAkB;AAC7B,mBAAW,kBAAkB;AAE7B,cAAM,eAAe,+CAA+C,UAAU;AAC9E,yCAAiC,QAAQ,YAAY;AAErD,cAAM,cAAc,eAAc;AAClC,cAAM,eAAe,oBAAoB,WAAW;AACpD,oBACE,cACA,MAAK;AAEH,qBAAW,WAAW;AACtB,8DAAoD,UAAU;AAC9D,iBAAO;WAET,OAAI;AAEF,qBAAW,WAAW;AACtB,0CAAgC,QAAQ,CAAC;AACzC,iBAAO;QACT,CAAC;MAEL;AAEA,eAAS,uDAA0D,QACA,gBACA,eACA,eAA6C;AAC9G,cAAM,aAAa,OAAO,OAAO,gCAAgC,SAAS;AAE1E,YAAI;AACJ,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI,eAAe,UAAU,QAAW;AACtC,2BAAiB,MAAM,eAAe,MAAO,UAAU;eAClD;AACL,2BAAiB,MAAM;;AAEzB,YAAI,eAAe,UAAU,QAAW;AACtC,2BAAiB,WAAS,eAAe,MAAO,OAAO,UAAU;eAC5D;AACL,2BAAiB,MAAM,oBAAoB,MAAS;;AAEtD,YAAI,eAAe,UAAU,QAAW;AACtC,2BAAiB,MAAM,eAAe,MAAM;eACvC;AACL,2BAAiB,MAAM,oBAAoB,MAAS;;AAEtD,YAAI,eAAe,UAAU,QAAW;AACtC,2BAAiB,YAAU,eAAe,MAAO,MAAM;eAClD;AACL,2BAAiB,MAAM,oBAAoB,MAAS;;AAGtD,6CACE,QAAQ,YAAY,gBAAgB,gBAAgB,gBAAgB,gBAAgB,eAAe,aAAa;MAEpH;AAGA,eAAS,+CAA+C,YAAgD;AACtG,mBAAW,kBAAkB;AAC7B,mBAAW,kBAAkB;AAC7B,mBAAW,kBAAkB;AAC7B,mBAAW,yBAAyB;MACtC;AAEA,eAAS,qCAAwC,YAA8C;AAC7F,6BAAqB,YAAY,eAAe,CAAC;AACjD,4DAAoD,UAAU;MAChE;AAEA,eAAS,4CAA+C,YACA,OAAQ;AAC9D,YAAI;AACF,iBAAO,WAAW,uBAAuB,KAAK;iBACvC,YAAY;AACnB,uDAA6C,YAAY,UAAU;AACnE,iBAAO;;MAEX;AAEA,eAAS,8CAA8C,YAAgD;AACrG,eAAO,WAAW,eAAe,WAAW;MAC9C;AAEA,eAAS,qCAAwC,YACA,OACA,WAAiB;AAChE,YAAI;AACF,+BAAqB,YAAY,OAAO,SAAS;iBAC1C,UAAU;AACjB,uDAA6C,YAAY,QAAQ;AACjE;;AAGF,cAAM,SAAS,WAAW;AAC1B,YAAI,CAAC,oCAAoC,MAAM,KAAK,OAAO,WAAW,YAAY;AAChF,gBAAM,eAAe,+CAA+C,UAAU;AAC9E,2CAAiC,QAAQ,YAAY;;AAGvD,4DAAoD,UAAU;MAChE;AAIA,eAAS,oDAAuD,YAA8C;AAC5G,cAAM,SAAS,WAAW;AAE1B,YAAI,CAAC,WAAW,UAAU;AACxB;;AAGF,YAAI,OAAO,0BAA0B,QAAW;AAC9C;;AAGF,cAAM,QAAQ,OAAO;AAErB,YAAI,UAAU,YAAY;AACxB,uCAA6B,MAAM;AACnC;;AAGF,YAAI,WAAW,OAAO,WAAW,GAAG;AAClC;;AAGF,cAAM,QAAQ,eAAe,UAAU;AACvC,YAAI,UAAU,eAAe;AAC3B,sDAA4C,UAAU;eACjD;AACL,sDAA4C,YAAY,KAAK;;MAEjE;AAEA,eAAS,6CAA6C,YAAkD,OAAU;AAChH,YAAI,WAAW,0BAA0B,WAAW,YAAY;AAC9D,+CAAqC,YAAY,KAAK;;MAE1D;AAEA,eAAS,4CAA4C,YAAgD;AACnG,cAAM,SAAS,WAAW;AAE1B,+CAAuC,MAAM;AAE7C,qBAAa,UAAU;AAGvB,cAAM,mBAAmB,WAAW,gBAAe;AACnD,uDAA+C,UAAU;AACzD,oBACE,kBACA,MAAK;AACH,4CAAkC,MAAM;AACxC,iBAAO;WAET,YAAS;AACP,qDAA2C,QAAQ,MAAM;AACzD,iBAAO;QACT,CAAC;MAEL;AAEA,eAAS,4CAA+C,YAAgD,OAAQ;AAC9G,cAAM,SAAS,WAAW;AAE1B,oDAA4C,MAAM;AAElD,cAAM,mBAAmB,WAAW,gBAAgB,KAAK;AACzD,oBACE,kBACA,MAAK;AACH,4CAAkC,MAAM;AAExC,gBAAM,QAAQ,OAAO;AAGrB,uBAAa,UAAU;AAEvB,cAAI,CAAC,oCAAoC,MAAM,KAAK,UAAU,YAAY;AACxE,kBAAM,eAAe,+CAA+C,UAAU;AAC9E,6CAAiC,QAAQ,YAAY;;AAGvD,8DAAoD,UAAU;AAC9D,iBAAO;WAET,YAAS;AACP,cAAI,OAAO,WAAW,YAAY;AAChC,2DAA+C,UAAU;;AAE3D,qDAA2C,QAAQ,MAAM;AACzD,iBAAO;QACT,CAAC;MAEL;AAEA,eAAS,+CAA+C,YAAgD;AACtG,cAAM,cAAc,8CAA8C,UAAU;AAC5E,eAAO,eAAe;MACxB;AAIA,eAAS,qCAAqC,YAAkD,OAAU;AACxG,cAAM,SAAS,WAAW;AAI1B,uDAA+C,UAAU;AACzD,oCAA4B,QAAQ,KAAK;MAC3C;AAIA,eAASD,4BAA0B,MAAY;AAC7C,eAAO,IAAI,UAAU,4BAA4B,IAAI,uCAAuC;MAC9F;AAIA,eAASC,uCAAqC,MAAY;AACxD,eAAO,IAAI,UACT,6CAA6C,IAAI,wDAAwD;MAC7G;AAKA,eAAS,iCAAiC,MAAY;AACpD,eAAO,IAAI,UACT,yCAAyC,IAAI,oDAAoD;MACrG;AAEA,eAAS,2BAA2B,MAAY;AAC9C,eAAO,IAAI,UAAU,YAAY,OAAO,mCAAmC;MAC7E;AAEA,eAAS,qCAAqC,QAAmC;AAC/E,eAAO,iBAAiB,WAAW,CAAC,SAAS,WAAU;AACrD,iBAAO,yBAAyB;AAChC,iBAAO,wBAAwB;AAC/B,iBAAO,sBAAsB;QAC/B,CAAC;MACH;AAEA,eAAS,+CAA+C,QAAqC,QAAW;AACtG,6CAAqC,MAAM;AAC3C,yCAAiC,QAAQ,MAAM;MACjD;AAEA,eAAS,+CAA+C,QAAmC;AACzF,6CAAqC,MAAM;AAC3C,0CAAkC,MAAM;MAC1C;AAEA,eAAS,iCAAiC,QAAqC,QAAW;AACxF,YAAI,OAAO,0BAA0B,QAAW;AAC9C;;AAIF,kCAA0B,OAAO,cAAc;AAC/C,eAAO,sBAAsB,MAAM;AACnC,eAAO,yBAAyB;AAChC,eAAO,wBAAwB;AAC/B,eAAO,sBAAsB;MAC/B;AAEA,eAAS,0CAA0C,QAAqC,QAAW;AAKjG,uDAA+C,QAAQ,MAAM;MAC/D;AAEA,eAAS,kCAAkC,QAAmC;AAC5E,YAAI,OAAO,2BAA2B,QAAW;AAC/C;;AAIF,eAAO,uBAAuB,MAAS;AACvC,eAAO,yBAAyB;AAChC,eAAO,wBAAwB;AAC/B,eAAO,sBAAsB;MAC/B;AAEA,eAAS,oCAAoC,QAAmC;AAC9E,eAAO,gBAAgB,WAAW,CAAC,SAAS,WAAU;AACpD,iBAAO,wBAAwB;AAC/B,iBAAO,uBAAuB;QAChC,CAAC;AACD,eAAO,qBAAqB;MAC9B;AAEA,eAAS,8CAA8C,QAAqC,QAAW;AACrG,4CAAoC,MAAM;AAC1C,wCAAgC,QAAQ,MAAM;MAChD;AAEA,eAAS,8CAA8C,QAAmC;AACxF,4CAAoC,MAAM;AAC1C,yCAAiC,MAAM;MACzC;AAEA,eAAS,gCAAgC,QAAqC,QAAW;AACvF,YAAI,OAAO,yBAAyB,QAAW;AAC7C;;AAGF,kCAA0B,OAAO,aAAa;AAC9C,eAAO,qBAAqB,MAAM;AAClC,eAAO,wBAAwB;AAC/B,eAAO,uBAAuB;AAC9B,eAAO,qBAAqB;MAC9B;AAEA,eAAS,+BAA+B,QAAmC;AAIzE,4CAAoC,MAAM;MAC5C;AAEA,eAAS,yCAAyC,QAAqC,QAAW;AAIhG,sDAA8C,QAAQ,MAAM;MAC9D;AAEA,eAAS,iCAAiC,QAAmC;AAC3E,YAAI,OAAO,0BAA0B,QAAW;AAC9C;;AAGF,eAAO,sBAAsB,MAAS;AACtC,eAAO,wBAAwB;AAC/B,eAAO,uBAAuB;AAC9B,eAAO,qBAAqB;MAC9B;ACz5CA,eAAS,aAAU;AACjB,YAAI,OAAO,eAAe,aAAa;AACrC,iBAAO;mBACE,OAAO,SAAS,aAAa;AACtC,iBAAO;mBACE,OAAO,WAAW,aAAa;AACxC,iBAAO;;AAET,eAAO;MACT;AAEO,YAAM,UAAU,WAAU;ACFjC,eAAS,0BAA0B,MAAa;AAC9C,YAAI,EAAE,OAAO,SAAS,cAAc,OAAO,SAAS,WAAW;AAC7D,iBAAO;;AAET,YAAK,KAAiC,SAAS,gBAAgB;AAC7D,iBAAO;;AAET,YAAI;AACF,cAAK,KAAgC;AACrC,iBAAO;iBACPH,KAAM;AACN,iBAAO;;MAEX;AAOA,eAAS,gBAAa;AACpB,cAAM,OAAO,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AACtB,eAAO,0BAA0B,IAAI,IAAI,OAAO;MAClD;AAMA,eAAS,iBAAc;AAErB,cAAM,OAAO,SAASI,cAAiC,SAAkB,MAAa;AACpF,eAAK,UAAU,WAAW;AAC1B,eAAK,OAAO,QAAQ;AACpB,cAAI,MAAM,mBAAmB;AAC3B,kBAAM,kBAAkB,MAAM,KAAK,WAAW;;QAElD;AACA,wBAAgB,MAAM,cAAc;AACpC,aAAK,YAAY,OAAO,OAAO,MAAM,SAAS;AAC9C,eAAO,eAAe,KAAK,WAAW,eAAe,EAAE,OAAO,MAAM,UAAU,MAAM,cAAc,KAAI,CAAE;AACxG,eAAO;MACT;AAGA,YAAM,eAAwC,cAAa,KAAM,eAAc;AC5B/D,eAAA,qBAAwB,QACA,MACA,cACA,cACA,eACA,QAA+B;AAUrE,cAAM,SAAS,mCAAsC,MAAM;AAC3D,cAAM,SAAS,mCAAsC,IAAI;AAEzD,eAAO,aAAa;AAEpB,YAAI,eAAe;AAGnB,YAAI,eAAe,oBAA0B,MAAS;AAEtD,eAAO,WAAW,CAAC,SAAS,WAAU;AACpC,cAAI;AACJ,cAAI,WAAW,QAAW;AACxB,6BAAiB,MAAK;AACpB,oBAAM,QAAQ,OAAO,WAAW,SAAY,OAAO,SAAS,IAAI,aAAa,WAAW,YAAY;AACpG,oBAAM,UAAsC,CAAA;AAC5C,kBAAI,CAAC,cAAc;AACjB,wBAAQ,KAAK,MAAK;AAChB,sBAAI,KAAK,WAAW,YAAY;AAC9B,2BAAO,oBAAoB,MAAM,KAAK;;AAExC,yBAAO,oBAAoB,MAAS;gBACtC,CAAC;;AAEH,kBAAI,CAAC,eAAe;AAClB,wBAAQ,KAAK,MAAK;AAChB,sBAAI,OAAO,WAAW,YAAY;AAChC,2BAAO,qBAAqB,QAAQ,KAAK;;AAE3C,yBAAO,oBAAoB,MAAS;gBACtC,CAAC;;AAEH,iCAAmB,MAAM,QAAQ,IAAI,QAAQ,IAAI,YAAU,OAAM,CAAE,CAAC,GAAG,MAAM,KAAK;YACpF;AAEA,gBAAI,OAAO,SAAS;AAClB,6BAAc;AACd;;AAGF,mBAAO,iBAAiB,SAAS,cAAc;;AAMjD,mBAAS,WAAQ;AACf,mBAAO,WAAiB,CAAC,aAAa,eAAc;AAClD,uBAAS,KAAK,MAAa;AACzB,oBAAI,MAAM;AACR,8BAAW;uBACN;AAGL,qCAAmB,SAAQ,GAAI,MAAM,UAAU;;;AAInD,mBAAK,KAAK;YACZ,CAAC;;AAGH,mBAAS,WAAQ;AACf,gBAAI,cAAc;AAChB,qBAAO,oBAAoB,IAAI;;AAGjC,mBAAO,mBAAmB,OAAO,eAAe,MAAK;AACnD,qBAAO,WAAoB,CAAC,aAAa,eAAc;AACrD,gDACE,QACA;kBACE,aAAa,WAAQ;AACnB,mCAAe,mBAAmB,iCAAiC,QAAQ,KAAK,GAAG,QAAW,IAAI;AAClG,gCAAY,KAAK;;kBAEnB,aAAa,MAAM,YAAY,IAAI;kBACnC,aAAa;gBACd,CAAA;cAEL,CAAC;YACH,CAAC;;AAIH,6BAAmB,QAAQ,OAAO,gBAAgB,iBAAc;AAC9D,gBAAI,CAAC,cAAc;AACjB,iCAAmB,MAAM,oBAAoB,MAAM,WAAW,GAAG,MAAM,WAAW;mBAC7E;AACL,uBAAS,MAAM,WAAW;;AAE5B,mBAAO;UACT,CAAC;AAGD,6BAAmB,MAAM,OAAO,gBAAgB,iBAAc;AAC5D,gBAAI,CAAC,eAAe;AAClB,iCAAmB,MAAM,qBAAqB,QAAQ,WAAW,GAAG,MAAM,WAAW;mBAChF;AACL,uBAAS,MAAM,WAAW;;AAE5B,mBAAO;UACT,CAAC;AAGD,4BAAkB,QAAQ,OAAO,gBAAgB,MAAK;AACpD,gBAAI,CAAC,cAAc;AACjB,iCAAmB,MAAM,qDAAqD,MAAM,CAAC;mBAChF;AACL,uBAAQ;;AAEV,mBAAO;UACT,CAAC;AAGD,cAAI,oCAAoC,IAAI,KAAK,KAAK,WAAW,UAAU;AACzE,kBAAM,aAAa,IAAI,UAAU,6EAA6E;AAE9G,gBAAI,CAAC,eAAe;AAClB,iCAAmB,MAAM,qBAAqB,QAAQ,UAAU,GAAG,MAAM,UAAU;mBAC9E;AACL,uBAAS,MAAM,UAAU;;;AAI7B,oCAA0B,SAAQ,CAAE;AAEpC,mBAAS,wBAAqB;AAG5B,kBAAM,kBAAkB;AACxB,mBAAO,mBACL,cACA,MAAM,oBAAoB,eAAe,sBAAqB,IAAK,MAAS;;AAIhF,mBAAS,mBAAmB,QACA,SACA,QAA6B;AACvD,gBAAI,OAAO,WAAW,WAAW;AAC/B,qBAAO,OAAO,YAAY;mBACrB;AACL,4BAAc,SAAS,MAAM;;;AAIjC,mBAAS,kBAAkB,QAAyC,SAAwB,QAAkB;AAC5G,gBAAI,OAAO,WAAW,UAAU;AAC9B,qBAAM;mBACD;AACL,8BAAgB,SAAS,MAAM;;;AAInC,mBAAS,mBAAmB,QAAgC,iBAA2B,eAAmB;AACxG,gBAAI,cAAc;AAChB;;AAEF,2BAAe;AAEf,gBAAI,KAAK,WAAW,cAAc,CAAC,oCAAoC,IAAI,GAAG;AAC5E,8BAAgB,sBAAqB,GAAI,SAAS;mBAC7C;AACL,wBAAS;;AAGX,qBAAS,YAAS;AAChB,0BACE,OAAM,GACN,MAAM,SAAS,iBAAiB,aAAa,GAC7C,cAAY,SAAS,MAAM,QAAQ,CAAC;AAEtC,qBAAO;;;AAIX,mBAAS,SAAS,SAAmB,OAAW;AAC9C,gBAAI,cAAc;AAChB;;AAEF,2BAAe;AAEf,gBAAI,KAAK,WAAW,cAAc,CAAC,oCAAoC,IAAI,GAAG;AAC5E,8BAAgB,sBAAqB,GAAI,MAAM,SAAS,SAAS,KAAK,CAAC;mBAClE;AACL,uBAAS,SAAS,KAAK;;;AAI3B,mBAAS,SAAS,SAAmB,OAAW;AAC9C,+CAAmC,MAAM;AACzC,+CAAmC,MAAM;AAEzC,gBAAI,WAAW,QAAW;AACxB,qBAAO,oBAAoB,SAAS,cAAc;;AAEpD,gBAAI,SAAS;AACX,qBAAO,KAAK;mBACP;AACL,sBAAQ,MAAS;;AAGnB,mBAAO;;QAEX,CAAC;MACH;YCpOa,gCAA+B;QAwB1C,cAAA;AACE,gBAAM,IAAI,UAAU,qBAAqB;;;;;;QAO3C,IAAI,cAAW;AACb,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMD,uCAAqC,aAAa;;AAG1D,iBAAO,8CAA8C,IAAI;;;;;;QAO3D,QAAK;AACH,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMA,uCAAqC,OAAO;;AAGpD,cAAI,CAAC,iDAAiD,IAAI,GAAG;AAC3D,kBAAM,IAAI,UAAU,iDAAiD;;AAGvE,+CAAqC,IAAI;;QAO3C,QAAQ,QAAW,QAAU;AAC3B,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMA,uCAAqC,SAAS;;AAGtD,cAAI,CAAC,iDAAiD,IAAI,GAAG;AAC3D,kBAAM,IAAI,UAAU,mDAAmD;;AAGzE,iBAAO,uCAAuC,MAAM,KAAK;;;;;QAM3D,MAAM,IAAS,QAAS;AACtB,cAAI,CAAC,kCAAkC,IAAI,GAAG;AAC5C,kBAAMA,uCAAqC,OAAO;;AAGpD,+CAAqC,MAAM,CAAC;;;QAI9C,CAAC,WAAW,EAAE,QAAW;AACvB,qBAAW,IAAI;AACf,gBAAM,SAAS,KAAK,iBAAiB,MAAM;AAC3C,yDAA+C,IAAI;AACnD,iBAAO;;;QAIT,CAAC,SAAS,EAAE,aAA2B;AACrC,gBAAM,SAAS,KAAK;AAEpB,cAAI,KAAK,OAAO,SAAS,GAAG;AAC1B,kBAAM,QAAQ,aAAa,IAAI;AAE/B,gBAAI,KAAK,mBAAmB,KAAK,OAAO,WAAW,GAAG;AACpD,6DAA+C,IAAI;AACnD,kCAAoB,MAAM;mBACrB;AACL,8DAAgD,IAAI;;AAGtD,wBAAY,YAAY,KAAK;iBACxB;AACL,yCAA6B,QAAQ,WAAW;AAChD,4DAAgD,IAAI;;;;QAKxD,CAAC,YAAY,IAAC;;MAGf;AAED,aAAO,iBAAiB,gCAAgC,WAAW;QACjE,OAAO,EAAE,YAAY,KAAI;QACzB,SAAS,EAAE,YAAY,KAAI;QAC3B,OAAO,EAAE,YAAY,KAAI;QACzB,aAAa,EAAE,YAAY,KAAI;MAChC,CAAA;AACD,sBAAgB,gCAAgC,UAAU,OAAO,OAAO;AACxE,sBAAgB,gCAAgC,UAAU,SAAS,SAAS;AAC5E,sBAAgB,gCAAgC,UAAU,OAAO,OAAO;AACxE,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,gCAAgC,WAAW,OAAO,aAAa;UACnF,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,kCAA2C,GAAM;AACxD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,2BAA2B,GAAG;AACzE,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,gDAAgD,YAAgD;AACvG,cAAM,aAAa,8CAA8C,UAAU;AAC3E,YAAI,CAAC,YAAY;AACf;;AAGF,YAAI,WAAW,UAAU;AACvB,qBAAW,aAAa;AACxB;;AAKF,mBAAW,WAAW;AAEtB,cAAM,cAAc,WAAW,eAAc;AAC7C,oBACE,aACA,MAAK;AACH,qBAAW,WAAW;AAEtB,cAAI,WAAW,YAAY;AACzB,uBAAW,aAAa;AACxB,4DAAgD,UAAU;;AAG5D,iBAAO;WAET,OAAI;AACF,+CAAqC,YAAY,CAAC;AAClD,iBAAO;QACT,CAAC;MAEL;AAEA,eAAS,8CAA8C,YAAgD;AACrG,cAAM,SAAS,WAAW;AAE1B,YAAI,CAAC,iDAAiD,UAAU,GAAG;AACjE,iBAAO;;AAGT,YAAI,CAAC,WAAW,UAAU;AACxB,iBAAO;;AAGT,YAAI,uBAAuB,MAAM,KAAK,iCAAiC,MAAM,IAAI,GAAG;AAClF,iBAAO;;AAGT,cAAM,cAAc,8CAA8C,UAAU;AAE5E,YAAI,cAAe,GAAG;AACpB,iBAAO;;AAGT,eAAO;MACT;AAEA,eAAS,+CAA+C,YAAgD;AACtG,mBAAW,iBAAiB;AAC5B,mBAAW,mBAAmB;AAC9B,mBAAW,yBAAyB;MACtC;AAIM,eAAU,qCAAqC,YAAgD;AACnG,YAAI,CAAC,iDAAiD,UAAU,GAAG;AACjE;;AAGF,cAAM,SAAS,WAAW;AAE1B,mBAAW,kBAAkB;AAE7B,YAAI,WAAW,OAAO,WAAW,GAAG;AAClC,yDAA+C,UAAU;AACzD,8BAAoB,MAAM;;MAE9B;AAEgB,eAAA,uCACd,YACA,OAAQ;AAER,YAAI,CAAC,iDAAiD,UAAU,GAAG;AACjE;;AAGF,cAAM,SAAS,WAAW;AAE1B,YAAI,uBAAuB,MAAM,KAAK,iCAAiC,MAAM,IAAI,GAAG;AAClF,2CAAiC,QAAQ,OAAO,KAAK;eAChD;AACL,cAAI;AACJ,cAAI;AACF,wBAAY,WAAW,uBAAuB,KAAK;mBAC5C,YAAY;AACnB,iDAAqC,YAAY,UAAU;AAC3D,kBAAM;;AAGR,cAAI;AACF,iCAAqB,YAAY,OAAO,SAAS;mBAC1C,UAAU;AACjB,iDAAqC,YAAY,QAAQ;AACzD,kBAAM;;;AAIV,wDAAgD,UAAU;MAC5D;AAEgB,eAAA,qCAAqC,YAAkD,GAAM;AAC3G,cAAM,SAAS,WAAW;AAE1B,YAAI,OAAO,WAAW,YAAY;AAChC;;AAGF,mBAAW,UAAU;AAErB,uDAA+C,UAAU;AACzD,4BAAoB,QAAQ,CAAC;MAC/B;AAEM,eAAU,8CACd,YAAgD;AAEhD,cAAM,QAAQ,WAAW,0BAA0B;AAEnD,YAAI,UAAU,WAAW;AACvB,iBAAO;;AAET,YAAI,UAAU,UAAU;AACtB,iBAAO;;AAGT,eAAO,WAAW,eAAe,WAAW;MAC9C;AAGM,eAAU,+CACd,YAAgD;AAEhD,YAAI,8CAA8C,UAAU,GAAG;AAC7D,iBAAO;;AAGT,eAAO;MACT;AAEM,eAAU,iDACd,YAAgD;AAEhD,cAAM,QAAQ,WAAW,0BAA0B;AAEnD,YAAI,CAAC,WAAW,mBAAmB,UAAU,YAAY;AACvD,iBAAO;;AAGT,eAAO;MACT;AAEgB,eAAA,qCAAwC,QACA,YACA,gBACA,eACA,iBACA,eACA,eAA6C;AAGnG,mBAAW,4BAA4B;AAEvC,mBAAW,SAAS;AACpB,mBAAW,kBAAkB;AAC7B,mBAAW,UAAU;AAErB,mBAAW,WAAW;AACtB,mBAAW,kBAAkB;AAC7B,mBAAW,aAAa;AACxB,mBAAW,WAAW;AAEtB,mBAAW,yBAAyB;AACpC,mBAAW,eAAe;AAE1B,mBAAW,iBAAiB;AAC5B,mBAAW,mBAAmB;AAE9B,eAAO,4BAA4B;AAEnC,cAAM,cAAc,eAAc;AAClC,oBACE,oBAAoB,WAAW,GAC/B,MAAK;AACH,qBAAW,WAAW;AAKtB,0DAAgD,UAAU;AAC1D,iBAAO;WAET,OAAI;AACF,+CAAqC,YAAY,CAAC;AAClD,iBAAO;QACT,CAAC;MAEL;AAEM,eAAU,yDACd,QACA,kBACA,eACA,eAA6C;AAE7C,cAAM,aAAiD,OAAO,OAAO,gCAAgC,SAAS;AAE9G,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI,iBAAiB,UAAU,QAAW;AACxC,2BAAiB,MAAM,iBAAiB,MAAO,UAAU;eACpD;AACL,2BAAiB,MAAM;;AAEzB,YAAI,iBAAiB,SAAS,QAAW;AACvC,0BAAgB,MAAM,iBAAiB,KAAM,UAAU;eAClD;AACL,0BAAgB,MAAM,oBAAoB,MAAS;;AAErD,YAAI,iBAAiB,WAAW,QAAW;AACzC,4BAAkB,YAAU,iBAAiB,OAAQ,MAAM;eACtD;AACL,4BAAkB,MAAM,oBAAoB,MAAS;;AAGvD,6CACE,QAAQ,YAAY,gBAAgB,eAAe,iBAAiB,eAAe,aAAa;MAEpG;AAIA,eAASA,uCAAqC,MAAY;AACxD,eAAO,IAAI,UACT,6CAA6C,IAAI,wDAAwD;MAC7G;ACxXgB,eAAA,kBAAqB,QACA,iBAAwB;AAG3D,YAAI,+BAA+B,OAAO,yBAAyB,GAAG;AACpE,iBAAO,sBAAsB,MAAuC;;AAGtE,eAAO,yBAAyB,MAAuB;MACzD;AAEgB,eAAA,yBACd,QACA,iBAAwB;AAKxB,cAAM,SAAS,mCAAsC,MAAM;AAE3D,YAAI,UAAU;AACd,YAAI,YAAY;AAChB,YAAI,YAAY;AAChB,YAAI,YAAY;AAChB,YAAI;AACJ,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI;AACJ,cAAM,gBAAgB,WAAsB,aAAU;AACpD,iCAAuB;QACzB,CAAC;AAED,iBAAS,gBAAa;AACpB,cAAI,SAAS;AACX,wBAAY;AACZ,mBAAO,oBAAoB,MAAS;;AAGtC,oBAAU;AAEV,gBAAM,cAA8B;YAClC,aAAa,WAAQ;AAInBF,8BAAe,MAAK;AAClB,4BAAY;AACZ,sBAAM,SAAS;AACf,sBAAM,SAAS;AAQf,oBAAI,CAAC,WAAW;AACd,yDAAuC,QAAQ,2BAA2B,MAAM;;AAElF,oBAAI,CAAC,WAAW;AACd,yDAAuC,QAAQ,2BAA2B,MAAM;;AAGlF,0BAAU;AACV,oBAAI,WAAW;AACb,gCAAa;;cAEjB,CAAC;;YAEH,aAAa,MAAK;AAChB,wBAAU;AACV,kBAAI,CAAC,WAAW;AACd,qDAAqC,QAAQ,yBAAyB;;AAExE,kBAAI,CAAC,WAAW;AACd,qDAAqC,QAAQ,yBAAyB;;AAGxE,kBAAI,CAAC,aAAa,CAAC,WAAW;AAC5B,qCAAqB,MAAS;;;YAGlC,aAAa,MAAK;AAChB,wBAAU;;;AAGd,0CAAgC,QAAQ,WAAW;AAEnD,iBAAO,oBAAoB,MAAS;;AAGtC,iBAAS,iBAAiB,QAAW;AACnC,sBAAY;AACZ,oBAAU;AACV,cAAI,WAAW;AACb,kBAAM,kBAAkB,oBAAoB,CAAC,SAAS,OAAO,CAAC;AAC9D,kBAAM,eAAe,qBAAqB,QAAQ,eAAe;AACjE,iCAAqB,YAAY;;AAEnC,iBAAO;;AAGT,iBAAS,iBAAiB,QAAW;AACnC,sBAAY;AACZ,oBAAU;AACV,cAAI,WAAW;AACb,kBAAM,kBAAkB,oBAAoB,CAAC,SAAS,OAAO,CAAC;AAC9D,kBAAM,eAAe,qBAAqB,QAAQ,eAAe;AACjE,iCAAqB,YAAY;;AAEnC,iBAAO;;AAGT,iBAAS,iBAAc;;AAIvB,kBAAU,qBAAqB,gBAAgB,eAAe,gBAAgB;AAC9E,kBAAU,qBAAqB,gBAAgB,eAAe,gBAAgB;AAE9E,sBAAc,OAAO,gBAAgB,CAAC,MAAU;AAC9C,+CAAqC,QAAQ,2BAA2B,CAAC;AACzE,+CAAqC,QAAQ,2BAA2B,CAAC;AACzE,cAAI,CAAC,aAAa,CAAC,WAAW;AAC5B,iCAAqB,MAAS;;AAEhC,iBAAO;QACT,CAAC;AAED,eAAO,CAAC,SAAS,OAAO;MAC1B;AAEM,eAAU,sBAAsB,QAA0B;AAI9D,YAAI,SAAsD,mCAAmC,MAAM;AACnG,YAAI,UAAU;AACd,YAAI,sBAAsB;AAC1B,YAAI,sBAAsB;AAC1B,YAAI,YAAY;AAChB,YAAI,YAAY;AAChB,YAAI;AACJ,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI;AACJ,cAAM,gBAAgB,WAAiB,aAAU;AAC/C,iCAAuB;QACzB,CAAC;AAED,iBAAS,mBAAmB,YAAuD;AACjF,wBAAc,WAAW,gBAAgB,OAAI;AAC3C,gBAAI,eAAe,QAAQ;AACzB,qBAAO;;AAET,8CAAkC,QAAQ,2BAA2B,CAAC;AACtE,8CAAkC,QAAQ,2BAA2B,CAAC;AACtE,gBAAI,CAAC,aAAa,CAAC,WAAW;AAC5B,mCAAqB,MAAS;;AAEhC,mBAAO;UACT,CAAC;;AAGH,iBAAS,wBAAqB;AAC5B,cAAI,2BAA2B,MAAM,GAAG;AAEtC,+CAAmC,MAAM;AAEzC,qBAAS,mCAAmC,MAAM;AAClD,+BAAmB,MAAM;;AAG3B,gBAAM,cAAkD;YACtD,aAAa,WAAQ;AAInBA,8BAAe,MAAK;AAClB,sCAAsB;AACtB,sCAAsB;AAEtB,sBAAM,SAAS;AACf,oBAAI,SAAS;AACb,oBAAI,CAAC,aAAa,CAAC,WAAW;AAC5B,sBAAI;AACF,6BAAS,kBAAkB,KAAK;2BACzB,QAAQ;AACf,sDAAkC,QAAQ,2BAA2B,MAAM;AAC3E,sDAAkC,QAAQ,2BAA2B,MAAM;AAC3E,yCAAqB,qBAAqB,QAAQ,MAAM,CAAC;AACzD;;;AAIJ,oBAAI,CAAC,WAAW;AACd,sDAAoC,QAAQ,2BAA2B,MAAM;;AAE/E,oBAAI,CAAC,WAAW;AACd,sDAAoC,QAAQ,2BAA2B,MAAM;;AAG/E,0BAAU;AACV,oBAAI,qBAAqB;AACvB,iCAAc;2BACL,qBAAqB;AAC9B,iCAAc;;cAElB,CAAC;;YAEH,aAAa,MAAK;AAChB,wBAAU;AACV,kBAAI,CAAC,WAAW;AACd,kDAAkC,QAAQ,yBAAyB;;AAErE,kBAAI,CAAC,WAAW;AACd,kDAAkC,QAAQ,yBAAyB;;AAErE,kBAAI,QAAQ,0BAA0B,kBAAkB,SAAS,GAAG;AAClE,oDAAoC,QAAQ,2BAA2B,CAAC;;AAE1E,kBAAI,QAAQ,0BAA0B,kBAAkB,SAAS,GAAG;AAClE,oDAAoC,QAAQ,2BAA2B,CAAC;;AAE1E,kBAAI,CAAC,aAAa,CAAC,WAAW;AAC5B,qCAAqB,MAAS;;;YAGlC,aAAa,MAAK;AAChB,wBAAU;;;AAGd,0CAAgC,QAAQ,WAAW;;AAGrD,iBAAS,mBAAmB,MAAkC,YAAmB;AAC/E,cAAI,8BAAqD,MAAM,GAAG;AAEhE,+CAAmC,MAAM;AAEzC,qBAAS,gCAAgC,MAAM;AAC/C,+BAAmB,MAAM;;AAG3B,gBAAM,aAAa,aAAa,UAAU;AAC1C,gBAAM,cAAc,aAAa,UAAU;AAE3C,gBAAM,kBAA+D;YACnE,aAAa,WAAQ;AAInBA,8BAAe,MAAK;AAClB,sCAAsB;AACtB,sCAAsB;AAEtB,sBAAM,eAAe,aAAa,YAAY;AAC9C,sBAAM,gBAAgB,aAAa,YAAY;AAE/C,oBAAI,CAAC,eAAe;AAClB,sBAAI;AACJ,sBAAI;AACF,kCAAc,kBAAkB,KAAK;2BAC9B,QAAQ;AACf,sDAAkC,WAAW,2BAA2B,MAAM;AAC9E,sDAAkC,YAAY,2BAA2B,MAAM;AAC/E,yCAAqB,qBAAqB,QAAQ,MAAM,CAAC;AACzD;;AAEF,sBAAI,CAAC,cAAc;AACjB,mEAA+C,WAAW,2BAA2B,KAAK;;AAE5F,sDAAoC,YAAY,2BAA2B,WAAW;2BAC7E,CAAC,cAAc;AACxB,iEAA+C,WAAW,2BAA2B,KAAK;;AAG5F,0BAAU;AACV,oBAAI,qBAAqB;AACvB,iCAAc;2BACL,qBAAqB;AAC9B,iCAAc;;cAElB,CAAC;;YAEH,aAAa,WAAQ;AACnB,wBAAU;AAEV,oBAAM,eAAe,aAAa,YAAY;AAC9C,oBAAM,gBAAgB,aAAa,YAAY;AAE/C,kBAAI,CAAC,cAAc;AACjB,kDAAkC,WAAW,yBAAyB;;AAExE,kBAAI,CAAC,eAAe;AAClB,kDAAkC,YAAY,yBAAyB;;AAGzE,kBAAI,UAAU,QAAW;AAGvB,oBAAI,CAAC,cAAc;AACjB,iEAA+C,WAAW,2BAA2B,KAAK;;AAE5F,oBAAI,CAAC,iBAAiB,YAAY,0BAA0B,kBAAkB,SAAS,GAAG;AACxF,sDAAoC,YAAY,2BAA2B,CAAC;;;AAIhF,kBAAI,CAAC,gBAAgB,CAAC,eAAe;AACnC,qCAAqB,MAAS;;;YAGlC,aAAa,MAAK;AAChB,wBAAU;;;AAGd,uCAA6B,QAAQ,MAAM,GAAG,eAAe;;AAG/D,iBAAS,iBAAc;AACrB,cAAI,SAAS;AACX,kCAAsB;AACtB,mBAAO,oBAAoB,MAAS;;AAGtC,oBAAU;AAEV,gBAAM,cAAc,2CAA2C,QAAQ,yBAAyB;AAChG,cAAI,gBAAgB,MAAM;AACxB,kCAAqB;iBAChB;AACL,+BAAmB,YAAY,OAAQ,KAAK;;AAG9C,iBAAO,oBAAoB,MAAS;;AAGtC,iBAAS,iBAAc;AACrB,cAAI,SAAS;AACX,kCAAsB;AACtB,mBAAO,oBAAoB,MAAS;;AAGtC,oBAAU;AAEV,gBAAM,cAAc,2CAA2C,QAAQ,yBAAyB;AAChG,cAAI,gBAAgB,MAAM;AACxB,kCAAqB;iBAChB;AACL,+BAAmB,YAAY,OAAQ,IAAI;;AAG7C,iBAAO,oBAAoB,MAAS;;AAGtC,iBAAS,iBAAiB,QAAW;AACnC,sBAAY;AACZ,oBAAU;AACV,cAAI,WAAW;AACb,kBAAM,kBAAkB,oBAAoB,CAAC,SAAS,OAAO,CAAC;AAC9D,kBAAM,eAAe,qBAAqB,QAAQ,eAAe;AACjE,iCAAqB,YAAY;;AAEnC,iBAAO;;AAGT,iBAAS,iBAAiB,QAAW;AACnC,sBAAY;AACZ,oBAAU;AACV,cAAI,WAAW;AACb,kBAAM,kBAAkB,oBAAoB,CAAC,SAAS,OAAO,CAAC;AAC9D,kBAAM,eAAe,qBAAqB,QAAQ,eAAe;AACjE,iCAAqB,YAAY;;AAEnC,iBAAO;;AAGT,iBAAS,iBAAc;AACrB;;AAGF,kBAAU,yBAAyB,gBAAgB,gBAAgB,gBAAgB;AACnF,kBAAU,yBAAyB,gBAAgB,gBAAgB,gBAAgB;AAEnF,2BAAmB,MAAM;AAEzB,eAAO,CAAC,SAAS,OAAO;MAC1B;ACtZM,eAAU,qBAAwB,QAAe;AACrD,eAAO,aAAa,MAAM,KAAK,OAAQ,OAAiC,cAAc;MACxF;ACnBM,eAAU,mBACd,QAA8D;AAE9D,YAAI,qBAAqB,MAAM,GAAG;AAChC,iBAAO,gCAAgC,OAAO,UAAS,CAAE;;AAE3D,eAAO,2BAA2B,MAAM;MAC1C;AAEM,eAAU,2BAA8B,eAA6C;AACzF,YAAI;AACJ,cAAM,iBAAiB,YAAY,eAAe,OAAO;AAEzD,cAAM,iBAAiB;AAEvB,iBAAS,gBAAa;AACpB,cAAI;AACJ,cAAI;AACF,yBAAa,aAAa,cAAc;mBACjC,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAE9B,gBAAM,cAAc,oBAAoB,UAAU;AAClD,iBAAO,qBAAqB,aAAa,gBAAa;AACpD,gBAAI,CAAC,aAAa,UAAU,GAAG;AAC7B,oBAAM,IAAI,UAAU,gFAAgF;;AAEtG,kBAAM,OAAO,iBAAiB,UAAU;AACxC,gBAAI,MAAM;AACR,mDAAqC,OAAO,yBAAyB;mBAChE;AACL,oBAAM,QAAQ,cAAc,UAAU;AACtC,qDAAuC,OAAO,2BAA2B,KAAK;;UAElF,CAAC;;AAGH,iBAAS,gBAAgB,QAAW;AAClC,gBAAM,WAAW,eAAe;AAChC,cAAI;AACJ,cAAI;AACF,2BAAe,UAAU,UAAU,QAAQ;mBACpC,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAE9B,cAAI,iBAAiB,QAAW;AAC9B,mBAAO,oBAAoB,MAAS;;AAEtC,cAAI;AACJ,cAAI;AACF,2BAAe,YAAY,cAAc,UAAU,CAAC,MAAM,CAAC;mBACpD,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAE9B,gBAAM,gBAAgB,oBAAoB,YAAY;AACtD,iBAAO,qBAAqB,eAAe,gBAAa;AACtD,gBAAI,CAAC,aAAa,UAAU,GAAG;AAC7B,oBAAM,IAAI,UAAU,kFAAkF;;AAExG,mBAAO;UACT,CAAC;;AAGH,iBAAS,qBAAqB,gBAAgB,eAAe,iBAAiB,CAAC;AAC/E,eAAO;MACT;AAEM,eAAU,gCACd,QAA0C;AAE1C,YAAI;AAEJ,cAAM,iBAAiB;AAEvB,iBAAS,gBAAa;AACpB,cAAI;AACJ,cAAI;AACF,0BAAc,OAAO,KAAI;mBAClB,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAE9B,iBAAO,qBAAqB,aAAa,gBAAa;AACpD,gBAAI,CAAC,aAAa,UAAU,GAAG;AAC7B,oBAAM,IAAI,UAAU,8EAA8E;;AAEpG,gBAAI,WAAW,MAAM;AACnB,mDAAqC,OAAO,yBAAyB;mBAChE;AACL,oBAAM,QAAQ,WAAW;AACzB,qDAAuC,OAAO,2BAA2B,KAAK;;UAElF,CAAC;;AAGH,iBAAS,gBAAgB,QAAW;AAClC,cAAI;AACF,mBAAO,oBAAoB,OAAO,OAAO,MAAM,CAAC;mBACzC,GAAG;AACV,mBAAO,oBAAoB,CAAC;;;AAIhC,iBAAS,qBAAqB,gBAAgB,eAAe,iBAAiB,CAAC;AAC/E,eAAO;MACT;ACvGgB,eAAA,qCACd,QACA,SAAe;AAEf,yBAAiB,QAAQ,OAAO;AAChC,cAAM,WAAW;AACjB,cAAM,wBAAwB,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxC,cAAM,SAAS,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACzB,cAAM,OAAO,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACvB,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,OAAO,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACvB,eAAO;UACL,uBAAuB,0BAA0B,SAC/C,SACA,wCACE,uBACA,GAAG,OAAO,0CAA0C;UAExD,QAAQ,WAAW,SACjB,SACA,sCAAsC,QAAQ,UAAW,GAAG,OAAO,2BAA2B;UAChG,MAAM,SAAS,SACb,SACA,oCAAoC,MAAM,UAAW,GAAG,OAAO,yBAAyB;UAC1F,OAAO,UAAU,SACf,SACA,qCAAqC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UAC7F,MAAM,SAAS,SAAY,SAAY,0BAA0B,MAAM,GAAG,OAAO,yBAAyB;;MAE9G;AAEA,eAAS,sCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,WAAgB,YAAY,IAAI,UAAU,CAAC,MAAM,CAAC;MAC5D;AAEA,eAAS,oCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,eAA4C,YAAY,IAAI,UAAU,CAAC,UAAU,CAAC;MAC5F;AAEA,eAAS,qCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,eAA4C,YAAY,IAAI,UAAU,CAAC,UAAU,CAAC;MAC5F;AAEA,eAAS,0BAA0B,MAAc,SAAe;AAC9D,eAAO,GAAG,IAAI;AACd,YAAI,SAAS,SAAS;AACpB,gBAAM,IAAI,UAAU,GAAG,OAAO,KAAK,IAAI,2DAA2D;;AAEpG,eAAO;MACT;ACvEgB,eAAA,uBAAuB,SACA,SAAe;AACpD,yBAAiB,SAAS,OAAO;AACjC,cAAM,gBAAgB,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AAC/B,eAAO,EAAE,eAAe,QAAQ,aAAa,EAAC;MAChD;ACPgB,eAAA,mBAAmB,SACA,SAAe;AAChD,yBAAiB,SAAS,OAAO;AACjC,cAAM,eAAe,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AAC9B,cAAM,gBAAgB,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AAC/B,cAAM,eAAe,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AAC9B,cAAM,SAAS,YAAO,QAAP,YAAA,SAAA,SAAA,QAAS;AACxB,YAAI,WAAW,QAAW;AACxB,4BAAkB,QAAQ,GAAG,OAAO,2BAA2B;;AAEjE,eAAO;UACL,cAAc,QAAQ,YAAY;UAClC,eAAe,QAAQ,aAAa;UACpC,cAAc,QAAQ,YAAY;UAClC;;MAEJ;AAEA,eAAS,kBAAkB,QAAiB,SAAe;AACzD,YAAI,CAAC,cAAc,MAAM,GAAG;AAC1B,gBAAM,IAAI,UAAU,GAAG,OAAO,yBAAyB;;MAE3D;ACpBgB,eAAA,4BACd,MACA,SAAe;AAEf,yBAAiB,MAAM,OAAO;AAE9B,cAAM,WAAW,SAAI,QAAJ,SAAA,SAAA,SAAA,KAAM;AACvB,4BAAoB,UAAU,YAAY,sBAAsB;AAChE,6BAAqB,UAAU,GAAG,OAAO,6BAA6B;AAEtE,cAAM,WAAW,SAAI,QAAJ,SAAA,SAAA,SAAA,KAAM;AACvB,4BAAoB,UAAU,YAAY,sBAAsB;AAChE,6BAAqB,UAAU,GAAG,OAAO,6BAA6B;AAEtE,eAAO,EAAE,UAAU,SAAQ;MAC7B;YCkEaI,gBAAc;QAczB,YAAY,sBAAqF,CAAA,GACrF,cAAqD,CAAA,GAAE;AACjE,cAAI,wBAAwB,QAAW;AACrC,kCAAsB;iBACjB;AACL,yBAAa,qBAAqB,iBAAiB;;AAGrD,gBAAM,WAAW,uBAAuB,aAAa,kBAAkB;AACvE,gBAAM,mBAAmB,qCAAqC,qBAAqB,iBAAiB;AAEpG,mCAAyB,IAAI;AAE7B,cAAI,iBAAiB,SAAS,SAAS;AACrC,gBAAI,SAAS,SAAS,QAAW;AAC/B,oBAAM,IAAI,WAAW,4DAA4D;;AAEnF,kBAAM,gBAAgB,qBAAqB,UAAU,CAAC;AACtD,kEACE,MACA,kBACA,aAAa;iBAEV;AAEL,kBAAM,gBAAgB,qBAAqB,QAAQ;AACnD,kBAAM,gBAAgB,qBAAqB,UAAU,CAAC;AACtD,qEACE,MACA,kBACA,eACA,aAAa;;;;;;QAQnB,IAAI,SAAM;AACR,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMH,4BAA0B,QAAQ;;AAG1C,iBAAO,uBAAuB,IAAI;;;;;;;;QASpC,OAAO,SAAc,QAAS;AAC5B,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,mBAAO,oBAAoBA,4BAA0B,QAAQ,CAAC;;AAGhE,cAAI,uBAAuB,IAAI,GAAG;AAChC,mBAAO,oBAAoB,IAAI,UAAU,kDAAkD,CAAC;;AAG9F,iBAAO,qBAAqB,MAAM,MAAM;;QAsB1C,UACE,aAAgE,QAAS;AAEzE,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMA,4BAA0B,WAAW;;AAG7C,gBAAM,UAAU,qBAAqB,YAAY,iBAAiB;AAElE,cAAI,QAAQ,SAAS,QAAW;AAC9B,mBAAO,mCAAmC,IAAI;;AAIhD,iBAAO,gCAAgC,IAAqC;;QAc9E,YACE,cACA,aAAmD,CAAA,GAAE;AAErD,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMA,4BAA0B,aAAa;;AAE/C,iCAAuB,cAAc,GAAG,aAAa;AAErD,gBAAM,YAAY,4BAA4B,cAAc,iBAAiB;AAC7E,gBAAM,UAAU,mBAAmB,YAAY,kBAAkB;AAEjE,cAAI,uBAAuB,IAAI,GAAG;AAChC,kBAAM,IAAI,UAAU,gFAAgF;;AAEtG,cAAI,uBAAuB,UAAU,QAAQ,GAAG;AAC9C,kBAAM,IAAI,UAAU,gFAAgF;;AAGtG,gBAAM,UAAU,qBACd,MAAM,UAAU,UAAU,QAAQ,cAAc,QAAQ,cAAc,QAAQ,eAAe,QAAQ,MAAM;AAG7G,oCAA0B,OAAO;AAEjC,iBAAO,UAAU;;QAWnB,OAAO,aACA,aAAmD,CAAA,GAAE;AAC1D,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,mBAAO,oBAAoBA,4BAA0B,QAAQ,CAAC;;AAGhE,cAAI,gBAAgB,QAAW;AAC7B,mBAAO,oBAAoB,sCAAsC;;AAEnE,cAAI,CAAC,iBAAiB,WAAW,GAAG;AAClC,mBAAO,oBACL,IAAI,UAAU,2EAA2E,CAAC;;AAI9F,cAAI;AACJ,cAAI;AACF,sBAAU,mBAAmB,YAAY,kBAAkB;mBACpD,GAAG;AACV,mBAAO,oBAAoB,CAAC;;AAG9B,cAAI,uBAAuB,IAAI,GAAG;AAChC,mBAAO,oBACL,IAAI,UAAU,2EAA2E,CAAC;;AAG9F,cAAI,uBAAuB,WAAW,GAAG;AACvC,mBAAO,oBACL,IAAI,UAAU,2EAA2E,CAAC;;AAI9F,iBAAO,qBACL,MAAM,aAAa,QAAQ,cAAc,QAAQ,cAAc,QAAQ,eAAe,QAAQ,MAAM;;;;;;;;;;;;;QAexG,MAAG;AACD,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMA,4BAA0B,KAAK;;AAGvC,gBAAM,WAAW,kBAAkB,IAAW;AAC9C,iBAAO,oBAAoB,QAAQ;;QAerC,OAAO,aAA+D,QAAS;AAC7E,cAAI,CAAC,iBAAiB,IAAI,GAAG;AAC3B,kBAAMA,4BAA0B,QAAQ;;AAG1C,gBAAM,UAAU,uBAAuB,YAAY,iBAAiB;AACpE,iBAAO,mCAAsC,MAAM,QAAQ,aAAa;;QAQ1E,CAAC,mBAAmB,EAAE,SAAuC;AAE3D,iBAAO,KAAK,OAAO,OAAO;;;;;;;;QAS5B,OAAO,KAAQ,eAAqE;AAClF,iBAAO,mBAAmB,aAAa;;MAE1C;AAED,aAAO,iBAAiBG,iBAAgB;QACtC,MAAM,EAAE,YAAY,KAAI;MACzB,CAAA;AACD,aAAO,iBAAiBA,gBAAe,WAAW;QAChD,QAAQ,EAAE,YAAY,KAAI;QAC1B,WAAW,EAAE,YAAY,KAAI;QAC7B,aAAa,EAAE,YAAY,KAAI;QAC/B,QAAQ,EAAE,YAAY,KAAI;QAC1B,KAAK,EAAE,YAAY,KAAI;QACvB,QAAQ,EAAE,YAAY,KAAI;QAC1B,QAAQ,EAAE,YAAY,KAAI;MAC3B,CAAA;AACD,sBAAgBA,gBAAe,MAAM,MAAM;AAC3C,sBAAgBA,gBAAe,UAAU,QAAQ,QAAQ;AACzD,sBAAgBA,gBAAe,UAAU,WAAW,WAAW;AAC/D,sBAAgBA,gBAAe,UAAU,aAAa,aAAa;AACnE,sBAAgBA,gBAAe,UAAU,QAAQ,QAAQ;AACzD,sBAAgBA,gBAAe,UAAU,KAAK,KAAK;AACnD,sBAAgBA,gBAAe,UAAU,QAAQ,QAAQ;AACzD,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAeA,gBAAe,WAAW,OAAO,aAAa;UAClE,OAAO;UACP,cAAc;QACf,CAAA;MACH;AACA,aAAO,eAAeA,gBAAe,WAAW,qBAAqB;QACnE,OAAOA,gBAAe,UAAU;QAChC,UAAU;QACV,cAAc;MACf,CAAA;eAwBe,qBACd,gBACA,eACA,iBACA,gBAAgB,GAChB,gBAAgD,MAAM,GAAC;AAIvD,cAAM,SAAmC,OAAO,OAAOA,gBAAe,SAAS;AAC/E,iCAAyB,MAAM;AAE/B,cAAM,aAAiD,OAAO,OAAO,gCAAgC,SAAS;AAC9G,6CACE,QAAQ,YAAY,gBAAgB,eAAe,iBAAiB,eAAe,aAAa;AAGlG,eAAO;MACT;eAGgB,yBACd,gBACA,eACA,iBAA+C;AAE/C,cAAM,SAA6B,OAAO,OAAOA,gBAAe,SAAS;AACzE,iCAAyB,MAAM;AAE/B,cAAM,aAA2C,OAAO,OAAO,6BAA6B,SAAS;AACrG,0CAAkC,QAAQ,YAAY,gBAAgB,eAAe,iBAAiB,GAAG,MAAS;AAElH,eAAO;MACT;AAEA,eAAS,yBAAyB,QAAsB;AACtD,eAAO,SAAS;AAChB,eAAO,UAAU;AACjB,eAAO,eAAe;AACtB,eAAO,aAAa;MACtB;AAEM,eAAU,iBAAiB,GAAU;AACzC,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,2BAA2B,GAAG;AACzE,iBAAO;;AAGT,eAAO,aAAaA;MACtB;AAQM,eAAU,uBAAuB,QAAsB;AAG3D,YAAI,OAAO,YAAY,QAAW;AAChC,iBAAO;;AAGT,eAAO;MACT;AAIgB,eAAA,qBAAwB,QAA2B,QAAW;AAC5E,eAAO,aAAa;AAEpB,YAAI,OAAO,WAAW,UAAU;AAC9B,iBAAO,oBAAoB,MAAS;;AAEtC,YAAI,OAAO,WAAW,WAAW;AAC/B,iBAAO,oBAAoB,OAAO,YAAY;;AAGhD,4BAAoB,MAAM;AAE1B,cAAM,SAAS,OAAO;AACtB,YAAI,WAAW,UAAa,2BAA2B,MAAM,GAAG;AAC9D,gBAAM,mBAAmB,OAAO;AAChC,iBAAO,oBAAoB,IAAI,YAAW;AAC1C,2BAAiB,QAAQ,qBAAkB;AACzC,4BAAgB,YAAY,MAAS;UACvC,CAAC;;AAGH,cAAM,sBAAsB,OAAO,0BAA0B,WAAW,EAAE,MAAM;AAChF,eAAO,qBAAqB,qBAAqB,IAAI;MACvD;AAEM,eAAU,oBAAuB,QAAyB;AAG9D,eAAO,SAAS;AAEhB,cAAM,SAAS,OAAO;AAEtB,YAAI,WAAW,QAAW;AACxB;;AAGF,0CAAkC,MAAM;AAExC,YAAI,8BAAiC,MAAM,GAAG;AAC5C,gBAAM,eAAe,OAAO;AAC5B,iBAAO,gBAAgB,IAAI,YAAW;AACtC,uBAAa,QAAQ,iBAAc;AACjC,wBAAY,YAAW;UACzB,CAAC;;MAEL;AAEgB,eAAA,oBAAuB,QAA2B,GAAM;AAItE,eAAO,SAAS;AAChB,eAAO,eAAe;AAEtB,cAAM,SAAS,OAAO;AAEtB,YAAI,WAAW,QAAW;AACxB;;AAGF,yCAAiC,QAAQ,CAAC;AAE1C,YAAI,8BAAiC,MAAM,GAAG;AAC5C,uDAA6C,QAAQ,CAAC;eACjD;AAEL,wDAA8C,QAAQ,CAAC;;MAE3D;AAqBA,eAASH,4BAA0B,MAAY;AAC7C,eAAO,IAAI,UAAU,4BAA4B,IAAI,uCAAuC;MAC9F;ACljBgB,eAAA,2BAA2B,MACA,SAAe;AACxD,yBAAiB,MAAM,OAAO;AAC9B,cAAM,gBAAgB,SAAI,QAAJ,SAAA,SAAA,SAAA,KAAM;AAC5B,4BAAoB,eAAe,iBAAiB,qBAAqB;AACzE,eAAO;UACL,eAAe,0BAA0B,aAAa;;MAE1D;ACLA,YAAM,yBAAyB,CAAC,UAAkC;AAChE,eAAO,MAAM;MACf;AACA,sBAAgB,wBAAwB,MAAM;MAOhC,MAAO,0BAAyB;QAI5C,YAAY,SAA4B;AACtC,iCAAuB,SAAS,GAAG,2BAA2B;AAC9D,oBAAU,2BAA2B,SAAS,iBAAiB;AAC/D,eAAK,0CAA0C,QAAQ;;;;;QAMzD,IAAI,gBAAa;AACf,cAAI,CAAC,4BAA4B,IAAI,GAAG;AACtC,kBAAM,8BAA8B,eAAe;;AAErD,iBAAO,KAAK;;;;;QAMd,IAAI,OAAI;AACN,cAAI,CAAC,4BAA4B,IAAI,GAAG;AACtC,kBAAM,8BAA8B,MAAM;;AAE5C,iBAAO;;MAEV;AAED,aAAO,iBAAiB,0BAA0B,WAAW;QAC3D,eAAe,EAAE,YAAY,KAAI;QACjC,MAAM,EAAE,YAAY,KAAI;MACzB,CAAA;AACD,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,0BAA0B,WAAW,OAAO,aAAa;UAC7E,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,8BAA8B,MAAY;AACjD,eAAO,IAAI,UAAU,uCAAuC,IAAI,kDAAkD;MACpH;AAEM,eAAU,4BAA4B,GAAM;AAChD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,yCAAyC,GAAG;AACvF,iBAAO;;AAGT,eAAO,aAAa;MACtB;ACpEA,YAAM,oBAAoB,MAAQ;AAChC,eAAO;MACT;AACA,sBAAgB,mBAAmB,MAAM;MAO3B,MAAO,qBAAoB;QAIvC,YAAY,SAA4B;AACtC,iCAAuB,SAAS,GAAG,sBAAsB;AACzD,oBAAU,2BAA2B,SAAS,iBAAiB;AAC/D,eAAK,qCAAqC,QAAQ;;;;;QAMpD,IAAI,gBAAa;AACf,cAAI,CAAC,uBAAuB,IAAI,GAAG;AACjC,kBAAM,yBAAyB,eAAe;;AAEhD,iBAAO,KAAK;;;;;;QAOd,IAAI,OAAI;AACN,cAAI,CAAC,uBAAuB,IAAI,GAAG;AACjC,kBAAM,yBAAyB,MAAM;;AAEvC,iBAAO;;MAEV;AAED,aAAO,iBAAiB,qBAAqB,WAAW;QACtD,eAAe,EAAE,YAAY,KAAI;QACjC,MAAM,EAAE,YAAY,KAAI;MACzB,CAAA;AACD,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,qBAAqB,WAAW,OAAO,aAAa;UACxE,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,yBAAyB,MAAY;AAC5C,eAAO,IAAI,UAAU,kCAAkC,IAAI,6CAA6C;MAC1G;AAEM,eAAU,uBAAuB,GAAM;AAC3C,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,oCAAoC,GAAG;AAClF,iBAAO;;AAGT,eAAO,aAAa;MACtB;AC/DgB,eAAA,mBAAyB,UACA,SAAe;AACtD,yBAAiB,UAAU,OAAO;AAClC,cAAM,SAAS,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACzB,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,eAAe,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AAC/B,cAAM,QAAQ,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AACxB,cAAM,YAAY,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AAC5B,cAAM,eAAe,aAAQ,QAAR,aAAA,SAAA,SAAA,SAAU;AAC/B,eAAO;UACL,QAAQ,WAAW,SACjB,SACA,iCAAiC,QAAQ,UAAW,GAAG,OAAO,2BAA2B;UAC3F,OAAO,UAAU,SACf,SACA,gCAAgC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UACxF;UACA,OAAO,UAAU,SACf,SACA,gCAAgC,OAAO,UAAW,GAAG,OAAO,0BAA0B;UACxF,WAAW,cAAc,SACvB,SACA,oCAAoC,WAAW,UAAW,GAAG,OAAO,8BAA8B;UACpG;;MAEJ;AAEA,eAAS,gCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,eAAoD,YAAY,IAAI,UAAU,CAAC,UAAU,CAAC;MACpG;AAEA,eAAS,gCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,eAAoD,YAAY,IAAI,UAAU,CAAC,UAAU,CAAC;MACpG;AAEA,eAAS,oCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,OAAU,eAAoD,YAAY,IAAI,UAAU,CAAC,OAAO,UAAU,CAAC;MACrH;AAEA,eAAS,iCACP,IACA,UACA,SAAe;AAEf,uBAAe,IAAI,OAAO;AAC1B,eAAO,CAAC,WAAgB,YAAY,IAAI,UAAU,CAAC,MAAM,CAAC;MAC5D;YC7Ba,gBAAe;QAmB1B,YAAY,iBAAuD,CAAA,GACvD,sBAA6D,CAAA,GAC7D,sBAA6D,CAAA,GAAE;AACzE,cAAI,mBAAmB,QAAW;AAChC,6BAAiB;;AAGnB,gBAAM,mBAAmB,uBAAuB,qBAAqB,kBAAkB;AACvF,gBAAM,mBAAmB,uBAAuB,qBAAqB,iBAAiB;AAEtF,gBAAM,cAAc,mBAAmB,gBAAgB,iBAAiB;AACxE,cAAI,YAAY,iBAAiB,QAAW;AAC1C,kBAAM,IAAI,WAAW,gCAAgC;;AAEvD,cAAI,YAAY,iBAAiB,QAAW;AAC1C,kBAAM,IAAI,WAAW,gCAAgC;;AAGvD,gBAAM,wBAAwB,qBAAqB,kBAAkB,CAAC;AACtE,gBAAM,wBAAwB,qBAAqB,gBAAgB;AACnE,gBAAM,wBAAwB,qBAAqB,kBAAkB,CAAC;AACtE,gBAAM,wBAAwB,qBAAqB,gBAAgB;AAEnE,cAAI;AACJ,gBAAM,eAAe,WAAiB,aAAU;AAC9C,mCAAuB;UACzB,CAAC;AAED,oCACE,MAAM,cAAc,uBAAuB,uBAAuB,uBAAuB,qBAAqB;AAEhH,+DAAqD,MAAM,WAAW;AAEtE,cAAI,YAAY,UAAU,QAAW;AACnC,iCAAqB,YAAY,MAAM,KAAK,0BAA0B,CAAC;iBAClE;AACL,iCAAqB,MAAS;;;;;;QAOlC,IAAI,WAAQ;AACV,cAAI,CAAC,kBAAkB,IAAI,GAAG;AAC5B,kBAAM,0BAA0B,UAAU;;AAG5C,iBAAO,KAAK;;;;;QAMd,IAAI,WAAQ;AACV,cAAI,CAAC,kBAAkB,IAAI,GAAG;AAC5B,kBAAM,0BAA0B,UAAU;;AAG5C,iBAAO,KAAK;;MAEf;AAED,aAAO,iBAAiB,gBAAgB,WAAW;QACjD,UAAU,EAAE,YAAY,KAAI;QAC5B,UAAU,EAAE,YAAY,KAAI;MAC7B,CAAA;AACD,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,gBAAgB,WAAW,OAAO,aAAa;UACnE,OAAO;UACP,cAAc;QACf,CAAA;MACH;AA0CA,eAAS,0BAAgC,QACA,cACA,uBACA,uBACA,uBACA,uBAAqD;AAC5F,iBAAS,iBAAc;AACrB,iBAAO;;AAGT,iBAAS,eAAe,OAAQ;AAC9B,iBAAO,yCAAyC,QAAQ,KAAK;;AAG/D,iBAAS,eAAe,QAAW;AACjC,iBAAO,yCAAyC,QAAQ,MAAM;;AAGhE,iBAAS,iBAAc;AACrB,iBAAO,yCAAyC,MAAM;;AAGxD,eAAO,YAAY,qBAAqB,gBAAgB,gBAAgB,gBAAgB,gBAChD,uBAAuB,qBAAqB;AAEpF,iBAAS,gBAAa;AACpB,iBAAO,0CAA0C,MAAM;;AAGzD,iBAAS,gBAAgB,QAAW;AAClC,iBAAO,4CAA4C,QAAQ,MAAM;;AAGnE,eAAO,YAAY,qBAAqB,gBAAgB,eAAe,iBAAiB,uBAChD,qBAAqB;AAG7D,eAAO,gBAAgB;AACvB,eAAO,6BAA6B;AACpC,eAAO,qCAAqC;AAC5C,uCAA+B,QAAQ,IAAI;AAE3C,eAAO,6BAA6B;MACtC;AAEA,eAAS,kBAAkB,GAAU;AACnC,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,4BAA4B,GAAG;AAC1E,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAGA,eAAS,qBAAqB,QAAyB,GAAM;AAC3D,6CAAqC,OAAO,UAAU,2BAA2B,CAAC;AAClF,oDAA4C,QAAQ,CAAC;MACvD;AAEA,eAAS,4CAA4C,QAAyB,GAAM;AAClF,wDAAgD,OAAO,0BAA0B;AACjF,qDAA6C,OAAO,UAAU,2BAA2B,CAAC;AAC1F,oCAA4B,MAAM;MACpC;AAEA,eAAS,4BAA4B,QAAuB;AAC1D,YAAI,OAAO,eAAe;AAIxB,yCAA+B,QAAQ,KAAK;;MAEhD;AAEA,eAAS,+BAA+B,QAAyB,cAAqB;AAIpF,YAAI,OAAO,+BAA+B,QAAW;AACnD,iBAAO,mCAAkC;;AAG3C,eAAO,6BAA6B,WAAW,aAAU;AACvD,iBAAO,qCAAqC;QAC9C,CAAC;AAED,eAAO,gBAAgB;MACzB;YASa,iCAAgC;QAgB3C,cAAA;AACE,gBAAM,IAAI,UAAU,qBAAqB;;;;;QAM3C,IAAI,cAAW;AACb,cAAI,CAAC,mCAAmC,IAAI,GAAG;AAC7C,kBAAM,qCAAqC,aAAa;;AAG1D,gBAAM,qBAAqB,KAAK,2BAA2B,UAAU;AACrE,iBAAO,8CAA8C,kBAAkB;;QAOzE,QAAQ,QAAW,QAAU;AAC3B,cAAI,CAAC,mCAAmC,IAAI,GAAG;AAC7C,kBAAM,qCAAqC,SAAS;;AAGtD,kDAAwC,MAAM,KAAK;;;;;;QAOrD,MAAM,SAAc,QAAS;AAC3B,cAAI,CAAC,mCAAmC,IAAI,GAAG;AAC7C,kBAAM,qCAAqC,OAAO;;AAGpD,gDAAsC,MAAM,MAAM;;;;;;QAOpD,YAAS;AACP,cAAI,CAAC,mCAAmC,IAAI,GAAG;AAC7C,kBAAM,qCAAqC,WAAW;;AAGxD,oDAA0C,IAAI;;MAEjD;AAED,aAAO,iBAAiB,iCAAiC,WAAW;QAClE,SAAS,EAAE,YAAY,KAAI;QAC3B,OAAO,EAAE,YAAY,KAAI;QACzB,WAAW,EAAE,YAAY,KAAI;QAC7B,aAAa,EAAE,YAAY,KAAI;MAChC,CAAA;AACD,sBAAgB,iCAAiC,UAAU,SAAS,SAAS;AAC7E,sBAAgB,iCAAiC,UAAU,OAAO,OAAO;AACzE,sBAAgB,iCAAiC,UAAU,WAAW,WAAW;AACjF,UAAI,OAAO,OAAO,gBAAgB,UAAU;AAC1C,eAAO,eAAe,iCAAiC,WAAW,OAAO,aAAa;UACpF,OAAO;UACP,cAAc;QACf,CAAA;MACH;AAIA,eAAS,mCAA4C,GAAM;AACzD,YAAI,CAAC,aAAa,CAAC,GAAG;AACpB,iBAAO;;AAGT,YAAI,CAAC,OAAO,UAAU,eAAe,KAAK,GAAG,4BAA4B,GAAG;AAC1E,iBAAO;;AAGT,eAAO,aAAa;MACtB;AAEA,eAAS,sCAA4C,QACA,YACA,oBACA,gBACA,iBAA+C;AAIlG,mBAAW,6BAA6B;AACxC,eAAO,6BAA6B;AAEpC,mBAAW,sBAAsB;AACjC,mBAAW,kBAAkB;AAC7B,mBAAW,mBAAmB;AAE9B,mBAAW,iBAAiB;AAC5B,mBAAW,yBAAyB;AACpC,mBAAW,wBAAwB;MACrC;AAEA,eAAS,qDAA2D,QACA,aAAuC;AACzG,cAAM,aAAkD,OAAO,OAAO,iCAAiC,SAAS;AAEhH,YAAI;AACJ,YAAI;AACJ,YAAI;AAEJ,YAAI,YAAY,cAAc,QAAW;AACvC,+BAAqB,WAAS,YAAY,UAAW,OAAO,UAAU;eACjE;AACL,+BAAqB,WAAQ;AAC3B,gBAAI;AACF,sDAAwC,YAAY,KAAqB;AACzE,qBAAO,oBAAoB,MAAS;qBAC7B,kBAAkB;AACzB,qBAAO,oBAAoB,gBAAgB;;UAE/C;;AAGF,YAAI,YAAY,UAAU,QAAW;AACnC,2BAAiB,MAAM,YAAY,MAAO,UAAU;eAC/C;AACL,2BAAiB,MAAM,oBAAoB,MAAS;;AAGtD,YAAI,YAAY,WAAW,QAAW;AACpC,4BAAkB,YAAU,YAAY,OAAQ,MAAM;eACjD;AACL,4BAAkB,MAAM,oBAAoB,MAAS;;AAGvD,8CAAsC,QAAQ,YAAY,oBAAoB,gBAAgB,eAAe;MAC/G;AAEA,eAAS,gDAAgD,YAAiD;AACxG,mBAAW,sBAAsB;AACjC,mBAAW,kBAAkB;AAC7B,mBAAW,mBAAmB;MAChC;AAEA,eAAS,wCAA2C,YAAiD,OAAQ;AAC3G,cAAM,SAAS,WAAW;AAC1B,cAAM,qBAAqB,OAAO,UAAU;AAC5C,YAAI,CAAC,iDAAiD,kBAAkB,GAAG;AACzE,gBAAM,IAAI,UAAU,sDAAsD;;AAM5E,YAAI;AACF,iDAAuC,oBAAoB,KAAK;iBACzD,GAAG;AAEV,sDAA4C,QAAQ,CAAC;AAErD,gBAAM,OAAO,UAAU;;AAGzB,cAAM,eAAe,+CAA+C,kBAAkB;AACtF,YAAI,iBAAiB,OAAO,eAAe;AAEzC,yCAA+B,QAAQ,IAAI;;MAE/C;AAEA,eAAS,sCAAsC,YAAmD,GAAM;AACtG,6BAAqB,WAAW,4BAA4B,CAAC;MAC/D;AAEA,eAAS,iDAAuD,YACA,OAAQ;AACtE,cAAM,mBAAmB,WAAW,oBAAoB,KAAK;AAC7D,eAAO,qBAAqB,kBAAkB,QAAW,OAAI;AAC3D,+BAAqB,WAAW,4BAA4B,CAAC;AAC7D,gBAAM;QACR,CAAC;MACH;AAEA,eAAS,0CAA6C,YAA+C;AACnG,cAAM,SAAS,WAAW;AAC1B,cAAM,qBAAqB,OAAO,UAAU;AAE5C,6CAAqC,kBAAkB;AAEvD,cAAM,QAAQ,IAAI,UAAU,4BAA4B;AACxD,oDAA4C,QAAQ,KAAK;MAC3D;AAIA,eAAS,yCAA+C,QAA+B,OAAQ;AAG7F,cAAM,aAAa,OAAO;AAE1B,YAAI,OAAO,eAAe;AACxB,gBAAM,4BAA4B,OAAO;AAEzC,iBAAO,qBAAqB,2BAA2B,MAAK;AAC1D,kBAAM,WAAW,OAAO;AACxB,kBAAM,QAAQ,SAAS;AACvB,gBAAI,UAAU,YAAY;AACxB,oBAAM,SAAS;;AAGjB,mBAAO,iDAAuD,YAAY,KAAK;UACjF,CAAC;;AAGH,eAAO,iDAAuD,YAAY,KAAK;MACjF;AAEA,eAAS,yCAA+C,QAA+B,QAAW;AAChG,cAAM,aAAa,OAAO;AAC1B,YAAI,WAAW,mBAAmB,QAAW;AAC3C,iBAAO,WAAW;;AAIpB,cAAM,WAAW,OAAO;AAIxB,mBAAW,iBAAiB,WAAW,CAAC,SAAS,WAAU;AACzD,qBAAW,yBAAyB;AACpC,qBAAW,wBAAwB;QACrC,CAAC;AAED,cAAM,gBAAgB,WAAW,iBAAiB,MAAM;AACxD,wDAAgD,UAAU;AAE1D,oBAAY,eAAe,MAAK;AAC9B,cAAI,SAAS,WAAW,WAAW;AACjC,iDAAqC,YAAY,SAAS,YAAY;iBACjE;AACL,iDAAqC,SAAS,2BAA2B,MAAM;AAC/E,kDAAsC,UAAU;;AAElD,iBAAO;WACN,OAAI;AACL,+CAAqC,SAAS,2BAA2B,CAAC;AAC1E,+CAAqC,YAAY,CAAC;AAClD,iBAAO;QACT,CAAC;AAED,eAAO,WAAW;MACpB;AAEA,eAAS,yCAA+C,QAA6B;AACnF,cAAM,aAAa,OAAO;AAC1B,YAAI,WAAW,mBAAmB,QAAW;AAC3C,iBAAO,WAAW;;AAIpB,cAAM,WAAW,OAAO;AAIxB,mBAAW,iBAAiB,WAAW,CAAC,SAAS,WAAU;AACzD,qBAAW,yBAAyB;AACpC,qBAAW,wBAAwB;QACrC,CAAC;AAED,cAAM,eAAe,WAAW,gBAAe;AAC/C,wDAAgD,UAAU;AAE1D,oBAAY,cAAc,MAAK;AAC7B,cAAI,SAAS,WAAW,WAAW;AACjC,iDAAqC,YAAY,SAAS,YAAY;iBACjE;AACL,iDAAqC,SAAS,yBAAyB;AACvE,kDAAsC,UAAU;;AAElD,iBAAO;WACN,OAAI;AACL,+CAAqC,SAAS,2BAA2B,CAAC;AAC1E,+CAAqC,YAAY,CAAC;AAClD,iBAAO;QACT,CAAC;AAED,eAAO,WAAW;MACpB;AAIA,eAAS,0CAA0C,QAAuB;AAMxE,uCAA+B,QAAQ,KAAK;AAG5C,eAAO,OAAO;MAChB;AAEA,eAAS,4CAAkD,QAA+B,QAAW;AACnG,cAAM,aAAa,OAAO;AAC1B,YAAI,WAAW,mBAAmB,QAAW;AAC3C,iBAAO,WAAW;;AAIpB,cAAM,WAAW,OAAO;AAKxB,mBAAW,iBAAiB,WAAW,CAAC,SAAS,WAAU;AACzD,qBAAW,yBAAyB;AACpC,qBAAW,wBAAwB;QACrC,CAAC;AAED,cAAM,gBAAgB,WAAW,iBAAiB,MAAM;AACxD,wDAAgD,UAAU;AAE1D,oBAAY,eAAe,MAAK;AAC9B,cAAI,SAAS,WAAW,WAAW;AACjC,iDAAqC,YAAY,SAAS,YAAY;iBACjE;AACL,yDAA6C,SAAS,2BAA2B,MAAM;AACvF,wCAA4B,MAAM;AAClC,kDAAsC,UAAU;;AAElD,iBAAO;WACN,OAAI;AACL,uDAA6C,SAAS,2BAA2B,CAAC;AAClF,sCAA4B,MAAM;AAClC,+CAAqC,YAAY,CAAC;AAClD,iBAAO;QACT,CAAC;AAED,eAAO,WAAW;MACpB;AAIA,eAAS,qCAAqC,MAAY;AACxD,eAAO,IAAI,UACT,8CAA8C,IAAI,yDAAyD;MAC/G;AAEM,eAAU,sCAAsC,YAAiD;AACrG,YAAI,WAAW,2BAA2B,QAAW;AACnD;;AAGF,mBAAW,uBAAsB;AACjC,mBAAW,yBAAyB;AACpC,mBAAW,wBAAwB;MACrC;AAEgB,eAAA,qCAAqC,YAAmD,QAAW;AACjH,YAAI,WAAW,0BAA0B,QAAW;AAClD;;AAGF,kCAA0B,WAAW,cAAe;AACpD,mBAAW,sBAAsB,MAAM;AACvC,mBAAW,yBAAyB;AACpC,mBAAW,wBAAwB;MACrC;AAIA,eAAS,0BAA0B,MAAY;AAC7C,eAAO,IAAI,UACT,6BAA6B,IAAI,wCAAwC;MAC7E;;;;;;;;;;;;;;;;;;;ACnoBO,IAAI,OAAO;AACX,IAAI,OAAkC;AACtC,IAAI,QAAoC;AACxC,IAAII,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,WAAwC;AAC5C,IAAI,WAA0C;AAC9C,IAAIC,QAAkC;AACtC,IAAIC,QAAkC;AACtC,IAAI,iBAAsD;AAC1D,IAAI,6BAA8E;AAClF,IAAI,kBAAwD;AAC5D,IAAI,eAAkD;AACtD,IAAI,iBAAsD;AAE3D,SAAU,SAAS,OAAc,UAA6B,EAAE,MAAM,MAAK,GAAE;AACjF,MAAI,MAAM;AACR,UAAM,IAAI,MACR,mCAAmC,MAAM,IAAI,gDAAgD;;AAGjG,MAAI,MAAM;AACR,UAAM,IAAI,MAAM,gCAAgC,MAAM,IAAI,oCAAoC,IAAI,KAAK;;AAEzG,SAAO,QAAQ;AACf,SAAO,MAAM;AACb,UAAQ,MAAM;AACd,EAAAJ,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,WAAU,MAAM;AAChB,aAAW,MAAM;AACjB,EAAAC,QAAO,MAAM;AACb,EAAAC,QAAO,MAAM;AACb,mBAAiB,MAAM;AACvB,+BAA6B,MAAM;AACnC,oBAAkB,MAAM;AACxB,iBAAe,MAAM;AACrB,mBAAiB,MAAM;AACzB;;;;;;AC1DA,SAAS,eAAe;;;ACLjB,IAAM,SAAS,CAAC,UAAU,iBAAiB;;;ACDlD,SAAS,iBAAiB;AACnB,IAAM,8BAA8B,UAAU,MAAM;AAAE,GAAG,iGACd;;;AFFlD,IAAI,yBAAkE,SAAU,UAAU,OAAOC,OAAM,GAAG;AACtG,MAAIA,UAAS,OAAO,CAAC;AAAG,UAAM,IAAI,UAAU,+CAA+C;AAC3F,MAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,IAAI,QAAQ;AAAG,UAAM,IAAI,UAAU,0EAA0E;AACjL,SAAOA,UAAS,MAAM,IAAIA,UAAS,MAAM,EAAE,KAAK,QAAQ,IAAI,IAAI,EAAE,QAAQ,MAAM,IAAI,QAAQ;AAChG;AACA,IAAI;AAAJ,IAAyB;AAAzB,IAA4C;AAOrC,IAAMC,YAAN,MAAe;AAAA,EAClB,YAAY,SAAS;AACjB,wBAAoB,IAAI,IAAI;AAC5B,sBAAkB,IAAI,MAAM,oBAAI,IAAI,CAAC;AACrC,QAAI,SAAS;AACT,kCAA4B;AAC5B,cAAQ,QAAQ,CAAC,EAAE,MAAM,OAAO,SAAS,MAAM,KAAK,OAAO,MAAM,OAAO,QAAQ,CAAC;AAAA,IACrF;AAAA,EACJ;AAAA,EACA,SAAS,oBAAoB,oBAAI,QAAQ,GAAG,sBAAsB,oBAAI,QAAQ,GAAG,OAAO,YAAY,EAAE,OAAO;AACzG,WAAO,QAAQ,SACR,WAAW,MAAM,WAAW,KAC5B,MAAM,OAAO,WAAW,MAAM,cAC9B,WAAW,MAAM,MAAM,KACvB,WAAW,MAAM,GAAG,KACpB,WAAW,MAAM,GAAG,KACpB,WAAW,MAAM,MAAM,KACvB,WAAW,MAAM,GAAG,KACpB,WAAW,MAAM,MAAM,KACvB,WAAW,MAAM,OAAO,KACxB,WAAW,MAAM,MAAM,KACvB,WAAW,MAAM,IAAI,KACrB,WAAW,MAAM,OAAO,QAAQ,CAAC,KACjC,WAAW,MAAM,OAAO,CAAC;AAAA,EACpC;AAAA,EACA,OAAO,MAAM,OAAO,UAAU;AAC1B,2BAAuB,MAAM,qBAAqB,KAAK,kBAAkB,EAAE,KAAK,MAAM;AAAA,MAClF;AAAA,MACA;AAAA,MACA,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,YAAY,UAAU;AAAA,IAC1B,CAAC;AAAA,EACL;AAAA,EACA,IAAI,MAAM,OAAO,UAAU;AACvB,2BAAuB,MAAM,qBAAqB,KAAK,kBAAkB,EAAE,KAAK,MAAM;AAAA,MAClF;AAAA,MACA;AAAA,MACA,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,YAAY,UAAU;AAAA,IAC1B,CAAC;AAAA,EACL;AAAA,EACA,IAAI,MAAM;AACN,UAAM,QAAQ,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,OAAO,IAAI,CAAC;AACnF,QAAI,CAAC,OAAO;AACR,aAAO;AAAA,IACX;AACA,WAAO,MAAM,CAAC;AAAA,EAClB;AAAA,EACA,OAAO,MAAM;AACT,UAAM,QAAQ,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,OAAO,IAAI,CAAC;AACnF,QAAI,CAAC,OAAO;AACR,aAAO,CAAC;AAAA,IACZ;AACA,WAAO,MAAM,MAAM;AAAA,EACvB;AAAA,EACA,IAAI,MAAM;AACN,WAAO,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,OAAO,IAAI,CAAC;AAAA,EAChF;AAAA,EACA,OAAO,MAAM;AACT,2BAAuB,MAAM,mBAAmB,GAAG,EAAE,OAAO,OAAO,IAAI,CAAC;AAAA,EAC5E;AAAA,EACA,CAAC,OAAO;AACJ,eAAW,OAAO,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,KAAK,GAAG;AAC3E,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EACA,CAAC,UAAU;AACP,eAAW,QAAQ,KAAK,KAAK,GAAG;AAC5B,YAAM,SAAS,KAAK,OAAO,IAAI;AAC/B,iBAAW,SAAS,QAAQ;AACxB,cAAM,CAAC,MAAM,KAAK;AAAA,MACtB;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,CAAC,SAAS;AACN,eAAW,CAAC,EAAE,KAAK,KAAK,MAAM;AAC1B,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EACA,EAAE,qBAAqB,SAASC,oBAAmB,EAAE,MAAM,UAAU,QAAQ,UAAU,WAAW,GAAG;AACjG,UAAM,aAAa,SAAS,WAAW;AACvC,QAAI,aAAa,GAAG;AAChB,YAAM,IAAI,UAAU,sBAAsB,UAAU,mDACZ,UAAU,WAAW;AAAA,IACjE;AACA,WAAO,OAAO,IAAI;AAClB,QAAI;AACJ,QAAI,OAAO,QAAQ,GAAG;AAClB,cAAQ,aAAa,SACf,WACA,IAAI,KAAK,CAAC,QAAQ,GAAG,UAAU;AAAA,QAC7B,MAAM,SAAS;AAAA,QACf,cAAc,SAAS;AAAA,MAC3B,CAAC;AAAA,IACT,WACS,OAAO,QAAQ,GAAG;AACvB,cAAQ,IAAI,KAAK,CAAC,QAAQ,GAAG,aAAa,SAAY,SAAS,UAAU;AAAA,QACrE,MAAM,SAAS;AAAA,MACnB,CAAC;AAAA,IACL,WACS,UAAU;AACf,YAAM,IAAI,UAAU,sBAAsB,UAAU,qDACV;AAAA,IAC9C,OACK;AACD,cAAQ,OAAO,QAAQ;AAAA,IAC3B;AACA,UAAM,SAAS,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,IAAI;AAC5E,QAAI,CAAC,QAAQ;AACT,aAAO,KAAK,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,MAAM,CAAC,KAAK,CAAC;AAAA,IACtF;AACA,QAAI,CAAC,QAAQ;AACT,aAAO,KAAK,uBAAuB,MAAM,mBAAmB,GAAG,EAAE,IAAI,MAAM,CAAC,KAAK,CAAC;AAAA,IACtF;AACA,WAAO,KAAK,KAAK;AAAA,EACrB,GAAG,OAAO,SAAS,IAAI;AACnB,WAAO,KAAK,QAAQ;AAAA,EACxB;AAAA,EACA,QAAQ,UAAU,SAAS;AACvB,eAAW,CAAC,MAAM,KAAK,KAAK,MAAM;AAC9B,eAAS,KAAK,SAAS,OAAO,MAAM,IAAI;AAAA,IAC5C;AAAA,EACJ;AAAA,EACA,KAAK,OAAO,WAAW,IAAI;AACvB,WAAO;AAAA,EACX;AAAA,EACA,CAAC,QAAQ,MAAM,IAAI;AACf,WAAO,KAAK,OAAO,WAAW;AAAA,EAClC;AACJ;;;4BGzI2B;8BACgC;SAClD,cAAc,oBAAoB;;;ACR3C,IAAM,WAAW;AACjB,SAAS,iBAAiB;AACtB,MAAI,OAAO;AACX,MAAI,MAAM;AACV,SAAO,QAAQ;AACX,WAAO,SAAU,KAAK,OAAO,IAAI,SAAS,UAAW,CAAC;AAAA,EAC1D;AACA,SAAO;AACX;AACA,IAAO,yBAAQ;;;ACTf,IAAM,UAAU,CAAC,UAAW,OAAO,UAAU,SAAS,KAAK,KAAK,EAAE,MAAM,GAAG,EAAE,EAAE,YAAY;AAC3F,SAAS,cAAc,OAAO;AAC1B,MAAI,QAAQ,KAAK,MAAM,UAAU;AAC7B,WAAO;AAAA,EACX;AACA,QAAM,KAAK,OAAO,eAAe,KAAK;AACtC,MAAI,OAAO,QAAQ,OAAO,QAAW;AACjC,WAAO;AAAA,EACX;AACA,QAAM,OAAO,GAAG,eAAe,GAAG,YAAY,SAAS;AACvD,SAAO,SAAS,OAAO,SAAS;AACpC;AACA,IAAO,wBAAQ;;;ACZf,IAAM,iBAAiB,CAAC,UAAU,OAAO,KAAK,EACzC,QAAQ,UAAU,CAAC,OAAO,GAAGC,SAAQ;AACtC,MAAK,UAAU,QAAQA,KAAI,IAAI,CAAC,MAAM,QAC9B,UAAU,QAAQA,KAAI,IAAI,CAAC,MAAM,MAAO;AAC5C,WAAO;AAAA,EACX;AACA,SAAO;AACX,CAAC;AACD,IAAO,yBAAQ;;;ACRf,IAAM,aAAa,CAAC,SAAS,OAAO,IAAI,EACnC,QAAQ,OAAO,KAAK,EACpB,QAAQ,OAAO,KAAK,EACpB,QAAQ,MAAM,KAAK;AACxB,IAAO,qBAAQ;;;ACJf,IAAMC,cAAa,CAAC,UAAW,OAAO,UAAU;AAChD,IAAO,qBAAQA;;;ACAR,IAAM,aAAa,CAAC,UAAU,QAAQ,SACtC,OAAO,UAAU,YACjB,mBAAW,MAAM,WAAW,KAC5B,MAAM,OAAO,WAAW,MAAM,UAC9B,mBAAW,MAAM,MAAM,KACvB,MAAM,QAAQ,QACd,MAAM,QAAQ,QACd,MAAM,gBAAgB,IAAI;;;ACP1B,IAAM,aAAa,CAAC,UAAU,QAAQ,SACtC,mBAAW,MAAM,WAAW,KAC5B,MAAM,OAAO,WAAW,MAAM,cAC9B,mBAAW,MAAM,MAAM,KACvB,mBAAW,MAAM,MAAM,KACvB,mBAAW,MAAM,OAAO,KACxB,mBAAW,MAAM,OAAO,QAAQ,CAAC,CAAC;;;ACPzC,IAAI,yBAAkE,SAAU,UAAU,OAAO,OAAOC,OAAM,GAAG;AAC7G,MAAIA,UAAS;AAAK,UAAM,IAAI,UAAU,gCAAgC;AACtE,MAAIA,UAAS,OAAO,CAAC;AAAG,UAAM,IAAI,UAAU,+CAA+C;AAC3F,MAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,IAAI,QAAQ;AAAG,UAAM,IAAI,UAAU,yEAAyE;AAChL,SAAQA,UAAS,MAAM,EAAE,KAAK,UAAU,KAAK,IAAI,IAAI,EAAE,QAAQ,QAAQ,MAAM,IAAI,UAAU,KAAK,GAAI;AACxG;AACA,IAAIC,0BAAkE,SAAU,UAAU,OAAOD,OAAM,GAAG;AACtG,MAAIA,UAAS,OAAO,CAAC;AAAG,UAAM,IAAI,UAAU,+CAA+C;AAC3F,MAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,IAAI,QAAQ;AAAG,UAAM,IAAI,UAAU,0EAA0E;AACjL,SAAOA,UAAS,MAAM,IAAIA,UAAS,MAAM,EAAE,KAAK,QAAQ,IAAI,IAAI,EAAE,QAAQ,MAAM,IAAI,QAAQ;AAChG;AACA,IAAI;AAAJ,IAAgC;AAAhC,IAAuD;AAAvD,IAAoF;AAApF,IAAwH;AAAxH,IAAiJ;AAAjJ,IAA2K;AAA3K,IAAoM;AAApM,IAA2N;AAA3N,IAAqP;AAOrP,IAAM,iBAAiB;AAAA,EACnB,yBAAyB;AAC7B;AACO,IAAM,kBAAN,MAAsB;AAAA,EACzB,YAAY,MAAM,mBAAmB,SAAS;AAC1C,+BAA2B,IAAI,IAAI;AACnC,0BAAsB,IAAI,MAAM,MAAM;AACtC,gCAA4B,IAAI,MAAM,MAAM;AAC5C,uCAAmC,IAAI,MAAM,MAAM;AACnD,4BAAwB,IAAI,MAAM,IAAI,OAAO,CAAC,CAAC;AAC/C,6BAAyB,IAAI,MAAM,IAAI,YAAY,CAAC;AACpD,4BAAwB,IAAI,MAAM,MAAM;AACxC,0BAAsB,IAAI,MAAM,MAAM;AACtC,6BAAyB,IAAI,MAAM,MAAM;AACzC,QAAI,CAAC,WAAW,IAAI,GAAG;AACnB,YAAM,IAAI,UAAU,oDAAoD;AAAA,IAC5E;AACA,QAAI;AACJ,QAAI,sBAAc,iBAAiB,GAAG;AAClC,gBAAU;AAAA,IACd,OACK;AACD,iBAAW;AAAA,IACf;AACA,QAAI,CAAC,UAAU;AACX,iBAAW,uBAAe;AAAA,IAC9B;AACA,QAAI,OAAO,aAAa,UAAU;AAC9B,YAAM,IAAI,UAAU,4CAA4C;AAAA,IACpE;AACA,QAAI,WAAW,CAAC,sBAAc,OAAO,GAAG;AACpC,YAAM,IAAI,UAAU,4CAA4C;AAAA,IACpE;AACA,2BAAuB,MAAM,uBAAuB,MAAM,GAAG;AAC7D,2BAAuB,MAAM,0BAA0B,EAAE,GAAG,gBAAgB,GAAG,QAAQ,GAAG,GAAG;AAC7F,2BAAuB,MAAM,6BAA6BC,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAOA,wBAAuB,MAAM,uBAAuB,GAAG,CAAC,GAAG,GAAG;AAC3L,2BAAuB,MAAM,oCAAoCA,wBAAuB,MAAM,6BAA6B,GAAG,EAAE,YAAY,GAAG;AAC/I,SAAK,WAAW,sBAAsB,QAAQ;AAC9C,SAAK,cAAc,iCAAiC,KAAK,QAAQ;AACjE,2BAAuB,MAAM,yBAAyBA,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,GAAGA,wBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAG,KAAK,QAAQ,GAAGA,wBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAGA,wBAAuB,MAAM,uBAAuB,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG;AAChV,SAAK,gBAAgB,OAAO,KAAK,iBAAiB,CAAC;AACnD,SAAK,UAAU,OAAO,OAAO;AAAA,MACzB,gBAAgB,KAAK;AAAA,MACrB,kBAAkB,KAAK;AAAA,IAC3B,CAAC;AACD,WAAO,iBAAiB,MAAM;AAAA,MAC1B,UAAU,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACjD,aAAa,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACpD,eAAe,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACtD,SAAS,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,IACpD,CAAC;AAAA,EACL;AAAA,EACA,mBAAmB;AACf,QAAI,SAAS;AACb,eAAW,CAAC,MAAM,GAAG,KAAKA,wBAAuB,MAAM,uBAAuB,GAAG,GAAG;AAChF,YAAM,QAAQ,WAAW,GAAG,IAAI,MAAMA,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,uBAAU,GAAG,CAAC;AACvH,gBAAUA,wBAAuB,MAAM,4BAA4B,KAAK,+BAA+B,EAAE,KAAK,MAAM,MAAM,KAAK,EAAE;AACjI,gBAAU,WAAW,KAAK,IAAI,MAAM,OAAO,MAAM;AACjD,gBAAUA,wBAAuB,MAAM,oCAAoC,GAAG;AAAA,IAClF;AACA,WAAO,SAASA,wBAAuB,MAAM,yBAAyB,GAAG,EAAE;AAAA,EAC/E;AAAA,EACA,CAAC,SAAS;AACN,eAAW,CAAC,MAAM,GAAG,KAAKA,wBAAuB,MAAM,uBAAuB,GAAG,EAAE,QAAQ,GAAG;AAC1F,YAAM,QAAQ,WAAW,GAAG,IAAI,MAAMA,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,uBAAU,GAAG,CAAC;AACvH,YAAMA,wBAAuB,MAAM,4BAA4B,KAAK,+BAA+B,EAAE,KAAK,MAAM,MAAM,KAAK;AAC3H,YAAM;AACN,YAAMA,wBAAuB,MAAM,6BAA6B,GAAG;AAAA,IACvE;AACA,UAAMA,wBAAuB,MAAM,yBAAyB,GAAG;AAAA,EACnE;AAAA,EACA,OAAO,SAAS;AACZ,eAAW,QAAQ,KAAK,OAAO,GAAG;AAC9B,UAAI,WAAW,IAAI,GAAG;AAClB,eAAO,KAAK,OAAO;AAAA,MACvB,OACK;AACD,cAAM;AAAA,MACV;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,EAAE,wBAAwB,oBAAI,QAAQ,GAAG,8BAA8B,oBAAI,QAAQ,GAAG,qCAAqC,oBAAI,QAAQ,GAAG,0BAA0B,oBAAI,QAAQ,GAAG,2BAA2B,oBAAI,QAAQ,GAAG,0BAA0B,oBAAI,QAAQ,GAAG,wBAAwB,oBAAI,QAAQ,GAAG,2BAA2B,oBAAI,QAAQ,GAAG,6BAA6B,oBAAI,QAAQ,GAAG,kCAAkC,SAASC,iCAAgC,MAAM,OAAO;AACvd,QAAI,SAAS;AACb,cAAU,GAAGD,wBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAG,KAAK,QAAQ,GAAGA,wBAAuB,MAAM,uBAAuB,GAAG,CAAC;AAClJ,cAAU,yCAAyC,mBAAO,IAAI,CAAC;AAC/D,QAAI,WAAW,KAAK,GAAG;AACnB,gBAAU,eAAe,mBAAO,MAAM,IAAI,CAAC,IAAIA,wBAAuB,MAAM,uBAAuB,GAAG,CAAC;AACvG,gBAAU,iBAAiB,MAAM,QAAQ,0BAA0B;AAAA,IACvE;AACA,QAAIA,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,4BAA4B,MAAM;AAC9F,gBAAU,GAAGA,wBAAuB,MAAM,uBAAuB,GAAG,CAAC,mBAAmB,WAAW,KAAK,IAAI,MAAM,OAAO,MAAM,UAAU;AAAA,IAC7I;AACA,WAAOA,wBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,GAAG,MAAM,GAAGA,wBAAuB,MAAM,uBAAuB,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE;AAAA,EAC9J,GAAG,OAAO,SAAS,IAAI;AACnB,WAAO,KAAK,OAAO;AAAA,EACvB;AAAA,EACA,CAAC,OAAO,aAAa,IAAI;AACrB,WAAO,KAAK,OAAO;AAAA,EACvB;AACJ;;;SR1GS,gBAAgB;;;ASRnB,IAAO,gBAAP,MAAoB;EACxB,YAAmB,MAAS;AAAT,SAAA,OAAA;EAAY;EAC/B,KAAK,OAAO,WAAW,IAAC;AACtB,WAAO;EACT;;;;6BTU6B;AAI/B,IAAI,qBAAqB;AASzB,eAAeE,cAAa,SAAiB,MAAW;AAEtD,QAAM,EAAE,cAAc,cAAa,IAAK,MAAM,OAAO,6BAA8B;AAEnF,MAAI,CAAC,oBAAoB;AACvB,YAAQ,KAAK,uDAAuD,KAAK,UAAU,IAAI,CAAC,WAAW;AACnG,yBAAqB;;AAGvB,SAAO,MAAM,cAAc,MAAM,GAAG,IAAI;AAC1C;AAEA,IAAM,mBAA0B,IAAI,sBAAAC,QAAe,EAAE,WAAW,MAAM,SAAS,IAAI,KAAK,IAAI,CAAE;AAC9F,IAAM,oBAA2B,IAAI,sBAAAA,QAAe,WAAW,EAAE,WAAW,MAAM,SAAS,IAAI,KAAK,IAAI,CAAE;AAE1G,eAAeC,4BACb,MACA,MAAuB;AAEvB,QAAM,UAAU,IAAI,gBAAgB,IAAI;AACxC,QAAM,WAAW,SAAS,KAAK,OAAO;AACtC,QAAM,OAAO,IAAI,cAAc,QAAQ;AACvC,QAAM,UAAU;IACd,GAAG,KAAK;IACR,GAAG,QAAQ;IACX,kBAAkB,QAAQ;;AAG5B,SAAO,EAAE,GAAG,MAAM,MAAmB,QAAO;AAC9C;AAEM,SAAU,aAAU;AAExB,MAAI,OAAO,oBAAoB,aAAa;AAE1C,eAAW,kBAAkB,wBAAAC;;AAE/B,SAAO;IACL,MAAM;IACN,OAAU;IACV;IACA;IACA;IACA,UAAaC;IACb;IACA;IACA;IACA,4BAAAF;IACA,iBAAiB,CAAC,QAAwB,IAAI,WAAW,OAAO,IAAI,oBAAoB;IACxF,cAAAF;IACA,gBAAgB,CAAC,UAAsC,iBAAiB;;AAE5E;;;AU7EA,IAAI,CAAO;AAAM,EAAM,SAAc,WAAW,GAAG,EAAE,MAAM,KAAK,CAAC;;;ACLjE;;;;;;;;;;;;;;;;AAIM,IAAO,cAAP,cAA2B,MAAK;;AAEhC,IAAO,WAAP,MAAO,kBAAiB,YAAW;EAWvC,YACE,QACA,OACA,SACA,SAA4B;AAE5B,UAAM,GAAG,UAAS,YAAY,QAAQ,OAAO,OAAO,CAAC,EAAE;AACvD,SAAK,SAAS;AACd,SAAK,UAAU;AACf,SAAK,aAAa,UAAU,cAAc;AAE1C,UAAM,OAAO;AACb,SAAK,QAAQ;AACb,SAAK,OAAO,OAAO,MAAM;AACzB,SAAK,QAAQ,OAAO,OAAO;AAC3B,SAAK,OAAO,OAAO,MAAM;EAC3B;EAEQ,OAAO,YAAY,QAA4B,OAAY,SAA2B;AAC5F,UAAM,MACJ,OAAO,UACL,OAAO,MAAM,YAAY,WACvB,MAAM,UACN,KAAK,UAAU,MAAM,OAAO,IAC9B,QAAQ,KAAK,UAAU,KAAK,IAC5B;AAEJ,QAAI,UAAU,KAAK;AACjB,aAAO,GAAG,MAAM,IAAI,GAAG;;AAEzB,QAAI,QAAQ;AACV,aAAO,GAAG,MAAM;;AAElB,QAAI,KAAK;AACP,aAAO;;AAET,WAAO;EACT;EAEA,OAAO,SACL,QACA,eACA,SACA,SAA4B;AAE5B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI,mBAAmB,EAAE,OAAO,YAAY,aAAa,EAAC,CAAE;;AAGrE,UAAM,QAAS,gBAAwC,OAAO;AAE9D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,gBAAgB,QAAQ,OAAO,SAAS,OAAO;;AAG5D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,sBAAsB,QAAQ,OAAO,SAAS,OAAO;;AAGlE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,yBAAyB,QAAQ,OAAO,SAAS,OAAO;;AAGrE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,eAAe,QAAQ,OAAO,SAAS,OAAO;;AAG3D,QAAI,UAAU,KAAK;AACjB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,WAAO,IAAI,UAAS,QAAQ,OAAO,SAAS,OAAO;EACrD;;AAGI,IAAO,oBAAP,cAAiC,SAAQ;EAG7C,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,QAAW,QAAW,WAAW,wBAAwB,MAAS;AAHxD,SAAA,SAAoB;EAItC;;AAGI,IAAO,qBAAP,cAAkC,SAAQ;EAG9C,YAAY,EAAE,SAAS,MAAK,GAAmD;AAC7E,UAAM,QAAW,QAAW,WAAW,qBAAqB,MAAS;AAHrD,SAAA,SAAoB;AAMpC,QAAI;AAAO,WAAK,QAAQ;EAC1B;;AAGI,IAAO,4BAAP,cAAyC,mBAAkB;EAC/D,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,EAAE,SAAS,WAAW,qBAAoB,CAAE;EACpD;;AAGI,IAAO,kBAAP,cAA+B,SAAQ;EAA7C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;EAAjD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,wBAAP,cAAqC,SAAQ;EAAnD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,2BAAP,cAAwC,SAAQ;EAAtD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,iBAAP,cAA8B,SAAQ;EAA5C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;;;;AChJ3C,IAAO,SAAP,MAAO,QAAM;EAGjB,YACU,UACR,YAA2B;AADnB,SAAA,WAAA;AAGR,SAAK,aAAa;EACpB;EAEA,OAAO,gBAAsB,UAAoB,YAA2B;AAC1E,QAAI,WAAW;AAEf,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,OAAO,iBAAiB,UAAU,UAAU,GAAG;AAC9D,cAAI;AAAM;AAEV,cAAI,IAAI,KAAK,WAAW,QAAQ,GAAG;AACjC,mBAAO;AACP;;AAGF,cAAI,IAAI,UAAU,MAAM;AACtB,gBAAI;AAEJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,QAAQ,KAAK,OAAO;AACtB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,QAAW,MAAS;;AAGhE,kBAAM;iBACD;AACL,gBAAI;AACJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,IAAI,SAAS,SAAS;AACxB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,KAAK,SAAS,MAAS;;AAEnE,kBAAM,EAAE,OAAO,IAAI,OAAO,KAAU;;;AAGxC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;;;;;EAMA,OAAO,mBAAyB,gBAAgC,YAA2B;AACzF,QAAI,WAAW;AAEf,oBAAgB,YAAS;AACvB,YAAM,cAAc,IAAI,YAAW;AAEnC,YAAM,OAAO,4BAAmC,cAAc;AAC9D,uBAAiB,SAAS,MAAM;AAC9B,mBAAW,QAAQ,YAAY,OAAO,KAAK,GAAG;AAC5C,gBAAM;;;AAIV,iBAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,cAAM;;IAEV;AAEA,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,QAAQ,UAAS,GAAI;AACpC,cAAI;AAAM;AACV,cAAI;AAAM,kBAAM,KAAK,MAAM,IAAI;;AAEjC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;EAEA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,SAAQ;EACtB;;;;;EAMA,MAAG;AACD,UAAM,OAA6C,CAAA;AACnD,UAAM,QAA8C,CAAA;AACpD,UAAM,WAAW,KAAK,SAAQ;AAE9B,UAAM,cAAc,CAAC,UAAoE;AACvF,aAAO;QACL,MAAM,MAAK;AACT,cAAI,MAAM,WAAW,GAAG;AACtB,kBAAM,SAAS,SAAS,KAAI;AAC5B,iBAAK,KAAK,MAAM;AAChB,kBAAM,KAAK,MAAM;;AAEnB,iBAAO,MAAM,MAAK;QACpB;;IAEJ;AAEA,WAAO;MACL,IAAI,QAAO,MAAM,YAAY,IAAI,GAAG,KAAK,UAAU;MACnD,IAAI,QAAO,MAAM,YAAY,KAAK,GAAG,KAAK,UAAU;;EAExD;;;;;;EAOA,mBAAgB;AACd,UAAMK,QAAO;AACb,QAAI;AACJ,UAAM,UAAU,IAAI,YAAW;AAE/B,WAAO,IAAI,eAAe;MACxB,MAAM,QAAK;AACT,eAAOA,MAAK,OAAO,aAAa,EAAC;MACnC;MACA,MAAM,KAAK,MAAS;AAClB,YAAI;AACF,gBAAM,EAAE,OAAO,KAAI,IAAK,MAAM,KAAK,KAAI;AACvC,cAAI;AAAM,mBAAO,KAAK,MAAK;AAE3B,gBAAM,QAAQ,QAAQ,OAAO,KAAK,UAAU,KAAK,IAAI,IAAI;AAEzD,eAAK,QAAQ,KAAK;iBACX,KAAK;AACZ,eAAK,MAAM,GAAG;;MAElB;MACA,MAAM,SAAM;AACV,cAAM,KAAK,SAAQ;MACrB;KACD;EACH;;AAGF,gBAAuB,iBACrB,UACA,YAA2B;AAE3B,MAAI,CAAC,SAAS,MAAM;AAClB,eAAW,MAAK;AAChB,UAAM,IAAI,YAAY,mDAAmD;;AAG3E,QAAM,aAAa,IAAI,WAAU;AACjC,QAAM,cAAc,IAAI,YAAW;AAEnC,QAAM,OAAO,4BAAmC,SAAS,IAAI;AAC7D,mBAAiB,YAAY,cAAc,IAAI,GAAG;AAChD,eAAW,QAAQ,YAAY,OAAO,QAAQ,GAAG;AAC/C,YAAM,MAAM,WAAW,OAAO,IAAI;AAClC,UAAI;AAAK,cAAM;;;AAInB,aAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,UAAM,MAAM,WAAW,OAAO,IAAI;AAClC,QAAI;AAAK,YAAM;;AAEnB;AAMA,gBAAgB,cAAc,UAAsC;AAClE,MAAI,OAAO,IAAI,WAAU;AAEzB,mBAAiB,SAAS,UAAU;AAClC,QAAI,SAAS,MAAM;AACjB;;AAGF,UAAM,cACJ,iBAAiB,cAAc,IAAI,WAAW,KAAK,IACjD,OAAO,UAAU,WAAW,IAAI,YAAW,EAAG,OAAO,KAAK,IAC1D;AAEJ,QAAI,UAAU,IAAI,WAAW,KAAK,SAAS,YAAY,MAAM;AAC7D,YAAQ,IAAI,IAAI;AAChB,YAAQ,IAAI,aAAa,KAAK,MAAM;AACpC,WAAO;AAEP,QAAI;AACJ,YAAQ,eAAe,uBAAuB,IAAI,OAAO,IAAI;AAC3D,YAAM,KAAK,MAAM,GAAG,YAAY;AAChC,aAAO,KAAK,MAAM,YAAY;;;AAIlC,MAAI,KAAK,SAAS,GAAG;AACnB,UAAM;;AAEV;AAEA,SAAS,uBAAuB,QAAkB;AAIhD,QAAM,UAAU;AAChB,QAAM,WAAW;AAEjB,WAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAC1C,QAAI,OAAO,CAAC,MAAM,WAAW,OAAO,IAAI,CAAC,MAAM,SAAS;AAEtD,aAAO,IAAI;;AAEb,QAAI,OAAO,CAAC,MAAM,YAAY,OAAO,IAAI,CAAC,MAAM,UAAU;AAExD,aAAO,IAAI;;AAEb,QACE,OAAO,CAAC,MAAM,YACd,OAAO,IAAI,CAAC,MAAM,WAClB,IAAI,IAAI,OAAO,UACf,OAAO,IAAI,CAAC,MAAM,YAClB,OAAO,IAAI,CAAC,MAAM,SAClB;AAEA,aAAO,IAAI;;;AAIf,SAAO;AACT;AAEA,IAAM,aAAN,MAAgB;EAKd,cAAA;AACE,SAAK,QAAQ;AACb,SAAK,OAAO,CAAA;AACZ,SAAK,SAAS,CAAA;EAChB;EAEA,OAAO,MAAY;AACjB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,aAAO,KAAK,UAAU,GAAG,KAAK,SAAS,CAAC;;AAG1C,QAAI,CAAC,MAAM;AAET,UAAI,CAAC,KAAK,SAAS,CAAC,KAAK,KAAK;AAAQ,eAAO;AAE7C,YAAM,MAAuB;QAC3B,OAAO,KAAK;QACZ,MAAM,KAAK,KAAK,KAAK,IAAI;QACzB,KAAK,KAAK;;AAGZ,WAAK,QAAQ;AACb,WAAK,OAAO,CAAA;AACZ,WAAK,SAAS,CAAA;AAEd,aAAO;;AAGT,SAAK,OAAO,KAAK,IAAI;AAErB,QAAI,KAAK,WAAW,GAAG,GAAG;AACxB,aAAO;;AAGT,QAAI,CAAC,WAAW,GAAG,KAAK,IAAI,UAAU,MAAM,GAAG;AAE/C,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,cAAQ,MAAM,UAAU,CAAC;;AAG3B,QAAI,cAAc,SAAS;AACzB,WAAK,QAAQ;eACJ,cAAc,QAAQ;AAC/B,WAAK,KAAK,KAAK,KAAK;;AAGtB,WAAO;EACT;;AASF,IAAM,cAAN,MAAM,aAAW;EASf,cAAA;AACE,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;EACpB;EAEA,OAAO,OAAY;AACjB,QAAI,OAAO,KAAK,WAAW,KAAK;AAEhC,QAAI,KAAK,YAAY;AACnB,aAAO,OAAO;AACd,WAAK,aAAa;;AAEpB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,WAAK,aAAa;AAClB,aAAO,KAAK,MAAM,GAAG,EAAE;;AAGzB,QAAI,CAAC,MAAM;AACT,aAAO,CAAA;;AAGT,UAAM,kBAAkB,aAAY,cAAc,IAAI,KAAK,KAAK,SAAS,CAAC,KAAK,EAAE;AACjF,QAAI,QAAQ,KAAK,MAAM,aAAY,cAAc;AAIjD,QAAI,iBAAiB;AACnB,YAAM,IAAG;;AAGX,QAAI,MAAM,WAAW,KAAK,CAAC,iBAAiB;AAC1C,WAAK,OAAO,KAAK,MAAM,CAAC,CAAE;AAC1B,aAAO,CAAA;;AAGT,QAAI,KAAK,OAAO,SAAS,GAAG;AAC1B,cAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,IAAI,MAAM,CAAC,GAAG,GAAG,MAAM,MAAM,CAAC,CAAC;AAC3D,WAAK,SAAS,CAAA;;AAGhB,QAAI,CAAC,iBAAiB;AACpB,WAAK,SAAS,CAAC,MAAM,IAAG,KAAM,EAAE;;AAGlC,WAAO;EACT;EAEA,WAAW,OAAY;AACrB,QAAI,SAAS;AAAM,aAAO;AAC1B,QAAI,OAAO,UAAU;AAAU,aAAO;AAGtC,QAAI,OAAO,WAAW,aAAa;AACjC,UAAI,iBAAiB,QAAQ;AAC3B,eAAO,MAAM,SAAQ;;AAEvB,UAAI,iBAAiB,YAAY;AAC/B,eAAO,OAAO,KAAK,KAAK,EAAE,SAAQ;;AAGpC,YAAM,IAAI,YACR,wCAAwC,MAAM,YAAY,IAAI,mIAAmI;;AAKrM,QAAI,OAAO,gBAAgB,aAAa;AACtC,UAAI,iBAAiB,cAAc,iBAAiB,aAAa;AAC/D,aAAK,gBAAL,KAAK,cAAgB,IAAI,YAAY,MAAM;AAC3C,eAAO,KAAK,YAAY,OAAO,KAAK;;AAGtC,YAAM,IAAI,YACR,oDACG,MAAc,YAAY,IAC7B,gDAAgD;;AAIpD,UAAM,IAAI,YACR,gGAAgG;EAEpG;EAEA,QAAK;AACH,QAAI,CAAC,KAAK,OAAO,UAAU,CAAC,KAAK,YAAY;AAC3C,aAAO,CAAA;;AAGT,UAAM,QAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,CAAC;AACnC,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;AAClB,WAAO;EACT;;AApGO,YAAA,gBAAgB,oBAAI,IAAI,CAAC,MAAM,IAAI,CAAC;AACpC,YAAA,iBAAiB;AAiH1B,SAAS,UAAUC,MAAa,WAAiB;AAC/C,QAAM,QAAQA,KAAI,QAAQ,SAAS;AACnC,MAAI,UAAU,IAAI;AAChB,WAAO,CAACA,KAAI,UAAU,GAAG,KAAK,GAAG,WAAWA,KAAI,UAAU,QAAQ,UAAU,MAAM,CAAC;;AAGrF,SAAO,CAACA,MAAK,IAAI,EAAE;AACrB;AAQM,SAAU,4BAA+B,QAAW;AACxD,MAAI,OAAO,OAAO,aAAa;AAAG,WAAO;AAEzC,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO;IACL,MAAM,OAAI;AACR,UAAI;AACF,cAAM,SAAS,MAAM,OAAO,KAAI;AAChC,YAAI,QAAQ;AAAM,iBAAO,YAAW;AACpC,eAAO;eACA,GAAG;AACV,eAAO,YAAW;AAClB,cAAM;;IAEV;IACA,MAAM,SAAM;AACV,YAAM,gBAAgB,OAAO,OAAM;AACnC,aAAO,YAAW;AAClB,YAAM;AACN,aAAO,EAAE,MAAM,MAAM,OAAO,OAAS;IACvC;IACA,CAAC,OAAO,aAAa,IAAC;AACpB,aAAO;IACT;;AAEJ;;;AC/bO,IAAM,iBAAiB,CAAC,UAC7B,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,QAAQ,YACrB,OAAO,MAAM,SAAS;AAEjB,IAAMC,cAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,iBAAiB,YAC9B,WAAW,KAAK;AAMX,IAAM,aAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,cACtB,OAAO,MAAM,UAAU,cACvB,OAAO,MAAM,gBAAgB;AAExB,IAAM,eAAe,CAAC,UAAmC;AAC9D,SAAOA,YAAW,KAAK,KAAK,eAAe,KAAK,KAAK,eAAe,KAAK;AAC3E;AAaA,eAAsB,OACpB,OACA,MACA,SAAqC;AAGrC,UAAQ,MAAM;AAGd,cAAA,UAAYA,YAAW,KAAK,IAAI,EAAE,cAAc,MAAM,cAAc,MAAM,MAAM,KAAI,IAAK,CAAA;AAEzF,MAAI,eAAe,KAAK,GAAG;AACzB,UAAM,OAAO,MAAM,MAAM,KAAI;AAC7B,aAAA,OAAS,IAAI,IAAI,MAAM,GAAG,EAAE,SAAS,MAAM,OAAO,EAAE,IAAG,KAAM;AAE7D,WAAO,IAAIC,MAAK,CAAC,IAAW,GAAG,MAAM,OAAO;;AAG9C,QAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,WAAA,OAAS,QAAQ,KAAK,KAAK;AAE3B,MAAI,CAAC,QAAQ,MAAM;AACjB,UAAM,OAAQ,KAAK,CAAC,GAAW;AAC/B,QAAI,OAAO,SAAS,UAAU;AAC5B,gBAAU,EAAE,GAAG,SAAS,KAAI;;;AAIhC,SAAO,IAAIA,MAAK,MAAM,MAAM,OAAO;AACrC;AAEA,eAAe,SAAS,OAAkB;AACxC,MAAI,QAAyB,CAAA;AAC7B,MACE,OAAO,UAAU,YACjB,YAAY,OAAO,KAAK;EACxB,iBAAiB,aACjB;AACA,UAAM,KAAK,KAAK;aACP,WAAW,KAAK,GAAG;AAC5B,UAAM,KAAK,MAAM,MAAM,YAAW,CAAE;aAEpC,wBAAwB,KAAK,GAC7B;AACA,qBAAiB,SAAS,OAAO;AAC/B,YAAM,KAAK,KAAiB;;SAEzB;AACL,UAAM,IAAI,MACR,yBAAyB,OAAO,KAAK,kBAAkB,OAAO,aAC1D,IAAI,YAAY,cAAc,KAAK,CAAC,EAAE;;AAI9C,SAAO;AACT;AAEA,SAAS,cAAc,OAAU;AAC/B,QAAM,QAAQ,OAAO,oBAAoB,KAAK;AAC9C,SAAO,IAAI,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,IAAI,CAAC;AAClD;AAEA,SAAS,QAAQ,OAAU;AACzB,SACE,yBAAyB,MAAM,IAAI,KACnC,yBAAyB,MAAM,QAAQ;EAEvC,yBAAyB,MAAM,IAAI,GAAG,MAAM,OAAO,EAAE,IAAG;AAE5D;AAEA,IAAM,2BAA2B,CAAC,MAAoD;AACpF,MAAI,OAAO,MAAM;AAAU,WAAO;AAClC,MAAI,OAAO,WAAW,eAAe,aAAa;AAAQ,WAAO,OAAO,CAAC;AACzE,SAAO;AACT;AAEA,IAAM,0BAA0B,CAAC,UAC/B,SAAS,QAAQ,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,aAAa,MAAM;AAEhF,IAAM,kBAAkB,CAAC,SAC9B,QAAQ,OAAO,SAAS,YAAY,KAAK,QAAQ,KAAK,OAAO,WAAW,MAAM;AAezE,IAAM,8BAA8B,OACzC,SAC8C;AAC9C,QAAM,OAAO,MAAM,WAAW,KAAK,IAAI;AACvC,SAAO,2BAA2B,MAAM,IAAI;AAC9C;AAEO,IAAM,aAAa,OAAoC,SAA0C;AACtG,QAAM,OAAO,IAAI,SAAQ;AACzB,QAAM,QAAQ,IAAI,OAAO,QAAQ,QAAQ,CAAA,CAAE,EAAE,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,aAAa,MAAM,KAAK,KAAK,CAAC,CAAC;AAClG,SAAO;AACT;AAaA,IAAM,eAAe,OAAO,MAAgB,KAAa,UAAiC;AACxF,MAAI,UAAU;AAAW;AACzB,MAAI,SAAS,MAAM;AACjB,UAAM,IAAI,UACR,sBAAsB,GAAG,6DAA6D;;AAK1F,MAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,SAAK,OAAO,KAAK,OAAO,KAAK,CAAC;aACrB,aAAa,KAAK,GAAG;AAC9B,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,SAAK,OAAO,KAAK,IAAY;aACpB,MAAM,QAAQ,KAAK,GAAG;AAC/B,UAAM,QAAQ,IAAI,MAAM,IAAI,CAAC,UAAU,aAAa,MAAM,MAAM,MAAM,KAAK,CAAC,CAAC;aACpE,OAAO,UAAU,UAAU;AACpC,UAAM,QAAQ,IACZ,OAAO,QAAQ,KAAK,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM,aAAa,MAAM,GAAG,GAAG,IAAI,IAAI,KAAK,IAAI,CAAC,CAAC;SAErF;AACL,UAAM,IAAI,UACR,wGAAwG,KAAK,UAAU;;AAG7H;;;;;;;;;;;;;;;;;;;;AChNA,eAAe,qBAAwB,OAAuB;AAC5D,QAAM,EAAE,SAAQ,IAAK;AACrB,MAAI,MAAM,QAAQ,QAAQ;AACxB,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,SAAS,IAAI;AAKhF,QAAI,MAAM,QAAQ,eAAe;AAC/B,aAAO,MAAM,QAAQ,cAAc,gBAAgB,UAAU,MAAM,UAAU;;AAG/E,WAAO,OAAO,gBAAgB,UAAU,MAAM,UAAU;;AAI1D,MAAI,SAAS,WAAW,KAAK;AAC3B,WAAO;;AAGT,MAAI,MAAM,QAAQ,kBAAkB;AAClC,WAAO;;AAGT,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,QAAM,SACJ,aAAa,SAAS,kBAAkB,KAAK,aAAa,SAAS,0BAA0B;AAC/F,MAAI,QAAQ;AACV,UAAM,OAAO,MAAM,SAAS,KAAI;AAEhC,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAEvE,WAAO;;AAGT,QAAM,OAAO,MAAM,SAAS,KAAI;AAChC,QAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAGvE,SAAO;AACT;AAMM,IAAO,aAAP,MAAO,oBAAsB,QAAU;EAG3C,YACU,iBACA,gBAAgE,sBAAoB;AAE5F,UAAM,CAAC,YAAW;AAIhB,cAAQ,IAAW;IACrB,CAAC;AARO,SAAA,kBAAA;AACA,SAAA,gBAAA;EAQV;EAEA,YAAe,WAAyB;AACtC,WAAO,IAAI,YAAW,KAAK,iBAAiB,OAAO,UAAU,UAAU,MAAM,KAAK,cAAc,KAAK,CAAC,CAAC;EACzG;;;;;;;;;;;;;;EAeA,aAAU;AACR,WAAO,KAAK,gBAAgB,KAAK,CAAC,MAAM,EAAE,QAAQ;EACpD;;;;;;;;;;;;;;EAcA,MAAM,eAAY;AAChB,UAAM,CAAC,MAAM,QAAQ,IAAI,MAAM,QAAQ,IAAI,CAAC,KAAK,MAAK,GAAI,KAAK,WAAU,CAAE,CAAC;AAC5E,WAAO,EAAE,MAAM,SAAQ;EACzB;EAEQ,QAAK;AACX,QAAI,CAAC,KAAK,eAAe;AACvB,WAAK,gBAAgB,KAAK,gBAAgB,KAAK,KAAK,aAAa;;AAEnE,WAAO,KAAK;EACd;EAES,KACP,aACA,YAAmF;AAEnF,WAAO,KAAK,MAAK,EAAG,KAAK,aAAa,UAAU;EAClD;EAES,MACP,YAAiF;AAEjF,WAAO,KAAK,MAAK,EAAG,MAAM,UAAU;EACtC;EAES,QAAQ,WAA2C;AAC1D,WAAO,KAAK,MAAK,EAAG,QAAQ,SAAS;EACvC;;AAGI,IAAgB,YAAhB,MAAyB;EAS7B,YAAY;IACV;IACA,aAAa;IACb,UAAU;;IACV;IACA,OAAO;EAAc,GAOtB;AACC,SAAK,UAAU;AACf,SAAK,aAAa,wBAAwB,cAAc,UAAU;AAClE,SAAK,UAAU,wBAAwB,WAAW,OAAO;AACzD,SAAK,YAAY;AAEjB,SAAK,QAAQ,kBAAkB;EACjC;EAEU,YAAY,MAAyB;AAC7C,WAAO,CAAA;EACT;;;;;;;;;EAUU,eAAe,MAAyB;AAChD,WAAO;MACL,QAAQ;MACR,gBAAgB;MAChB,cAAc,KAAK,aAAY;MAC/B,GAAG,mBAAkB;MACrB,GAAG,KAAK,YAAY,IAAI;;EAE5B;;;;EAOU,gBAAgB,SAAkB,eAAsB;EAAG;EAE3D,wBAAqB;AAC7B,WAAO,wBAAwB,MAAK,CAAE;EACxC;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,KAAe,MAAc,MAA0C;AACrE,WAAO,KAAK,cAAc,QAAQ,MAAM,IAAI;EAC9C;EAEA,MAAgB,MAAc,MAA0C;AACtE,WAAO,KAAK,cAAc,SAAS,MAAM,IAAI;EAC/C;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,OAAiB,MAAc,MAA0C;AACvE,WAAO,KAAK,cAAc,UAAU,MAAM,IAAI;EAChD;EAEQ,cACN,QACA,MACA,MAA0C;AAE1C,WAAO,KAAK,QACV,QAAQ,QAAQ,IAAI,EAAE,KAAK,OAAOC,UAAQ;AACxC,YAAM,OACJA,SAAQ,WAAWA,OAAM,IAAI,IAAI,IAAI,SAAS,MAAMA,MAAK,KAAK,YAAW,CAAE,IACzEA,OAAM,gBAAgB,WAAWA,MAAK,OACtCA,OAAM,gBAAgB,cAAc,IAAI,SAASA,MAAK,IAAI,IAC1DA,SAAQ,YAAY,OAAOA,OAAM,IAAI,IAAI,IAAI,SAASA,MAAK,KAAK,MAAM,IACtEA,OAAM;AACV,aAAO,EAAE,QAAQ,MAAM,GAAGA,OAAM,KAAI;IACtC,CAAC,CAAC;EAEN;EAEA,WACE,MACAC,OACA,MAA0B;AAE1B,WAAO,KAAK,eAAeA,OAAM,EAAE,QAAQ,OAAO,MAAM,GAAG,KAAI,CAAE;EACnE;EAEQ,uBAAuB,MAAa;AAC1C,QAAI,OAAO,SAAS,UAAU;AAC5B,UAAI,OAAO,WAAW,aAAa;AACjC,eAAO,OAAO,WAAW,MAAM,MAAM,EAAE,SAAQ;;AAGjD,UAAI,OAAO,gBAAgB,aAAa;AACtC,cAAM,UAAU,IAAI,YAAW;AAC/B,cAAM,UAAU,QAAQ,OAAO,IAAI;AACnC,eAAO,QAAQ,OAAO,SAAQ;;eAEvB,YAAY,OAAO,IAAI,GAAG;AACnC,aAAO,KAAK,WAAW,SAAQ;;AAGjC,WAAO;EACT;EAEA,aAAkB,SAAiC;AACjD,UAAM,EAAE,QAAQ,MAAM,OAAO,UAAmB,CAAA,EAAE,IAAK;AAEvD,UAAM,OACJ,YAAY,OAAO,QAAQ,IAAI,KAAM,QAAQ,mBAAmB,OAAO,QAAQ,SAAS,WACtF,QAAQ,OACR,gBAAgB,QAAQ,IAAI,IAAI,QAAQ,KAAK,OAC7C,QAAQ,OAAO,KAAK,UAAU,QAAQ,MAAM,MAAM,CAAC,IACnD;AACJ,UAAM,gBAAgB,KAAK,uBAAuB,IAAI;AAEtD,UAAM,MAAM,KAAK,SAAS,MAAO,KAAK;AACtC,QAAI,aAAa;AAAS,8BAAwB,WAAW,QAAQ,OAAO;AAC5E,UAAM,UAAU,QAAQ,WAAW,KAAK;AACxC,UAAM,YAAY,QAAQ,aAAa,KAAK,aAAa,gBAAgB,GAAG;AAC5E,UAAM,kBAAkB,UAAU;AAClC,QACE,OAAQ,WAAmB,SAAS,YAAY,YAChD,mBAAoB,UAAkB,QAAQ,WAAW,IACzD;AAKC,gBAAkB,QAAQ,UAAU;;AAGvC,QAAI,KAAK,qBAAqB,WAAW,OAAO;AAC9C,UAAI,CAAC,QAAQ;AAAgB,gBAAQ,iBAAiB,KAAK,sBAAqB;AAChF,cAAQ,KAAK,iBAAiB,IAAI,QAAQ;;AAG5C,UAAM,aAAa,KAAK,aAAa,EAAE,SAAS,SAAS,cAAa,CAAE;AAExE,UAAM,MAAmB;MACvB;MACA,GAAI,QAAQ,EAAE,KAAiB;MAC/B,SAAS;MACT,GAAI,aAAa,EAAE,OAAO,UAAS;;;MAGnC,QAAQ,QAAQ,UAAU;;AAG5B,WAAO,EAAE,KAAK,KAAK,QAAO;EAC5B;EAEQ,aAAa,EACnB,SACA,SACA,cAAa,GAKd;AACC,UAAM,aAAqC,CAAA;AAC3C,QAAI,eAAe;AACjB,iBAAW,gBAAgB,IAAI;;AAGjC,UAAM,iBAAiB,KAAK,eAAe,OAAO;AAClD,oBAAgB,YAAY,cAAc;AAC1C,oBAAgB,YAAY,OAAO;AAGnC,QAAI,gBAAgB,QAAQ,IAAI,KAAK,SAAc,QAAQ;AACzD,aAAO,WAAW,cAAc;;AAGlC,SAAK,gBAAgB,YAAY,OAAO;AAExC,WAAO;EACT;;;;EAKU,MAAM,eAAe,SAA4B;EAAkB;;;;;;;EAQnE,MAAM,eACd,SACA,EAAE,KAAK,QAAO,GAAiD;EAC/C;EAER,aAAa,SAAuC;AAC5D,WACE,CAAC,UAAU,CAAA,IACT,OAAO,YAAY,UACnB,OAAO,YAAY,MAAM,KAAK,OAA6B,EAAE,IAAI,CAAC,WAAW,CAAC,GAAG,MAAM,CAAC,CAAC,IACzF,EAAE,GAAG,QAAO;EAElB;EAEU,gBACR,QACA,OACA,SACA,SAA4B;AAE5B,WAAO,SAAS,SAAS,QAAQ,OAAO,SAAS,OAAO;EAC1D;EAEA,QACE,SACA,mBAAkC,MAAI;AAEtC,WAAO,IAAI,WAAW,KAAK,YAAY,SAAS,gBAAgB,CAAC;EACnE;EAEQ,MAAM,YACZ,cACA,kBAA+B;AAE/B,UAAM,UAAU,MAAM;AACtB,QAAI,oBAAoB,MAAM;AAC5B,yBAAmB,QAAQ,cAAc,KAAK;;AAGhD,UAAM,KAAK,eAAe,OAAO;AAEjC,UAAM,EAAE,KAAK,KAAK,QAAO,IAAK,KAAK,aAAa,OAAO;AAEvD,UAAM,KAAK,eAAe,KAAK,EAAE,KAAK,QAAO,CAAE;AAE/C,UAAM,WAAW,KAAK,SAAS,IAAI,OAAO;AAE1C,QAAI,QAAQ,QAAQ,SAAS;AAC3B,YAAM,IAAI,kBAAiB;;AAG7B,UAAM,aAAa,IAAI,gBAAe;AACtC,UAAM,WAAW,MAAM,KAAK,iBAAiB,KAAK,KAAK,SAAS,UAAU,EAAE,MAAM,WAAW;AAE7F,QAAI,oBAAoB,OAAO;AAC7B,UAAI,QAAQ,QAAQ,SAAS;AAC3B,cAAM,IAAI,kBAAiB;;AAE7B,UAAI,kBAAkB;AACpB,eAAO,KAAK,aAAa,SAAS,gBAAgB;;AAEpD,UAAI,SAAS,SAAS,cAAc;AAClC,cAAM,IAAI,0BAAyB;;AAErC,YAAM,IAAI,mBAAmB,EAAE,OAAO,SAAQ,CAAE;;AAGlD,UAAM,kBAAkB,sBAAsB,SAAS,OAAO;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,oBAAoB,KAAK,YAAY,QAAQ,GAAG;AAClD,cAAMC,gBAAe,aAAa,gBAAgB;AAClD,cAAM,oBAAoBA,aAAY,KAAK,SAAS,QAAQ,KAAK,eAAe;AAChF,eAAO,KAAK,aAAa,SAAS,kBAAkB,eAAe;;AAGrE,YAAM,UAAU,MAAM,SAAS,KAAI,EAAG,MAAM,CAAC,MAAM,YAAY,CAAC,EAAE,OAAO;AACzE,YAAM,UAAU,SAAS,OAAO;AAChC,YAAM,aAAa,UAAU,SAAY;AACzC,YAAM,eAAe,mBAAmB,kCAAkC;AAE1E,YAAM,oBAAoB,YAAY,KAAK,SAAS,QAAQ,KAAK,iBAAiB,UAAU;AAE5F,YAAM,MAAM,KAAK,gBAAgB,SAAS,QAAQ,SAAS,YAAY,eAAe;AACtF,YAAM;;AAGR,WAAO,EAAE,UAAU,SAAS,WAAU;EACxC;EAEA,eACED,OACA,SAA4B;AAE5B,UAAM,UAAU,KAAK,YAAY,SAAS,IAAI;AAC9C,WAAO,IAAI,YAA6B,MAAM,SAASA,KAAI;EAC7D;EAEA,SAAc,MAAc,OAA6B;AACvD,UAAM,MACJ,cAAc,IAAI,IAChB,IAAI,IAAI,IAAI,IACZ,IAAI,IAAI,KAAK,WAAW,KAAK,QAAQ,SAAS,GAAG,KAAK,KAAK,WAAW,GAAG,IAAI,KAAK,MAAM,CAAC,IAAI,KAAK;AAEtG,UAAM,eAAe,KAAK,aAAY;AACtC,QAAI,CAAC,WAAW,YAAY,GAAG;AAC7B,cAAQ,EAAE,GAAG,cAAc,GAAG,MAAK;;AAGrC,QAAI,OAAO,UAAU,YAAY,SAAS,CAAC,MAAM,QAAQ,KAAK,GAAG;AAC/D,UAAI,SAAS,KAAK,eAAe,KAAgC;;AAGnE,WAAO,IAAI,SAAQ;EACrB;EAEU,eAAe,OAA8B;AACrD,WAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,OAAO,UAAU,WAAW,EACnD,IAAI,CAAC,CAAC,KAAK,KAAK,MAAK;AACpB,UAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,eAAO,GAAG,mBAAmB,GAAG,CAAC,IAAI,mBAAmB,KAAK,CAAC;;AAEhE,UAAI,UAAU,MAAM;AAClB,eAAO,GAAG,mBAAmB,GAAG,CAAC;;AAEnC,YAAM,IAAI,YACR,yBAAyB,OAAO,KAAK,mQAAmQ;IAE5S,CAAC,EACA,KAAK,GAAG;EACb;EAEA,MAAM,iBACJ,KACA,MACA,IACA,YAA2B;AAE3B,UAAM,EAAE,QAAQ,GAAG,QAAO,IAAK,QAAQ,CAAA;AACvC,QAAI;AAAQ,aAAO,iBAAiB,SAAS,MAAM,WAAW,MAAK,CAAE;AAErE,UAAM,UAAU,WAAW,MAAM,WAAW,MAAK,GAAI,EAAE;AAEvD,WACE,KAAK,iBAAgB,EAElB,MAAM,KAAK,QAAW,KAAK,EAAE,QAAQ,WAAW,QAAe,GAAG,QAAO,CAAE,EAC3E,QAAQ,MAAK;AACZ,mBAAa,OAAO;IACtB,CAAC;EAEP;EAEU,mBAAgB;AACxB,WAAO,EAAE,OAAO,KAAK,MAAK;EAC5B;EAEQ,YAAY,UAAkB;AAEpC,UAAM,oBAAoB,SAAS,QAAQ,IAAI,gBAAgB;AAG/D,QAAI,sBAAsB;AAAQ,aAAO;AACzC,QAAI,sBAAsB;AAAS,aAAO;AAG1C,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,UAAU;AAAK,aAAO;AAEnC,WAAO;EACT;EAEQ,MAAM,aACZ,SACA,kBACA,iBAAqC;AAErC,QAAI;AAGJ,UAAM,yBAAyB,kBAAkB,gBAAgB;AACjE,QAAI,wBAAwB;AAC1B,YAAM,YAAY,WAAW,sBAAsB;AACnD,UAAI,CAAC,OAAO,MAAM,SAAS,GAAG;AAC5B,wBAAgB;;;AAKpB,UAAM,mBAAmB,kBAAkB,aAAa;AACxD,QAAI,oBAAoB,CAAC,eAAe;AACtC,YAAM,iBAAiB,WAAW,gBAAgB;AAClD,UAAI,CAAC,OAAO,MAAM,cAAc,GAAG;AACjC,wBAAgB,iBAAiB;aAC5B;AACL,wBAAgB,KAAK,MAAM,gBAAgB,IAAI,KAAK,IAAG;;;AAM3D,QAAI,EAAE,iBAAiB,KAAK,iBAAiB,gBAAgB,KAAK,MAAO;AACvE,YAAM,aAAa,QAAQ,cAAc,KAAK;AAC9C,sBAAgB,KAAK,mCAAmC,kBAAkB,UAAU;;AAEtF,UAAM,MAAM,aAAa;AAEzB,WAAO,KAAK,YAAY,SAAS,mBAAmB,CAAC;EACvD;EAEQ,mCAAmC,kBAA0B,YAAkB;AACrF,UAAM,oBAAoB;AAC1B,UAAM,gBAAgB;AAEtB,UAAM,aAAa,aAAa;AAGhC,UAAM,eAAe,KAAK,IAAI,oBAAoB,KAAK,IAAI,GAAG,UAAU,GAAG,aAAa;AAGxF,UAAM,SAAS,IAAI,KAAK,OAAM,IAAK;AAEnC,WAAO,eAAe,SAAS;EACjC;EAEQ,eAAY;AAClB,WAAO,GAAG,KAAK,YAAY,IAAI,OAAO,OAAO;EAC/C;;AAKI,IAAgB,eAAhB,MAA4B;EAOhC,YAAY,QAAmB,UAAoB,MAAe,SAA4B;AAN9F,yBAAA,IAAA,MAAA,MAAA;AAOE,IAAAE,wBAAA,MAAI,sBAAW,QAAM,GAAA;AACrB,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,OAAO;EACd;EAUA,cAAW;AACT,UAAM,QAAQ,KAAK,kBAAiB;AACpC,QAAI,CAAC,MAAM;AAAQ,aAAO;AAC1B,WAAO,KAAK,aAAY,KAAM;EAChC;EAEA,MAAM,cAAW;AACf,UAAM,WAAW,KAAK,aAAY;AAClC,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YACR,uFAAuF;;AAG3F,UAAM,cAAc,EAAE,GAAG,KAAK,QAAO;AACrC,QAAI,YAAY,YAAY,OAAO,YAAY,UAAU,UAAU;AACjE,kBAAY,QAAQ,EAAE,GAAG,YAAY,OAAO,GAAG,SAAS,OAAM;eACrD,SAAS,UAAU;AAC5B,YAAM,SAAS,CAAC,GAAG,OAAO,QAAQ,YAAY,SAAS,CAAA,CAAE,GAAG,GAAG,SAAS,IAAI,aAAa,QAAO,CAAE;AAClG,iBAAW,CAAC,KAAK,KAAK,KAAK,QAAQ;AACjC,iBAAS,IAAI,aAAa,IAAI,KAAK,KAAY;;AAEjD,kBAAY,QAAQ;AACpB,kBAAY,OAAO,SAAS,IAAI,SAAQ;;AAE1C,WAAO,MAAMC,wBAAA,MAAI,sBAAA,GAAA,EAAS,eAAe,KAAK,aAAoB,WAAW;EAC/E;EAEA,OAAO,YAAS;AAEd,QAAI,OAA2B;AAC/B,UAAM;AACN,WAAO,KAAK,YAAW,GAAI;AACzB,aAAO,MAAM,KAAK,YAAW;AAC7B,YAAM;;EAEV;EAEA,SAAO,uBAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AAC3B,qBAAiB,QAAQ,KAAK,UAAS,GAAI;AACzC,iBAAW,QAAQ,KAAK,kBAAiB,GAAI;AAC3C,cAAM;;;EAGZ;;AAYI,IAAO,cAAP,cAII,WAAqB;EAG7B,YACE,QACA,SACAH,OAA4E;AAE5E,UACE,SACA,OAAO,UAAU,IAAIA,MAAK,QAAQ,MAAM,UAAU,MAAM,qBAAqB,KAAK,GAAG,MAAM,OAAO,CAAC;EAEvG;;;;;;;;EASA,QAAQ,OAAO,aAAa,IAAC;AAC3B,UAAM,OAAO,MAAM;AACnB,qBAAiB,QAAQ,MAAM;AAC7B,YAAM;;EAEV;;AAGK,IAAM,wBAAwB,CACnC,YAC0B;AAC1B,SAAO,IAAI,MACT,OAAO;;IAEL,QAAQ,QAAO;EAAE,GAEnB;IACE,IAAI,QAAQ,MAAI;AACd,YAAM,MAAM,KAAK,SAAQ;AACzB,aAAO,OAAO,IAAI,YAAW,CAAE,KAAK,OAAO,GAAG;IAChD;GACD;AAEL;AAiCA,IAAM,qBAA+C;EACnD,QAAQ;EACR,MAAM;EACN,OAAO;EACP,MAAM;EACN,SAAS;EAET,YAAY;EACZ,QAAQ;EACR,SAAS;EACT,WAAW;EACX,QAAQ;EACR,gBAAgB;EAEhB,iBAAiB;EACjB,kBAAkB;EAClB,eAAe;;AAGV,IAAM,mBAAmB,CAAC,QAAuC;AACtE,SACE,OAAO,QAAQ,YACf,QAAQ,QACR,CAAC,WAAW,GAAG,KACf,OAAO,KAAK,GAAG,EAAE,MAAM,CAAC,MAAM,OAAO,oBAAoB,CAAC,CAAC;AAE/D;AA8BA,IAAM,wBAAwB,MAAyB;AACrD,MAAI,OAAO,SAAS,eAAe,KAAK,SAAS,MAAM;AACrD,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,KAAK,MAAM,EAAE;MACjD,oBAAoB,cAAc,KAAK,MAAM,IAAI;MACjD,uBAAuB;MACvB,+BACE,OAAO,KAAK,YAAY,WAAW,KAAK,UAAU,KAAK,SAAS,QAAQ;;;AAG9E,MAAI,OAAO,gBAAgB,aAAa;AACtC,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB,SAAS,WAAW;MACxC,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,MAAI,OAAO,UAAU,SAAS,KAAK,OAAO,YAAY,cAAc,UAAU,CAAC,MAAM,oBAAoB;AACvG,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,QAAQ,QAAQ;MACpD,oBAAoB,cAAc,QAAQ,IAAI;MAC9C,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,QAAM,cAAc,eAAc;AAClC,MAAI,aAAa;AACf,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB;MACpB,uBAAuB,WAAW,YAAY,OAAO;MACrD,+BAA+B,YAAY;;;AAK/C,SAAO;IACL,oBAAoB;IACpB,+BAA+B;IAC/B,kBAAkB;IAClB,oBAAoB;IACpB,uBAAuB;IACvB,+BAA+B;;AAEnC;AAUA,SAAS,iBAAc;AACrB,MAAI,OAAO,cAAc,eAAe,CAAC,WAAW;AAClD,WAAO;;AAIT,QAAM,kBAAkB;IACtB,EAAE,KAAK,QAAiB,SAAS,uCAAsC;IACvE,EAAE,KAAK,MAAe,SAAS,uCAAsC;IACrE,EAAE,KAAK,MAAe,SAAS,6CAA4C;IAC3E,EAAE,KAAK,UAAmB,SAAS,yCAAwC;IAC3E,EAAE,KAAK,WAAoB,SAAS,0CAAyC;IAC7E,EAAE,KAAK,UAAmB,SAAS,oEAAmE;;AAIxG,aAAW,EAAE,KAAK,QAAO,KAAM,iBAAiB;AAC9C,UAAM,QAAQ,QAAQ,KAAK,UAAU,SAAS;AAC9C,QAAI,OAAO;AACT,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAE1B,aAAO,EAAE,SAAS,KAAK,SAAS,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,GAAE;;;AAIhE,SAAO;AACT;AAEA,IAAM,gBAAgB,CAAC,SAAsB;AAK3C,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,YAAY,SAAS;AAAO,WAAO;AAChD,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,aAAa,SAAS;AAAS,WAAO;AACnD,MAAI;AAAM,WAAO,SAAS,IAAI;AAC9B,SAAO;AACT;AAEA,IAAM,oBAAoB,CAAC,aAAkC;AAO3D,aAAW,SAAS,YAAW;AAM/B,MAAI,SAAS,SAAS,KAAK;AAAG,WAAO;AACrC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAU,WAAO;AAClC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI;AAAU,WAAO,SAAS,QAAQ;AACtC,SAAO;AACT;AAEA,IAAI;AACJ,IAAM,qBAAqB,MAAK;AAC9B,SAAQ,qBAAA,mBAAqB,sBAAqB;AACpD;AAEO,IAAM,WAAW,CAAC,SAAgB;AACvC,MAAI;AACF,WAAO,KAAK,MAAM,IAAI;WACf,KAAK;AACZ,WAAO;;AAEX;AAGA,IAAM,yBAAyB,IAAI,OAAO,mBAAmB,GAAG;AAChE,IAAM,gBAAgB,CAAC,QAAwB;AAC7C,SAAO,uBAAuB,KAAK,GAAG;AACxC;AAEO,IAAM,QAAQ,CAAC,OAAe,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC;AAErF,IAAM,0BAA0B,CAAC,MAAc,MAAsB;AACnE,MAAI,OAAO,MAAM,YAAY,CAAC,OAAO,UAAU,CAAC,GAAG;AACjD,UAAM,IAAI,YAAY,GAAG,IAAI,qBAAqB;;AAEpD,MAAI,IAAI,GAAG;AACT,UAAM,IAAI,YAAY,GAAG,IAAI,6BAA6B;;AAE5D,SAAO;AACT;AAEO,IAAM,cAAc,CAAC,QAAmB;AAC7C,MAAI,eAAe;AAAO,WAAO;AACjC,SAAO,IAAI,MAAM,GAAG;AACtB;AAcO,IAAM,UAAU,CAAC,QAAmC;AACzD,MAAI,OAAO,YAAY,aAAa;AAClC,WAAO,QAAQ,MAAM,GAAG,GAAG,KAAI,KAAM;;AAEvC,MAAI,OAAO,SAAS,aAAa;AAC/B,WAAO,KAAK,KAAK,MAAM,GAAG,GAAG,KAAI;;AAEnC,SAAO;AACT;AA4CM,SAAU,WAAW,KAA8B;AACvD,MAAI,CAAC;AAAK,WAAO;AACjB,aAAW,MAAM;AAAK,WAAO;AAC7B,SAAO;AACT;AAGM,SAAU,OAAO,KAAa,KAAW;AAC7C,SAAO,OAAO,UAAU,eAAe,KAAK,KAAK,GAAG;AACtD;AAQA,SAAS,gBAAgB,eAAwB,YAAmB;AAClE,aAAW,KAAK,YAAY;AAC1B,QAAI,CAAC,OAAO,YAAY,CAAC;AAAG;AAC5B,UAAM,WAAW,EAAE,YAAW;AAC9B,QAAI,CAAC;AAAU;AAEf,UAAM,MAAM,WAAW,CAAC;AAExB,QAAI,QAAQ,MAAM;AAChB,aAAO,cAAc,QAAQ;eACpB,QAAQ,QAAW;AAC5B,oBAAc,QAAQ,IAAI;;;AAGhC;AAEM,SAAU,MAAM,WAAmB,MAAW;AAClD,MAAI,OAAO,YAAY,eAAe,SAAS,MAAM,OAAO,MAAM,QAAQ;AACxE,YAAQ,IAAI,gBAAgB,MAAM,IAAI,GAAG,IAAI;;AAEjD;AAKA,IAAM,QAAQ,MAAK;AACjB,SAAO,uCAAuC,QAAQ,SAAS,CAAC,MAAK;AACnE,UAAM,IAAK,KAAK,OAAM,IAAK,KAAM;AACjC,UAAM,IAAI,MAAM,MAAM,IAAK,IAAI,IAAO;AACtC,WAAO,EAAE,SAAS,EAAE;EACtB,CAAC;AACH;AAEO,IAAM,qBAAqB,MAAK;AACrC;;IAEE,OAAO,WAAW;IAElB,OAAO,OAAO,aAAa;IAE3B,OAAO,cAAc;;AAEzB;AAwDM,SAAU,MAAM,KAAY;AAChC,SAAO,OAAO,QAAQ,OAAO,QAAQ,YAAY,CAAC,MAAM,QAAQ,GAAG;AACrE;;;AC/oCM,IAAO,OAAP,cAA0B,aAAkB;EAKhD,YAAY,QAAmB,UAAoB,MAA0B,SAA4B;AACvG,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;AACzB,SAAK,SAAS,KAAK;EACrB;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;;;;;EAOA,iBAAc;AACZ,WAAO;EACT;EAEA,eAAY;AACV,WAAO;EACT;;AAaI,IAAO,aAAP,cACI,aAAkB;EAK1B,YACE,QACA,UACA,MACA,SAA4B;AAE5B,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;EAC3B;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;EAGA,iBAAc;AACZ,UAAM,OAAO,KAAK,aAAY;AAC9B,QAAI,CAAC;AAAM,aAAO;AAClB,QAAI,YAAY;AAAM,aAAO,KAAK;AAClC,UAAM,SAAS,OAAO,YAAY,KAAK,IAAI,YAAY;AACvD,QAAI,CAAC,OAAO,KAAK,MAAM,EAAE;AAAQ,aAAO;AACxC,WAAO;EACT;EAEA,eAAY;AACV,UAAM,OAAO,KAAK,kBAAiB;AACnC,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;;AAGT,UAAM,KAAK,KAAK,KAAK,SAAS,CAAC,GAAG;AAClC,QAAI,CAAC,IAAI;AACP,aAAO;;AAGT,WAAO,EAAE,QAAQ,EAAE,OAAO,GAAE,EAAE;EAChC;;;;AC5FI,IAAO,cAAP,MAAkB;EAGtB,YAAY,QAAc;AACxB,SAAK,UAAU;EACjB;;;;ACEI,IAAO,cAAP,cAA2B,YAAW;EAgB1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAGlG;;AAy6BF,0BAAiBI,cAAW;AA+B5B,GA/BiB,gBAAA,cAAW,CAAA,EAAA;;;ACr8BtB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EACvF;;CAyBA,SAAiBC,OAAI;AAEL,EAAAA,MAAA,cAA6B;AA+B7C,GAjCiB,SAAA,OAAI,CAAA,EAAA;;;AC1Bf,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,OAAO,MAA0B,SAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,iBAAiB,EAAE,MAAM,GAAG,SAAS,kBAAkB,KAAI,CAAE;EACxF;;AAoCF,0BAAiBC,SAAM;AAEvB,GAFiB,WAAA,SAAM,CAAA,EAAA;;;AC1CjB,IAAO,iBAAP,cAA8B,YAAW;;;;EAI7C,OAAO,MAAiC,SAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,yBAAyB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACrG;;AAmEF,0BAAiBC,iBAAc;AAG/B,GAHiB,mBAAA,iBAAc,CAAA,EAAA;;;ACzEzB,IAAO,eAAP,cAA4B,YAAW;;;;EAI3C,OAAO,MAA+B,SAA6B;AACjE,WAAO,KAAK,QAAQ,KAAK,uBAAuB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACnG;;AA4CF,0BAAiBC,eAAY;AAG7B,GAHiB,iBAAA,eAAY,CAAA,EAAA;;;AClDvB,IAAO,QAAP,cAAqB,YAAW;EAAtC,cAAA;;AACE,SAAA,iBAAmD,IAAsB,eAAe,KAAK,OAAO;AACpG,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,SAA2B,IAAc,OAAO,KAAK,OAAO;EAC9D;;CAEA,SAAiBC,QAAK;AACN,EAAAA,OAAA,iBAAmC;AAGnC,EAAAA,OAAA,eAA+B;AAG/B,EAAAA,OAAA,SAAmB;AAEnC,GATiB,UAAA,QAAK,CAAA,EAAA;;;ACLhB,IAAO,UAAP,cAAuB,YAAW;;;;EAItC,OAAO,MAAyB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,YAAY,EAAE,MAAM,GAAG,QAAO,CAAE;EAC3D;;;;EAKA,SAAS,SAAiB,SAA6B;AACrD,WAAO,KAAK,QAAQ,IAAI,YAAY,OAAO,IAAI,OAAO;EACxD;EAOA,KACE,QAA+C,CAAA,GAC/C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,YAAY,aAAa,EAAE,OAAO,GAAG,QAAO,CAAE;EAC/E;;;;;;EAOA,OAAO,SAAiB,SAA6B;AACnD,WAAO,KAAK,QAAQ,KAAK,YAAY,OAAO,WAAW,OAAO;EAChE;;AAGI,IAAO,cAAP,cAA2B,WAAiB;;CAsMlD,SAAiBC,UAAO;AAIR,EAAAA,SAAA,cAAyB;AAGzC,GAPiB,YAAA,UAAO,CAAA,EAAA;;;ACzOlB,IAAO,aAAP,cAA0B,YAAW;;;;EAIzC,OAAO,MAA6B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,eAAe;MACtC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,aAAqB,SAA6B;AACzD,WAAO,KAAK,QAAQ,IAAI,eAAe,WAAW,IAAI;MACpD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,aACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,WAAW,IAAI;MACrD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,eAAe,gBAAgB;MAC5D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,aAAqB,SAA6B;AACpD,WAAO,KAAK,QAAQ,OAAO,eAAe,WAAW,IAAI;MACvD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,iBAAP,cAA8B,WAAqB;;CAkyCzD,SAAiBC,aAAU;AAYX,EAAAA,YAAA,iBAA+B;AAI/C,GAhBiB,eAAA,aAAU,CAAA,EAAA;;;ACxyCrB,SAAU,4BACd,IAAO;AAEP,SAAO,OAAQ,GAAW,UAAU;AACtC;;;AC1EO,IAAM,qBAAqB,CAChC,YACkD;AAClD,SAAO,SAAS,SAAS;AAC3B;AAEO,IAAM,oBAAoB,CAC/B,YACiD;AACjD,SAAO,SAAS,SAAS;AAC3B;AAEO,IAAM,gBAAgB,CAC3B,YAC6C;AAC7C,SAAO,SAAS,SAAS;AAC3B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA,IAAM,+BAA+B;AAM/B,IAAgB,+BAAhB,MAA4C;EAuBhD,cAAA;;AApBA,SAAA,aAA8B,IAAI,gBAAe;AAEjD,mDAAA,IAAA,MAAA,MAAA;AACA,0DAAA,IAAA,MAAuC,MAAK;IAAE,CAAC;AAC/C,yDAAA,IAAA,MAAwD,MAAK;IAAE,CAAC;AAEhE,6CAAA,IAAA,MAAA,MAAA;AACA,oDAAA,IAAA,MAAiC,MAAK;IAAE,CAAC;AACzC,mDAAA,IAAA,MAAkD,MAAK;IAAE,CAAC;AAE1D,4CAAA,IAAA,MAA6E,CAAA,CAAE;AAErE,SAAA,mBAAqC,CAAA;AAC/C,SAAA,WAAyC,CAAA;AAEzC,wCAAA,IAAA,MAAS,KAAK;AACd,0CAAA,IAAA,MAAW,KAAK;AAChB,0CAAA,IAAA,MAAW,KAAK;AAChB,yDAAA,IAAA,MAA0B,KAAK;AAuR/B,8CAAA,IAAA,MAAe,CAAC,UAAkB;AAChC,MAAAC,wBAAA,MAAI,uCAAY,MAAI,GAAA;AACpB,UAAI,iBAAiB,SAAS,MAAM,SAAS,cAAc;AACzD,gBAAQ,IAAI,kBAAiB;;AAE/B,UAAI,iBAAiB,mBAAmB;AACtC,QAAAA,wBAAA,MAAI,uCAAY,MAAI,GAAA;AACpB,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,aAAa;AAChC,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,OAAO;AAC1B,cAAM,cAA2B,IAAI,YAAY,MAAM,OAAO;AAE9D,oBAAY,QAAQ;AACpB,eAAO,KAAK,MAAM,SAAS,WAAW;;AAExC,aAAO,KAAK,MAAM,SAAS,IAAI,YAAY,OAAO,KAAK,CAAC,CAAC;IAC3D,CAAC;AAvSC,IAAAA,wBAAA,MAAI,gDAAqB,IAAI,QAAc,CAAC,SAAS,WAAU;AAC7D,MAAAA,wBAAA,MAAI,uDAA4B,SAAO,GAAA;AACvC,MAAAA,wBAAA,MAAI,sDAA2B,QAAM,GAAA;IACvC,CAAC,GAAC,GAAA;AAEF,IAAAA,wBAAA,MAAI,0CAAe,IAAI,QAAc,CAAC,SAAS,WAAU;AACvD,MAAAA,wBAAA,MAAI,iDAAsB,SAAO,GAAA;AACjC,MAAAA,wBAAA,MAAI,gDAAqB,QAAM,GAAA;IACjC,CAAC,GAAC,GAAA;AAMF,IAAAC,wBAAA,MAAI,gDAAA,GAAA,EAAmB,MAAM,MAAK;IAAE,CAAC;AACrC,IAAAA,wBAAA,MAAI,0CAAA,GAAA,EAAa,MAAM,MAAK;IAAE,CAAC;EACjC;EAEU,KAAK,UAA4B;AAGzC,eAAW,MAAK;AACd,eAAQ,EAAG,KAAK,MAAK;AACnB,aAAK,WAAU;AACf,aAAK,MAAM,KAAK;MAClB,GAAGA,wBAAA,MAAI,2CAAA,GAAA,CAAa;IACtB,GAAG,CAAC;EACN;EAEU,mBAAmB,gBAA8B;AACzD,SAAK,iBAAiB,KAAK,cAAc;AACzC,SAAK,MAAM,kBAAkB,cAAc;AAC3C,UAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,QAAI;AAAS,WAAK,YAAY,OAAqC;AACnE,WAAO;EACT;EAEU,YAAY,SAAqC,OAAO,MAAI;AACpE,QAAI,EAAE,aAAa;AAAU,cAAQ,UAAU;AAE/C,SAAK,SAAS,KAAK,OAAO;AAE1B,QAAI,MAAM;AACR,WAAK,MAAM,WAAW,OAAO;AAC7B,WAAK,kBAAkB,OAAO,KAAK,cAAc,OAAO,MAAM,QAAQ,SAAS;AAE7E,aAAK,MAAM,sBAAsB,QAAQ,OAAiB;iBACjD,mBAAmB,OAAO,KAAK,QAAQ,eAAe;AAC/D,aAAK,MAAM,gBAAgB,QAAQ,aAAa;iBACvC,mBAAmB,OAAO,KAAK,QAAQ,YAAY;AAC5D,mBAAW,aAAa,QAAQ,YAAY;AAC1C,cAAI,UAAU,SAAS,YAAY;AACjC,iBAAK,MAAM,gBAAgB,UAAU,QAAQ;;;;;EAKvD;EAEU,aAAU;AAClB,QAAI,KAAK;AAAO;AAChB,IAAAA,wBAAA,MAAI,uDAAA,GAAA,EAAyB,KAA7B,IAAI;AACJ,SAAK,MAAM,SAAS;EACtB;EAEA,IAAI,QAAK;AACP,WAAOA,wBAAA,MAAI,qCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,uCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,uCAAA,GAAA;EACb;EAEA,QAAK;AACH,SAAK,WAAW,MAAK;EACvB;;;;;;;;EASA,GAA+B,OAAc,UAAyC;AACpF,UAAM,YACJA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,SAAQ,CAAE;AAC3B,WAAO;EACT;;;;;;;;EASA,IAAgC,OAAc,UAAyC;AACrF,UAAM,YAAYA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK;AACvC,QAAI,CAAC;AAAW,aAAO;AACvB,UAAM,QAAQ,UAAU,UAAU,CAAC,MAAM,EAAE,aAAa,QAAQ;AAChE,QAAI,SAAS;AAAG,gBAAU,OAAO,OAAO,CAAC;AACzC,WAAO;EACT;;;;;;EAOA,KAAiC,OAAc,UAAyC;AACtF,UAAM,YACJA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,UAAU,MAAM,KAAI,CAAE;AACvC,WAAO;EACT;;;;;;;;;;;;EAaA,QACE,OAAY;AAMZ,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,MAAAD,wBAAA,MAAI,sDAA2B,MAAI,GAAA;AACnC,UAAI,UAAU;AAAS,aAAK,KAAK,SAAS,MAAM;AAChD,WAAK,KAAK,OAAO,OAAc;IACjC,CAAC;EACH;EAEA,MAAM,OAAI;AACR,IAAAA,wBAAA,MAAI,sDAA2B,MAAI,GAAA;AACnC,UAAMC,wBAAA,MAAI,0CAAA,GAAA;EACZ;;;;;EAMA,MAAM,sBAAmB;AACvB,UAAM,KAAK,KAAI;AACf,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI,CAAC;AAAY,YAAM,IAAI,YAAY,iDAAiD;AACxF,WAAO;EACT;;;;;EAUA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAsBA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAoBA,MAAM,oBAAiB;AACrB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;EACb;EAwBA,MAAM,0BAAuB;AAC3B,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;EACb;EAkBA,MAAM,aAAU;AACd,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI;EACb;EAEA,qBAAkB;AAChB,WAAO,CAAC,GAAG,KAAK,gBAAgB;EAClC;EAuBU,MAAkC,UAAiB,MAAoC;AAE/F,QAAIA,wBAAA,MAAI,qCAAA,GAAA,GAAS;AACf;;AAGF,QAAI,UAAU,OAAO;AACnB,MAAAD,wBAAA,MAAI,qCAAU,MAAI,GAAA;AAClB,MAAAC,wBAAA,MAAI,iDAAA,GAAA,EAAmB,KAAvB,IAAI;;AAGN,UAAM,YAA0DA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK;AACrF,QAAI,WAAW;AACb,MAAAA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,UAAU,OAAO,CAAC,MAAM,CAAC,EAAE,IAAI;AACxD,gBAAU,QAAQ,CAAC,EAAE,SAAQ,MAAY,SAAS,GAAG,IAAI,CAAC;;AAG5D,QAAI,UAAU,SAAS;AACrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,sDAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AACvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,sDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,gDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;AAChB;;AAGF,QAAI,UAAU,SAAS;AAGrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,sDAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AAOvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,sDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,gDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;;EAEpB;EAEU,aAAU;AAClB,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI;AAAY,WAAK,MAAM,uBAAuB,UAAU;AAC5D,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AACzD,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AAEzD,UAAM,oBAAoBA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;AAC9B,QAAI;AAAmB,WAAK,MAAM,qBAAqB,iBAAiB;AAExE,UAAM,0BAA0BA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;AACpC,QAAI,2BAA2B;AAAM,WAAK,MAAM,2BAA2B,uBAAuB;AAElG,QAAI,KAAK,iBAAiB,KAAK,CAAC,MAAM,EAAE,KAAK,GAAG;AAC9C,WAAK,MAAM,cAAcA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI,CAAuB;;EAExD;EAUU,MAAM,sBACd,aACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,yCAAA,KAAA,4CAAA,EAAgB,KAApB,MAAqB,MAAM;AAE3B,UAAM,iBAAiB,MAAM,YAAY,OACvC,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,mBAAmB,cAAc;EAC/C;EAEU,MAAM,mBACd,aACA,QACA,SAA6B;AAE7B,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAEjC,WAAO,MAAM,KAAK,sBAAsB,aAAa,QAAQ,OAAO;EACtE;EAEU,MAAM,cACd,aACA,QAGA,SAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,gBAAgB,QAAQ,QAAQ,GAAG,WAAU,IAAK;AAC1D,UAAM,uBAAuB,OAAO,kBAAkB,YAAY,eAAe;AACjF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,WAAW;AAChC,sBAAgB,EAAE,QAAQ,EAAE,SAAS,IAAI,IAAI;;AAG/C,UAAM,YAAmD,OAAO,UAAU,IACxE,CAAC,OAA4C;MAC3C,MAAM,EAAE,QAAQ,EAAE,SAAS;MAC3B,YAAY,EAAE;MACd,aAAa,EAAE;MACf;AAGJ,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,aACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ;AAAe;AAC5B,YAAM,EAAE,MAAM,WAAW,KAAI,IAAK,QAAQ;AAC1C,YAAM,KAAK,gBAAgB,IAAI;AAC/B,UAAI,CAAC,IAAI;AACP,cAAMC,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,4BAA4B,UACvF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC,EACjC,KAAK,IAAI,CAAC;AAEb,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;iBACS,wBAAwB,yBAAyB,MAAM;AAChE,cAAMA,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UACtE,oBAAoB,CACrB;AAED,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;;AAGF,UAAI;AACJ,UAAI;AACF,iBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;eAC3D,OAAO;AACd,aAAK,YAAY;UACf;UACA;UACA,SAAS,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;SAC/D;AACD;;AAIF,YAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,YAAM,UAAUD,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAE5D,WAAK,YAAY,EAAE,MAAM,MAAM,QAAO,CAAE;AAExC,UAAI;AAAsB;;EAE9B;EAEU,MAAM,UACd,aACA,QAGA,SAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,cAAc,QAAQ,QAAQ,GAAG,WAAU,IAAK;AACxD,UAAM,uBAAuB,OAAO,gBAAgB,YAAY,aAAa,UAAU;AACvF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,OAAO;AAC5B,UAAI,EAAE,SAAS,YAAY;AACzB,wBAAgB,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS,IAAI,IAAI,EAAE;;;AAIrE,UAAM,QACJ,WAAW,SACT,OAAO,MAAM,IAAI,CAAC,MAChB,EAAE,SAAS,aACT;MACE,MAAM;MACN,UAAU;QACR,MAAM,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS;QAC7C,YAAY,EAAE,SAAS;QACvB,aAAa,EAAE,SAAS;;QAG3B,CAAmC,IAEvC;AAEL,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,aACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ,YAAY;AACvB;;AAGF,iBAAW,aAAa,QAAQ,YAAY;AAC1C,YAAI,UAAU,SAAS;AAAY;AACnC,cAAM,eAAe,UAAU;AAC/B,cAAM,EAAE,MAAM,WAAW,KAAI,IAAK,UAAU;AAC5C,cAAM,KAAK,gBAAgB,IAAI;AAE/B,YAAI,CAAC,IAAI;AACP,gBAAMC,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,4BAA4B,MACnF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,SAAS,IAAI,CAAC,EAC1C,KAAK,IAAI,CAAC;AAEb,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;mBACS,wBAAwB,yBAAyB,MAAM;AAChE,gBAAMA,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UAClE,oBAAoB,CACrB;AAED,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAGF,YAAI;AACJ,YAAI;AACF,mBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;iBAC3D,OAAO;AACd,gBAAMA,WAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACrE,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAIF,cAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,cAAM,UAAUD,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAC5D,aAAK,YAAY,EAAE,MAAM,cAAc,QAAO,CAAE;AAEhD,YAAI,sBAAsB;AACxB;;;;AAKN;EACF;;;AAxaE,SAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI,EAAoB,WAAW;AAC5C,GAAC,gDAAA,SAAAE,iDAAA;AAYC,MAAI,IAAI,KAAK,SAAS;AACtB,SAAO,MAAM,GAAG;AACd,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,GAAG;AAC/B,YAAM,EAAE,eAAe,GAAG,KAAI,IAAK;AACnC,YAAM,MAA6B,EAAE,GAAG,MAAM,SAAS,QAAQ,WAAW,KAAI;AAC9E,UAAI,eAAe;AACjB,YAAI,gBAAgB;;AAEtB,aAAO;;;AAGX,QAAM,IAAI,YAAY,4EAA4E;AACpG,GAAC,qDAAA,SAAAC,sDAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,KAAK,SAAS,eAAe;AACzD,aAAO,QAAQ;;AAEjB,QAAI,mBAAmB,OAAO,KAAK,SAAS,YAAY,QAAQ;AAC9D,aAAO,QAAQ,WAAW,GAAG,EAAE,GAAG;;;AAItC;AACF,GAAC,2DAAA,SAAAC,4DAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,kBAAkB,OAAO,KAAK,QAAQ,WAAW,MAAM;AACzD,aAAO,QAAQ;;AAEjB,QACE,cAAc,OAAO,KACrB,QAAQ,WAAW,QACnB,KAAK,SAAS,KACZ,CAAC,MACC,EAAE,SAAS,eACX,EAAE,YAAY,KAAK,CAAC,MAAM,EAAE,SAAS,cAAc,EAAE,OAAO,QAAQ,YAAY,CAAC,GAErF;AACA,aAAO,QAAQ;;;AAInB;AACF,GAAC,oDAAA,SAAAC,qDAAA;AAQC,QAAM,QAAyB;IAC7B,mBAAmB;IACnB,eAAe;IACf,cAAc;;AAEhB,aAAW,EAAE,MAAK,KAAM,KAAK,kBAAkB;AAC7C,QAAI,OAAO;AACT,YAAM,qBAAqB,MAAM;AACjC,YAAM,iBAAiB,MAAM;AAC7B,YAAM,gBAAgB,MAAM;;;AAGhC,SAAO;AACT,GAAC,+CAAA,SAAAC,8CAkGe,QAAkC;AAChD,MAAI,OAAO,KAAK,QAAQ,OAAO,IAAI,GAAG;AACpC,UAAM,IAAI,YACR,8HAA8H;;AAGpI,GAAC,4DAAA,SAAAC,2DA6N4B,YAAmB;AAC9C,SACE,OAAO,eAAe,WAAW,aAC/B,eAAe,SAAY,cAC3B,KAAK,UAAU,UAAU;AAE/B;;;AC1mBI,IAAO,uBAAP,MAAO,8BAA6B,6BAAwD;;EAEhG,OAAO,aACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,aAAa,QAAQ,IAAI,CAAC;AACjE,WAAO;EACT;EAEA,OAAO,SACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,aAAa,QAAQ,IAAI,CAAC;AAC7D,WAAO;EACT;EAES,YAAY,SAAmC;AACtD,UAAM,YAAY,OAAO;AACzB,QAAI,mBAAmB,OAAO,KAAK,QAAQ,SAAS;AAClD,WAAK,MAAM,WAAW,QAAQ,OAAiB;;EAEnD;;;;;;;;;;;;;;;;;;;;;;;;;;ACzCI,IAAO,uBAAP,MAAO,8BACH,6BAAwD;EADlE,cAAA;;;AAIE,wDAAA,IAAA,MAAA,MAAA;EAsPF;EApPE,IAAI,gCAA6B;AAC/B,WAAOC,wBAAA,MAAI,qDAAA,GAAA;EACb;;;;;;;;EASA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,sBAAoB;AACvC,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEA,OAAO,qBACL,aACA,QACA,SAA6B;AAE7B,UAAM,SAAS,IAAI,sBAAoB;AACvC,WAAO,KAAK,MACV,OAAO,mBACL,aACA,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ,EAAE,CAAE,CACxF;AAEH,WAAO;EACT;EA4BmB,MAAM,sBACvB,aACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,UAAM,SAAS,MAAM,YAAY,OAC/B,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAEU,MAAM,oBACd,gBACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAwC,gBAAgB,KAAK,UAAU;AAC7F,QAAI;AACJ,qBAAiB,SAAS,QAAQ;AAChC,UAAI,UAAU,WAAW,MAAM,IAAI;AAEjC,aAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;;AAG5C,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;AACpB,eAAS,MAAM;;AAEjB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAqEA,EAAA,sDAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,qCAAA,SAAAC,sCAAA;AAjJE,QAAI,KAAK;AAAO;AAChB,IAAAC,wBAAA,MAAI,qDAAkC,QAAS,GAAA;EACjD,GAAC,iCAAA,SAAAC,gCACS,OAA0B;AAClC,QAAI,KAAK;AAAO;AAChB,UAAM,aAAaH,wBAAA,MAAI,iCAAA,KAAA,8CAAA,EAA0B,KAA9B,MAA+B,KAAK;AACvD,SAAK,MAAM,SAAS,OAAO,UAAU;AACrC,UAAM,QAAQ,MAAM,QAAQ,CAAC,GAAG,OAAO;AACvC,UAAM,WAAW,WAAW,QAAQ,CAAC,GAAG;AACxC,QAAI,SAAS,QAAQ,UAAU,SAAS,eAAe,UAAU,SAAS;AACxE,WAAK,MAAM,WAAW,OAAO,SAAS,OAAO;;EAEjD,GAAC,mCAAA,SAAAI,oCAAA;AAEC,QAAI,KAAK,OAAO;AACd,YAAM,IAAI,YAAY,yCAAyC;;AAEjE,UAAM,WAAWJ,wBAAA,MAAI,qDAAA,GAAA;AACrB,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YAAY,0CAA0C;;AAElE,IAAAE,wBAAA,MAAI,qDAAkC,QAAS,GAAA;AAC/C,WAAO,uBAAuB,QAAQ;EACxC,GAAC,iDAAA,SAAAG,gDAuDyB,OAA0B;;AAClD,QAAI,WAAWL,wBAAA,MAAI,qDAAA,GAAA;AACnB,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,QAAI,CAAC,UAAU;AACb,iBAAWE,wBAAA,MAAI,qDAAkC;QAC/C,GAAG;QACH,SAAS,CAAA;SACV,GAAA;WACI;AACL,aAAO,OAAO,UAAU,IAAI;;AAG9B,eAAW,EAAE,OAAO,eAAe,OAAO,WAAW,MAAM,GAAG,MAAK,KAAM,MAAM,SAAS;AACtF,UAAI,SAAS,SAAS,QAAQ,KAAK;AACnC,UAAI,CAAC,QAAQ;AACX,iBAAS,SAAS,QAAQ,KAAK,IAAI,EAAE,eAAe,OAAO,SAAS,CAAA,GAAI,UAAU,GAAG,MAAK;;AAG5F,UAAI,UAAU;AACZ,YAAI,CAAC,OAAO,UAAU;AACpB,iBAAO,WAAW,OAAO,OAAO,CAAA,GAAI,QAAQ;eACvC;AACL,gBAAM,EAAE,SAAAI,UAAS,GAAGC,MAAI,IAAK;AAC7B,iBAAO,OAAO,OAAO,UAAUA,KAAI;AACnC,cAAID,UAAS;AACX,aAAAE,MAAA,OAAO,UAAS,YAAOA,IAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGF,QAAO;;;;AAK7C,UAAI;AAAe,eAAO,gBAAgB;AAC1C,aAAO,OAAO,QAAQ,KAAK;AAE3B,UAAI,CAAC;AAAO;AACZ,YAAM,EAAE,SAAS,eAAe,MAAM,YAAY,GAAGC,MAAI,IAAK;AAC9D,aAAO,OAAO,OAAO,SAASA,KAAI;AAElC,UAAI;AAAS,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;AACvE,UAAI;AAAM,eAAO,QAAQ,OAAO;AAChC,UAAI,eAAe;AACjB,YAAI,CAAC,OAAO,QAAQ,eAAe;AACjC,iBAAO,QAAQ,gBAAgB;eAC1B;AACL,cAAI,cAAc;AAAM,mBAAO,QAAQ,cAAc,OAAO,cAAc;AAC1E,cAAI,cAAc,WAAW;AAC3B,aAAA,KAAA,OAAO,QAAQ,eAAc,cAAS,GAAT,YAAc;AAC3C,mBAAO,QAAQ,cAAc,aAAa,cAAc;;;;AAI9D,UAAI,YAAY;AACd,YAAI,CAAC,OAAO,QAAQ;AAAY,iBAAO,QAAQ,aAAa,CAAA;AAC5D,mBAAW,EAAE,OAAAE,QAAO,IAAI,MAAM,UAAU,IAAI,GAAGF,MAAI,KAAM,YAAY;AACnE,gBAAM,aAAY,KAAC,OAAO,QAAQ,YAAWE,MAAK,MAAA,GAALA,MAAK,IAAM,CAAA;AACxD,iBAAO,OAAO,WAAWF,KAAI;AAC7B,cAAI;AAAI,sBAAU,KAAK;AACvB,cAAI;AAAM,sBAAU,OAAO;AAC3B,cAAI;AAAI,sBAAU,aAAV,UAAU,WAAa,EAAE,WAAW,GAAE;AAC9C,cAAI,IAAI;AAAM,sBAAU,SAAU,OAAO,GAAG;AAC5C,cAAI,IAAI;AAAW,sBAAU,SAAU,aAAa,GAAG;;;;AAI7D,WAAO;EACT,GAEC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAmC,CAAA;AACzC,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAEX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,YAAyD;AAC7D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAAyC,CAAC,SAAS,WAC5D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACG,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC;MACA,QAAQ,YAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC;;EAEJ;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;;AAGF,SAAS,uBAAuB,UAAgC;AAC9D,QAAM,EAAE,IAAI,SAAS,SAAS,OAAO,oBAAoB,GAAG,KAAI,IAAK;AACrE,SAAO;IACL,GAAG;IACH;IACA,SAAS,QAAQ,IACf,CAAC,EAAE,SAAS,eAAe,OAAO,UAAU,GAAG,WAAU,MAA6B;AACpF,UAAI,CAAC;AAAe,cAAM,IAAI,YAAY,oCAAoC,KAAK,EAAE;AACrF,YAAM,EAAE,UAAU,MAAM,eAAe,YAAY,GAAG,YAAW,IAAK;AACtE,YAAM,OAAO,QAAQ;AACrB,UAAI,CAAC;AAAM,cAAM,IAAI,YAAY,2BAA2B,KAAK,EAAE;AACnE,UAAI,eAAe;AACjB,cAAM,EAAE,WAAW,MAAM,KAAI,IAAK;AAClC,YAAI,QAAQ;AAAM,gBAAM,IAAI,YAAY,8CAA8C,KAAK,EAAE;AAC7F,YAAI,CAAC;AAAM,gBAAM,IAAI,YAAY,yCAAyC,KAAK,EAAE;AACjF,eAAO;UACL,GAAG;UACH,SAAS,EAAE,SAAS,eAAe,EAAE,WAAW,MAAM,KAAI,GAAI,KAAI;UAClE;UACA;UACA;;;AAGJ,UAAI,YAAY;AACd,eAAO;UACL,GAAG;UACH;UACA;UACA;UACA,SAAS;YACP,GAAG;YACH;YACA;YACA,YAAY,WAAW,IAAI,CAAC,WAAW,MAAK;AAC1C,oBAAM,EAAE,UAAU,IAAI,MAAM,IAAAC,KAAI,GAAG,SAAQ,IAAK;AAChD,oBAAM,EAAE,WAAW,MAAM,MAAM,GAAG,OAAM,IAAK,MAAM,CAAA;AACnD,kBAAIA,OAAM;AACR,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAS,IAAI,QAAQ,CAAC,EAAE;AACzF,kBAAI,QAAQ;AACV,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAW,IAAI,QAAQ,CAAC,EAAE;AAC3F,kBAAI,QAAQ;AACV,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAoB,IAAI,QAAQ,CAAC,EAAE;AAEhF,kBAAI,QAAQ;AACV,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAyB,IAAI,QAAQ,CAAC,EAAE;AAGrF,qBAAO,EAAE,GAAG,UAAU,IAAAA,KAAI,MAAM,UAAU,EAAE,GAAG,QAAQ,MAAM,WAAW,KAAI,EAAE;YAChF,CAAC;;;;AAIP,aAAO;QACL,GAAG;QACH,SAAS,EAAE,GAAG,aAAa,SAAS,KAAI;QACxC;QACA;QACA;;IAEJ,CAAC;IAEH;IACA;IACA,QAAQ;IACR,GAAI,qBAAqB,EAAE,mBAAkB,IAAK,CAAA;;AAEtD;AAEA,SAAS,IAAI,GAAU;AACrB,SAAO,KAAK,UAAU,CAAC;AACzB;;;AChUM,IAAO,gCAAP,MAAO,uCACH,qBAAoB;EAG5B,OAAgB,mBAAmB,QAAsB;AACvD,UAAM,SAAS,IAAI,+BAA6B;AAChD,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;;EAGA,OAAO,aACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA6B;AAChD,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,aAAa,QAAQ,IAAI,CAAC;AACjE,WAAO;EACT;EAEA,OAAO,SACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA6B;AAChD,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,aAAa,QAAQ,IAAI,CAAC;AAC7D,WAAO;EACT;;;;ACpCI,IAAOC,eAAP,cAA2B,YAAW;EAY1C,aACE,MAGA,SAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,aACnC,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;;AAGX,WAAO,qBAAqB,aAC1B,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;EAEX;EAmBA,SACE,MAGA,SAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,SACnC,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;;AAGX,WAAO,qBAAqB,SAC1B,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;EAEX;;;;EAKA,OAAO,MAAkC,SAA6B;AACpE,WAAO,qBAAqB,qBAAqB,KAAK,QAAQ,KAAK,aAAa,MAAM,OAAO;EAC/F;;;;ACnGI,IAAOC,QAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmBC,aAAY,KAAK,OAAO;EACvF;;CAEA,SAAiBD,OAAI;AACL,EAAAA,MAAA,cAA6BC;AAC7C,GAFiBD,UAAAA,QAAI,CAAA,EAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACHf,IAAgB,gCAAhB,MAA6C;EAoBjD,cAAA;AAjBA,SAAA,aAA8B,IAAI,gBAAe;AAEjD,oDAAA,IAAA,MAAA,MAAA;AACA,2DAAA,IAAA,MAAuC,MAAK;IAAE,CAAC;AAC/C,0DAAA,IAAA,MAAwD,MAAK;IAAE,CAAC;AAEhE,8CAAA,IAAA,MAAA,MAAA;AACA,qDAAA,IAAA,MAAiC,MAAK;IAAE,CAAC;AACzC,oDAAA,IAAA,MAAkD,MAAK;IAAE,CAAC;AAE1D,6CAAA,IAAA,MAA6E,CAAA,CAAE;AAE/E,yCAAA,IAAA,MAAS,KAAK;AACd,2CAAA,IAAA,MAAW,KAAK;AAChB,2CAAA,IAAA,MAAW,KAAK;AAChB,0DAAA,IAAA,MAA0B,KAAK;AAiI/B,+CAAA,IAAA,MAAe,CAAC,UAAkB;AAChC,MAAAE,wBAAA,MAAI,wCAAY,MAAI,GAAA;AACpB,UAAI,iBAAiB,SAAS,MAAM,SAAS,cAAc;AACzD,gBAAQ,IAAI,kBAAiB;;AAE/B,UAAI,iBAAiB,mBAAmB;AACtC,QAAAA,wBAAA,MAAI,wCAAY,MAAI,GAAA;AACpB,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,aAAa;AAChC,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,OAAO;AAC1B,cAAM,cAA2B,IAAI,YAAY,MAAM,OAAO;AAE9D,oBAAY,QAAQ;AACpB,eAAO,KAAK,MAAM,SAAS,WAAW;;AAExC,aAAO,KAAK,MAAM,SAAS,IAAI,YAAY,OAAO,KAAK,CAAC,CAAC;IAC3D,CAAC;AAjJC,IAAAA,wBAAA,MAAI,iDAAqB,IAAI,QAAc,CAAC,SAAS,WAAU;AAC7D,MAAAA,wBAAA,MAAI,wDAA4B,SAAO,GAAA;AACvC,MAAAA,wBAAA,MAAI,uDAA2B,QAAM,GAAA;IACvC,CAAC,GAAC,GAAA;AAEF,IAAAA,wBAAA,MAAI,2CAAe,IAAI,QAAc,CAAC,SAAS,WAAU;AACvD,MAAAA,wBAAA,MAAI,kDAAsB,SAAO,GAAA;AACjC,MAAAA,wBAAA,MAAI,iDAAqB,QAAM,GAAA;IACjC,CAAC,GAAC,GAAA;AAMF,IAAAC,wBAAA,MAAI,iDAAA,GAAA,EAAmB,MAAM,MAAK;IAAE,CAAC;AACrC,IAAAA,wBAAA,MAAI,2CAAA,GAAA,EAAa,MAAM,MAAK;IAAE,CAAC;EACjC;EAEU,KAAK,UAA4B;AAGzC,eAAW,MAAK;AACd,eAAQ,EAAG,KAAK,MAAK;AAEnB,aAAK,MAAM,KAAK;MAClB,GAAGA,wBAAA,MAAI,4CAAA,GAAA,CAAa;IACtB,GAAG,CAAC;EACN;EAEU,QAAQ,KAAQ;AACxB,WAAO;EACT;EAEU,aAAU;AAClB,QAAI,KAAK;AAAO;AAChB,IAAAA,wBAAA,MAAI,wDAAA,GAAA,EAAyB,KAA7B,IAAI;AACJ,SAAK,MAAM,SAAS;EACtB;EAEA,IAAI,QAAK;AACP,WAAOA,wBAAA,MAAI,sCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,wCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,wCAAA,GAAA;EACb;EAEA,QAAK;AACH,SAAK,WAAW,MAAK;EACvB;;;;;;;;EASA,GAA+B,OAAc,UAAyC;AACpF,UAAM,YACJA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,SAAQ,CAAE;AAC3B,WAAO;EACT;;;;;;;;EASA,IAAgC,OAAc,UAAyC;AACrF,UAAM,YAAYA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK;AACvC,QAAI,CAAC;AAAW,aAAO;AACvB,UAAM,QAAQ,UAAU,UAAU,CAAC,MAAM,EAAE,aAAa,QAAQ;AAChE,QAAI,SAAS;AAAG,gBAAU,OAAO,OAAO,CAAC;AACzC,WAAO;EACT;;;;;;EAOA,KAAiC,OAAc,UAAyC;AACtF,UAAM,YACJA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,UAAU,MAAM,KAAI,CAAE;AACvC,WAAO;EACT;;;;;;;;;;;;EAaA,QACE,OAAY;AAMZ,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,MAAAD,wBAAA,MAAI,uDAA2B,MAAI,GAAA;AACnC,UAAI,UAAU;AAAS,aAAK,KAAK,SAAS,MAAM;AAChD,WAAK,KAAK,OAAO,OAAc;IACjC,CAAC;EACH;EAEA,MAAM,OAAI;AACR,IAAAA,wBAAA,MAAI,uDAA2B,MAAI,GAAA;AACnC,UAAMC,wBAAA,MAAI,2CAAA,GAAA;EACZ;EAuBU,MAAkC,UAAiB,MAAoC;AAE/F,QAAIA,wBAAA,MAAI,sCAAA,GAAA,GAAS;AACf;;AAGF,QAAI,UAAU,OAAO;AACnB,MAAAD,wBAAA,MAAI,sCAAU,MAAI,GAAA;AAClB,MAAAC,wBAAA,MAAI,kDAAA,GAAA,EAAmB,KAAvB,IAAI;;AAGN,UAAM,YAA0DA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK;AACrF,QAAI,WAAW;AACb,MAAAA,wBAAA,MAAI,0CAAA,GAAA,EAAY,KAAK,IAAI,UAAU,OAAO,CAAC,MAAM,CAAC,EAAE,IAAI;AACxD,gBAAU,QAAQ,CAAC,EAAE,SAAQ,MAAY,SAAS,GAAG,IAAI,CAAC;;AAG5D,QAAI,UAAU,SAAS;AACrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,uDAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AACvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,uDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,iDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;AAChB;;AAGF,QAAI,UAAU,SAAS;AAGrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,uDAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AAOvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,uDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,iDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;;EAEpB;EAEU,MAAM,uBACd,MACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,6BAA6B,QAAQ,MAAM,OAAO;EACtE;EAEU,MAAM,oBACd,UACA,MACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,uBAAuB,MAAM,UAAU,QAAQ,OAAO;EAC1E;EAEU,MAAM,wBACd,UACA,OACA,MACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,2BAA2B,MAAM,UAAU,OAAO,QAAQ,OAAO;EACrF;EAEU,MAAM,6BACd,QACA,MACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAIhE,UAAM,YAAY,MAAM,OAAO,aAC7B,EAAE,GAAG,MAAM,QAAQ,MAAK,GACxB,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,QAAQ,SAAgB;EACtC;EAEU,MAAM,2BACd,KACA,UACA,OACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,YAAY,MAAM,IAAI,kBAC1B,UACA,OACA,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,QAAQ,SAAgB;EACtC;EAEU,MAAM,uBACd,KACA,UACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAIhE,UAAM,YAAY,MAAM,IAAI,OAC1B,UACA,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,QAAQ,SAAgB;EACtC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3OI,IAAO,kBAAP,MAAO,yBACH,8BAAoD;EAD9D,cAAA;;;AAKE,4BAAA,IAAA,MAAkC,CAAA,CAAE;AAIpC,sCAAA,IAAA,MAAoD,CAAA,CAAE;AACtD,sCAAA,IAAA,MAA+C,CAAA,CAAE;AACjD,qCAAA,IAAA,MAAA,MAAA;AACA,8BAAA,IAAA,MAAA,MAAA;AACA,yCAAA,IAAA,MAAA,MAAA;AACA,oCAAA,IAAA,MAAA,MAAA;AACA,0CAAA,IAAA,MAAA,MAAA;AACA,qCAAA,IAAA,MAAA,MAAA;AAGA,kCAAA,IAAA,MAAA,MAAA;AACA,wCAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;EAinBF;EA/mBE,EAAA,0BAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,4BAAA,oBAAA,QAAA,GAAA,uCAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,wCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,gCAAA,oBAAA,QAAA,GAAA,sCAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,6BAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAoC,CAAA;AAC1C,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAGX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,YAA0D;AAC9D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAA0C,CAAC,SAAS,WAC7D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACC,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC;MACA,QAAQ,YAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC;;EAEJ;EAEA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEU,MAAM,oBACd,gBACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAyC,gBAAgB,KAAK,UAAU;AAC9F,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;EAEA,OAAO,0BACL,UACA,OACA,MACA,MACA,SAAmC;AAEnC,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,wBAAwB,UAAU,OAAO,MAAM,MAAM;MAC1D,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEmB,MAAM,2BACvB,KACA,UACA,OACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAA4C,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAC3E,UAAM,SAAS,MAAM,IAAI,kBAAkB,UAAU,OAAO,MAAM;MAChE,GAAG;MACH,QAAQ,KAAK,WAAW;KACzB;AAED,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,OAAO,4BACL,MACA,QACA,SAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,uBAAuB,MAAM,QAAQ;MAC1C,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,OAAO,sBACL,UACA,MACA,QACA,SAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,oBAAoB,UAAU,MAAM,QAAQ;MACjD,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,eAAY;AACV,WAAOA,wBAAA,MAAI,+BAAA,GAAA;EACb;EAEA,aAAU;AACR,WAAOA,wBAAA,MAAI,qCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,kCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,yCAAA,GAAA;EACb;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,WAAQ;AACZ,UAAM,KAAK,KAAI;AACf,QAAI,CAACA,wBAAA,MAAI,2BAAA,GAAA;AAAY,YAAM,MAAM,6BAA6B;AAE9D,WAAOA,wBAAA,MAAI,2BAAA,GAAA;EACb;EAEmB,MAAM,6BACvB,QACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,OAAO,aAAa,MAAM,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE7F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEmB,MAAM,uBACvB,KACA,UACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,IAAI,OAAO,UAAU,MAAM,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE9F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EA6SA,OAAO,gBAAgB,KAA0B,OAA0B;AACzE,eAAW,CAAC,KAAK,UAAU,KAAK,OAAO,QAAQ,KAAK,GAAG;AACrD,UAAI,CAAC,IAAI,eAAe,GAAG,GAAG;AAC5B,YAAI,GAAG,IAAI;AACX;;AAGF,UAAI,WAAW,IAAI,GAAG;AACtB,UAAI,aAAa,QAAQ,aAAa,QAAW;AAC/C,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,QAAQ,WAAW,QAAQ,QAAQ;AACrC,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AAClE,oBAAY;iBACH,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AACzE,oBAAY;iBACE,MAAM,QAAQ,KAAU,MAAM,UAAU,GAAG;AACzD,mBAAW,KAAK,gBAAgB,UAAiC,UAAiC;iBACzF,MAAM,QAAQ,QAAQ,KAAK,MAAM,QAAQ,UAAU,GAAG;AAC/D,YAAI,SAAS,MAAM,CAAC,MAAM,OAAO,MAAM,YAAY,OAAO,MAAM,QAAQ,GAAG;AACzE,mBAAS,KAAK,GAAG,UAAU;AAC3B;;aAEG;AACL,cAAM,MAAM,0BAA0B,GAAG,iBAAiB,UAAU,eAAe,QAAQ,EAAE;;AAE/F,UAAI,GAAG,IAAI;;AAGb,WAAO;EACT;;gEAjVU,OAA2B;AACnC,MAAI,KAAK;AAAO;AAEhB,EAAAC,wBAAA,MAAI,+BAAiB,OAAK,GAAA;AAE1B,EAAAD,wBAAA,MAAI,4BAAA,KAAA,4BAAA,EAAa,KAAjB,MAAkB,KAAK;AAEvB,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,0BAAA,EAAW,KAAf,MAAgB,KAAK;AACrB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;AAEH,YAAM,IAAI,MACR,qFAAqF;;AAG7F,GAAC,8BAAA,SAAAE,+BAAA;AAGC,MAAI,KAAK,OAAO;AACd,UAAM,IAAI,YAAY,yCAAyC;;AAGjE,MAAI,CAACF,wBAAA,MAAI,2BAAA,GAAA;AAAY,UAAM,MAAM,iCAAiC;AAElE,SAAOA,wBAAA,MAAI,2BAAA,GAAA;AACb,GAAC,iCAAA,SAAAG,gCAEc,OAAyB;AACtC,QAAM,CAAC,oBAAoB,UAAU,IAAIH,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,OAAOA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC7F,EAAAC,wBAAA,MAAI,kCAAoB,oBAAkB,GAAA;AAC1C,EAAAD,wBAAA,MAAI,mCAAA,GAAA,EAAmB,mBAAmB,EAAE,IAAI;AAEhD,aAAW,WAAW,YAAY;AAChC,UAAM,kBAAkB,mBAAmB,QAAQ,QAAQ,KAAK;AAChE,QAAI,iBAAiB,QAAQ,QAAQ;AACnC,WAAK,MAAM,eAAe,gBAAgB,IAAI;;;AAIlD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IAEF,KAAK;AACH;IAEF,KAAK;AACH,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAE/D,UAAI,MAAM,KAAK,MAAM,SAAS;AAC5B,mBAAW,WAAW,MAAM,KAAK,MAAM,SAAS;AAE9C,cAAI,QAAQ,QAAQ,UAAU,QAAQ,MAAM;AAC1C,gBAAI,YAAY,QAAQ;AACxB,gBAAI,WAAW,mBAAmB,QAAQ,QAAQ,KAAK;AACvD,gBAAI,YAAY,SAAS,QAAQ,QAAQ;AACvC,mBAAK,MAAM,aAAa,WAAW,SAAS,IAAI;mBAC3C;AACL,oBAAM,MAAM,qEAAqE;;;AAIrF,cAAI,QAAQ,SAASA,wBAAA,MAAI,sCAAA,GAAA,GAAuB;AAE9C,gBAAIA,wBAAA,MAAI,iCAAA,GAAA,GAAkB;AACxB,sBAAQA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAM;gBACjC,KAAK;AACH,uBAAK,MAAM,YAAYA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACvE;gBACF,KAAK;AACH,uBAAK,MAAM,iBAAiBA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAClF;;;AAIN,YAAAC,wBAAA,MAAI,sCAAwB,QAAQ,OAAK,GAAA;;AAG3C,UAAAA,wBAAA,MAAI,iCAAmB,mBAAmB,QAAQ,QAAQ,KAAK,GAAC,GAAA;;;AAIpE;IAEF,KAAK;IACL,KAAK;AAEH,UAAID,wBAAA,MAAI,sCAAA,GAAA,MAA0B,QAAW;AAC3C,cAAM,iBAAiB,MAAM,KAAK,QAAQA,wBAAA,MAAI,sCAAA,GAAA,CAAqB;AACnE,YAAI,gBAAgB;AAClB,kBAAQ,eAAe,MAAM;YAC3B,KAAK;AACH,mBAAK,MAAM,iBAAiB,eAAe,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC5E;YACF,KAAK;AACH,mBAAK,MAAM,YAAY,eAAe,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACjE;;;;AAKR,UAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,eAAe,MAAM,IAAI;;AAGtC,MAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEvC,GAAC,iCAAA,SAAAG,gCAEc,OAAyB;AACtC,QAAM,qBAAqBJ,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,KAAK;AACxD,EAAAC,wBAAA,MAAI,yCAA2B,oBAAkB,GAAA;AAEjD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IACF,KAAK;AACH,YAAM,QAAQ,MAAM,KAAK;AACzB,UACE,MAAM,gBACN,MAAM,aAAa,QAAQ,gBAC3B,MAAM,aAAa,cACnB,mBAAmB,aAAa,QAAQ,cACxC;AACA,mBAAW,YAAY,MAAM,aAAa,YAAY;AACpD,cAAI,SAAS,SAASD,wBAAA,MAAI,uCAAA,GAAA,GAAwB;AAChD,iBAAK,MACH,iBACA,UACA,mBAAmB,aAAa,WAAW,SAAS,KAAK,CAAa;iBAEnE;AACL,gBAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,mBAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;AAGlD,YAAAC,wBAAA,MAAI,uCAAyB,SAAS,OAAK,GAAA;AAC3C,YAAAA,wBAAA,MAAI,kCAAoB,mBAAmB,aAAa,WAAW,SAAS,KAAK,GAAC,GAAA;AAClF,gBAAID,wBAAA,MAAI,kCAAA,GAAA;AAAmB,mBAAK,MAAM,mBAAmBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;;;AAKpF,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAC/D;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAC,wBAAA,MAAI,yCAA2B,QAAS,GAAA;AACxC,YAAM,UAAU,MAAM,KAAK;AAC3B,UAAI,QAAQ,QAAQ,cAAc;AAChC,YAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,eAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAA6B;AAC5D,UAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;;AAGrC,WAAK,MAAM,eAAe,MAAM,MAAM,kBAAkB;AACxD;IACF,KAAK;AACH;;AAEN,GAAC,+BAAA,SAAAI,8BAEY,OAA2B;AACtC,EAAAL,wBAAA,MAAI,yBAAA,GAAA,EAAS,KAAK,KAAK;AACvB,OAAK,MAAM,SAAS,KAAK;AAC3B,GAAC,qCAAA,SAAAM,oCAEkB,OAAyB;AAC1C,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,MAAAN,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C,aAAO,MAAM;IAEf,KAAK;AACH,UAAI,WAAWA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACnD,UAAI,CAAC,UAAU;AACb,cAAM,MAAM,uDAAuD;;AAGrE,UAAI,OAAO,MAAM;AAEjB,UAAI,KAAK,OAAO;AACd,cAAM,cAAc,gBAAgB,gBAAgB,UAAU,KAAK,KAAK;AACxE,QAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI;;AAG1C,aAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;IAE7C,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C;;AAGJ,MAAIA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AAAG,WAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACtF,QAAM,IAAI,MAAM,uBAAuB;AACzC,GAAC,qCAAA,SAAAO,oCAGC,OACA,UAA6B;AAE7B,MAAI,aAAoC,CAAA;AAExC,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH,aAAO,CAAC,MAAM,MAAM,UAAU;IAEhC,KAAK;AACH,UAAI,CAAC,UAAU;AACb,cAAM,MACJ,wFAAwF;;AAI5F,UAAI,OAAO,MAAM;AAGjB,UAAI,KAAK,MAAM,SAAS;AACtB,mBAAW,kBAAkB,KAAK,MAAM,SAAS;AAC/C,cAAI,eAAe,SAAS,SAAS,SAAS;AAC5C,gBAAI,iBAAiB,SAAS,QAAQ,eAAe,KAAK;AAC1D,qBAAS,QAAQ,eAAe,KAAK,IAAIP,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MACvC,gBACA,cAAc;iBAEX;AACL,qBAAS,QAAQ,eAAe,KAAK,IAAI;AAEzC,uBAAW,KAAK,cAAc;;;;AAKpC,aAAO,CAAC,UAAU,UAAU;IAE9B,KAAK;IACL,KAAK;IACL,KAAK;AAEH,UAAI,UAAU;AACZ,eAAO,CAAC,UAAU,UAAU;aACvB;AACL,cAAM,MAAM,yDAAyD;;;AAG3E,QAAM,MAAM,yCAAyC;AACvD,GAAC,qCAAA,SAAAQ,oCAGC,gBACA,gBAA0C;AAE1C,SAAO,gBAAgB,gBAAgB,gBAA+C,cAAc;AAGtG,GAAC,6BAAA,SAAAC,4BA0CU,OAAqB;AAC9B,EAAAR,wBAAA,MAAI,qCAAuB,MAAM,MAAI,GAAA;AACrC,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,2BAAa,MAAM,MAAI,GAAA;AAC3B,UAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAChD,QAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEnC;IACF,KAAK;AACH;;AAEN;;;ACxsBI,IAAO,WAAP,cAAwB,YAAW;;;;EAIvC,OACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa;MACxD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,WAAmB,SAA6B;AACzE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,aAAa,SAAS,IAAI;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,WACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,SAAS,IAAI;MACrE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,aAAa,cAAc;MAC5E;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,WAAmB,SAA6B;AACpE,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,aAAa,SAAS,IAAI;MACvE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;;CAylBrD,SAAiBS,WAAQ;AA2BT,EAAAA,UAAA,eAA2B;AAI3C,GA/BiB,aAAA,WAAQ,CAAA,EAAA;;;ACvqBnB,IAAO,QAAP,cAAqB,YAAW;;;;EAIpC,SACE,UACA,OACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,UAAU,MAAM,IAAI;MAC5E,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAgBA,KACE,UACA,OACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,OAAO,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,KAAK,UAAU,cAAc;MACvF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;;CAqjBrD,SAAiBC,QAAK;AAkBN,EAAAA,OAAA,eAAwB;AAExC,GApBiB,UAAA,QAAK,CAAA,EAAA;;;AC3lBhB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EAyPzD;EAzOE,OACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS;MACpD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;EAKA,SAAS,UAAkB,OAAe,SAA6B;AACrE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC5D,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC7D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,UAAU;MACpE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,OAAe,SAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,WAAW;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;;EAOA,MAAM,cACJ,UACA,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,OAAO,UAAU,MAAM,OAAO;AACrD,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAI,OAAO;EAClD;;;;;;EAOA,gBACE,UACA,MACA,SAA6B;AAE7B,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAM,OAAO;EACtG;;;;;;EAOA,MAAM,KACJ,UACA,OACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AAEnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,KAAK,SAAQ,IAAK,MAAM,KAAK,SAAS,UAAU,OAAO;QACnE,GAAG;QACH,SAAS,EAAE,GAAG,SAAS,SAAS,GAAG,QAAO;OAC3C,EAAE,aAAY;AAEf,cAAQ,IAAI,QAAQ;QAElB,KAAK;QACL,KAAK;QACL,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;EAKA,OAAO,UAAkB,MAAiC,SAA6B;AACrF,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAM,OAAO;EACtG;EA0BA,kBACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,wBAAwB;MACjF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,yBACJ,UACA,OACA,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,kBAAkB,UAAU,OAAO,MAAM,OAAO;AACvE,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAI,OAAO;EAClD;;;;;;EAOA,wBACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,gBAAgB,0BACrB,UACA,OACA,KAAK,QAAQ,KAAK,QAAQ,MAC1B,MACA,OAAO;EAEX;;AAGI,IAAO,WAAP,cAAwB,WAAe;;CA8zC7C,SAAiBC,OAAI;AAIL,EAAAA,MAAA,WAAmB;AAcnB,EAAAA,MAAA,QAAiB;AAkBjB,EAAAA,MAAA,eAAwB;AAExC,GAtCiB,SAAA,OAAI,CAAA,EAAA;;;AC9jDf,IAAO,UAAP,cAAuB,YAAW;EAAxC,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;AAClD,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;EAqGxE;EA9FE,OACE,OAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,IAAI,GAAG;AAC1B,aAAO,KAAK,OAAO,CAAA,GAAI,IAAI;;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY;MACnC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,SAA6B;AACtD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,IAAI;MAC9C,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,MAA0B,SAA6B;AAC9E,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,IAAI;MAC/C;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,SAA6B;AACjD,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,IAAI;MACjD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAiBA,aACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,iBAAiB;MACxC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,iBACJ,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,aAAa,MAAM,OAAO;AACjD,WAAO,MAAM,KAAK,KAAK,KAAK,IAAI,WAAW,IAAI,IAAI,OAAO;EAC5D;;;;EAKA,mBACE,MACA,SAA6B;AAE7B,WAAO,gBAAgB,4BAA4B,MAAM,KAAK,QAAQ,KAAK,SAAS,OAAO;EAC7F;;CA+7CF,SAAiBC,UAAO;AAeR,EAAAA,SAAA,OAAe;AAIf,EAAAA,SAAA,WAAmB;AAcnB,EAAAA,SAAA,WAAuB;AA2BvB,EAAAA,SAAA,eAA2B;AAI3C,GAhEiB,YAAA,UAAO,CAAA,EAAA;;;AC/iDjB,IAAM,sBAAsB,OAAU,aAAwC;AACnF,QAAM,UAAU,MAAM,QAAQ,WAAW,QAAQ;AACjD,QAAM,WAAW,QAAQ,OAAO,CAAC,WAA4C,OAAO,WAAW,UAAU;AACzG,MAAI,SAAS,QAAQ;AACnB,eAAW,UAAU,UAAU;AAC7B,cAAQ,MAAM,OAAO,MAAM;;AAG7B,UAAM,IAAI,MAAM,GAAG,SAAS,MAAM,2CAA2C;;AAI/E,QAAM,SAAc,CAAA;AACpB,aAAW,UAAU,SAAS;AAC5B,QAAI,OAAO,WAAW,aAAa;AACjC,aAAO,KAAK,OAAO,KAAK;;;AAG5B,SAAO;AACT;;;ACbM,IAAO,QAAP,cAAqB,YAAW;;;;;;EAMpC,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,UAAU;MAChE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,UAAU,MAAM,IAAI;MACzE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAcA,KACE,eACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,eAAe,CAAA,GAAI,KAAK;;AAE3C,WAAO,KAAK,QAAQ,WAAW,kBAAkB,aAAa,UAAU,sBAAsB;MAC5F;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;;;EAQA,IACE,eACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,UAAU,MAAM,IAAI;MAC5E,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,OAAO,MAAM,KAAK,OAAO,eAAe,MAAM,OAAO;AAC3D,WAAO,MAAM,KAAK,KAAK,eAAe,KAAK,IAAI,OAAO;EACxD;;;;;;;EAQA,MAAM,KACJ,eACA,QACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AACnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAE/E,WAAO,MAAM;AACX,YAAM,eAAe,MAAM,KAAK,SAAS,eAAe,QAAQ;QAC9D,GAAG;QACH;OACD,EAAE,aAAY;AAEf,YAAM,OAAO,aAAa;AAE1B,cAAQ,KAAK,QAAQ;QACnB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,aAAa,SAAS,QAAQ,IAAI,sBAAsB;AAC/E,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;;EAQA,MAAM,OACJ,eACA,MACA,SAA6B;AAE7B,UAAM,WAAW,MAAM,KAAK,QAAQ,MAAM,OAAO,EAAE,MAAY,SAAS,aAAY,GAAI,OAAO;AAC/F,WAAO,KAAK,OAAO,eAAe,EAAE,SAAS,SAAS,GAAE,GAAI,OAAO;EACrE;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,WAAW,MAAM,KAAK,OAAO,eAAe,MAAM,OAAO;AAC/D,WAAO,MAAM,KAAK,KAAK,eAAe,SAAS,IAAI,OAAO;EAC5D;;AAGI,IAAO,uBAAP,cAAoC,WAA2B;;CAmMrE,SAAiBC,QAAK;AAGN,EAAAA,OAAA,uBAAgC;AAGhD,GANiB,UAAA,QAAK,CAAA,EAAA;;;AClWhB,IAAO,cAAP,cAA2B,YAAW;;;;EAI1C,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB;MACvE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,SACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,iBAAiB,OAAO,IAAI;MACjF,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;EAMA,OACE,eACA,SACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB,OAAO,WAAW;MACzF,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,QAAQ,MAAM,KAAK,OAAO,eAAe,IAAI;AACnD,WAAO,MAAM,KAAK,KAAK,eAAe,MAAM,IAAI,OAAO;EACzD;EAgBA,UACE,eACA,SACA,QAAwD,CAAA,GACxD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,UAAU,eAAe,SAAS,CAAA,GAAI,KAAK;;AAEzD,WAAO,KAAK,QAAQ,WAClB,kBAAkB,aAAa,iBAAiB,OAAO,UACvD,sBACA,EAAE,OAAO,GAAG,SAAS,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO,EAAE,CAAE;EAE3F;;;;;;;EAQA,MAAM,KACJ,eACA,SACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AACnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,OAAO,SAAQ,IAAK,MAAM,KAAK,SAAS,eAAe,SAAS;QAC5E,GAAG;QACH;OACD,EAAE,aAAY;AAEf,cAAQ,MAAM,QAAQ;QACpB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;EAOA,MAAM,cACJ,eACA,EAAE,OAAO,UAAU,CAAA,EAAE,GACrB,SAAoF;AAEpF,QAAI,UAAU,QAAQ,MAAM,UAAU,GAAG;AACvC,YAAM,IAAI,MAAM,+BAA+B;;AAGjD,UAAM,wBAAwB,SAAS,kBAAkB;AAEzD,UAAM,mBAAmB,KAAK,IAAI,uBAAuB,MAAM,MAAM;AAErE,UAAM,SAAS,KAAK;AACpB,UAAM,eAAe,MAAM,OAAM;AACjC,UAAM,aAAuB,CAAC,GAAG,OAAO;AAIxC,mBAAe,aAAa,UAAsC;AAChE,eAAS,QAAQ,UAAU;AACzB,cAAM,UAAU,MAAM,OAAO,MAAM,OAAO,EAAE,MAAM,MAAM,SAAS,aAAY,GAAI,OAAO;AACxF,mBAAW,KAAK,QAAQ,EAAE;;IAE9B;AAGA,UAAM,UAAU,MAAM,gBAAgB,EAAE,KAAK,YAAY,EAAE,IAAI,YAAY;AAG3E,UAAM,oBAAoB,OAAO;AAEjC,WAAO,MAAM,KAAK,cAAc,eAAe;MAC7C,UAAU;KACX;EACH;;AAkJF,0BAAiBC,cAAW;AAI5B,GAJiB,gBAAA,cAAW,CAAA,EAAA;;;ACnUtB,IAAO,eAAP,cAA4B,YAAW;EAA7C,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;AACvD,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EAqEvF;;;;EAhEE,OAAO,MAA+B,SAA6B;AACjE,WAAO,KAAK,QAAQ,KAAK,kBAAkB;MACzC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,eAAuB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,IAAI;MACzD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,IAAI;MAC1D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAqD,CAAA,GACrD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,kBAAkB,kBAAkB;MACjE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,eAAuB,SAA6B;AACtD,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,IAAI;MAC5D,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,mBAAP,cAAgC,WAAuB;;CAoQ7D,SAAiBC,eAAY;AAGb,EAAAA,cAAA,mBAAmC;AAInC,EAAAA,cAAA,QAAiB;AAGjB,EAAAA,cAAA,uBAAgC;AAGhC,EAAAA,cAAA,cAA6B;AAI7C,GAjBiB,iBAAA,eAAY,CAAA,EAAA;;;AC/UvB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,OAAqB,IAAYC,MAAK,KAAK,OAAO;AAClD,SAAA,aAAuC,IAAkB,WAAW,KAAK,OAAO;AAChF,SAAA,UAA8B,IAAe,QAAQ,KAAK,OAAO;EACnE;;CAEA,SAAiBC,OAAI;AACL,EAAAA,MAAA,eAA+B;AAG/B,EAAAA,MAAA,mBAAmC;AAInC,EAAAA,MAAA,OAAeD;AACf,EAAAC,MAAA,aAA2B;AAY3B,EAAAA,MAAA,iBAA+B;AAI/B,EAAAA,MAAA,UAAqB;AAerC,GAxCiB,SAAA,OAAI,CAAA,EAAA;;;ACNf,IAAOC,eAAP,cAA2B,YAAW;EAa1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAG7F;;AAoSF,0BAAiBA,cAAW;AAO5B,GAPiBA,iBAAAA,eAAW,CAAA,EAAA;;;AC3TtB,IAAO,aAAP,cAA0B,YAAW;;;;EAIzC,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,EAAE,MAAM,GAAG,QAAO,CAAE;EAC9D;;AAyGF,0BAAiBC,aAAU;AAI3B,GAJiB,eAAA,aAAU,CAAA,EAAA;;;AC5GrB,IAAOC,SAAP,cAAqB,YAAW;;;;;;;;;;;;;;;;;;;;;;;;EAwBpC,OAAO,MAAwB,SAA6B;AAC1D,WAAO,KAAK,QAAQ,KAAK,UAAU,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACtF;;;;EAKA,SAAS,QAAgB,SAA6B;AACpD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,IAAI,OAAO;EACrD;EAOA,KACE,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,UAAU,iBAAiB,EAAE,OAAO,GAAG,QAAO,CAAE;EACjF;;;;EAKA,IAAI,QAAgB,SAA6B;AAC/C,WAAO,KAAK,QAAQ,OAAO,UAAU,MAAM,IAAI,OAAO;EACxD;;;;EAKA,QAAQ,QAAgB,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY,EAAE,GAAG,SAAS,kBAAkB,KAAI,CAAE;EAC5F;;;;;;EAOA,gBAAgB,QAAgB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY;MAClD,GAAG;MACH,SAAS,EAAE,QAAQ,oBAAoB,GAAG,SAAS,QAAO;KAC3D;EACH;;;;EAKA,MAAM,kBACJ,IACA,EAAE,eAAe,KAAM,UAAU,KAAK,KAAK,IAAI,IAAkD,CAAA,GAAE;AAEnG,UAAM,kBAAkB,oBAAI,IAAI,CAAC,aAAa,SAAS,SAAS,CAAC;AAEjE,UAAM,QAAQ,KAAK,IAAG;AACtB,QAAI,OAAO,MAAM,KAAK,SAAS,EAAE;AAEjC,WAAO,CAAC,KAAK,UAAU,CAAC,gBAAgB,IAAI,KAAK,MAAM,GAAG;AACxD,YAAM,MAAM,YAAY;AAExB,aAAO,MAAM,KAAK,SAAS,EAAE;AAC7B,UAAI,KAAK,IAAG,IAAK,QAAQ,SAAS;AAChC,cAAM,IAAI,0BAA0B;UAClC,SAAS,iCAAiC,EAAE,+BAA+B,OAAO;SACnF;;;AAIL,WAAO;EACT;;AAMI,IAAO,kBAAP,cAA+B,KAAgB;;CA8FrD,SAAiBA,QAAK;AAIN,EAAAA,OAAA,kBAA2B;AAG3C,GAPiBA,WAAAA,SAAK,CAAA,EAAA;;;AC5MhB,IAAO,cAAP,cAA2B,YAAW;EAa1C,KACE,iBACA,QAAoD,CAAA,GACpD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,iBAAiB,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAClB,qBAAqB,eAAe,gBACpC,8BACA,EAAE,OAAO,GAAG,QAAO,CAAE;EAEzB;;AAGI,IAAO,+BAAP,cAA4C,WAAmC;;CAkErF,SAAiBC,cAAW;AAEZ,EAAAA,aAAA,+BAA8C;AAE9D,GAJiB,gBAAA,cAAW,CAAA,EAAA;;;AC9FtB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EA0EvF;;;;;;;;;;EA/DE,OAAO,MAAuB,SAA6B;AACzD,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,QAAO,CAAE;EACpE;;;;;;EAOA,SAAS,iBAAyB,SAA6B;AAC7D,WAAO,KAAK,QAAQ,IAAI,qBAAqB,eAAe,IAAI,OAAO;EACzE;EAUA,KACE,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,qBAAqB,oBAAoB,EAAE,OAAO,GAAG,QAAO,CAAE;EAC/F;;;;EAKA,OAAO,iBAAyB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,qBAAqB,eAAe,WAAW,OAAO;EACjF;EAcA,WACE,iBACA,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,WAAW,iBAAiB,CAAA,GAAI,KAAK;;AAEnD,WAAO,KAAK,QAAQ,WAAW,qBAAqB,eAAe,WAAW,yBAAyB;MACrG;MACA,GAAG;KACJ;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;;AAE3D,IAAO,0BAAP,cAAuC,WAA8B;;CAuW3E,SAAiBC,OAAI;AAML,EAAAA,MAAA,qBAA6B;AAC7B,EAAAA,MAAA,0BAAkC;AAIlC,EAAAA,MAAA,cAA6B;AAE7B,EAAAA,MAAA,+BAA8C;AAE9D,GAfiB,SAAA,OAAI,CAAA,EAAA;;;AC1bf,IAAO,aAAP,cAA0B,YAAW;EAA3C,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;EACpD;;CAEA,SAAiBC,aAAU;AACX,EAAAA,YAAA,OAAe;AAMf,EAAAA,YAAA,qBAA6B;AAC7B,EAAAA,YAAA,0BAAkC;AAIlD,GAZiB,eAAA,aAAU,CAAA,EAAA;;;ACFrB,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,gBACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,sBAAsB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAClG;;;;EAKA,KAAK,MAAuB,SAA6B;AACvD,WAAO,KAAK,QAAQ,KAAK,iBAAiB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAC7F;;;;EAKA,SAAS,MAA2B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,uBAAuB,EAAE,MAAM,GAAG,QAAO,CAAE;EACtE;;AAkLF,0BAAiBC,SAAM;AAMvB,GANiB,WAAA,SAAM,CAAA,EAAA;;;ACzMjB,IAAO,SAAP,cAAsB,YAAW;;;;;EAKrC,SAAS,OAAe,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,WAAW,KAAK,IAAI,OAAO;EACrD;;;;;EAMA,KAAK,SAA6B;AAChC,WAAO,KAAK,QAAQ,WAAW,WAAW,YAAY,OAAO;EAC/D;;;;;EAMA,IAAI,OAAe,SAA6B;AAC9C,WAAO,KAAK,QAAQ,OAAO,WAAW,KAAK,IAAI,OAAO;EACxD;;AAMI,IAAO,aAAP,cAA0B,KAAW;;CAmC3C,SAAiBC,SAAM;AAGP,EAAAA,QAAA,aAAuB;AACvC,GAJiB,WAAA,SAAM,CAAA,EAAA;;;ACjEjB,IAAO,cAAP,cAA2B,YAAW;;;;EAI1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,QAAO,CAAE;EAC/D;;AAkMF,0BAAiBC,cAAW;AAI5B,GAJiB,gBAAA,cAAW,CAAA,EAAA;;;;ACxHtB,IAAO,SAAP,cAA2B,UAAS;;;;;;;;;;;;;;;;EAsBxC,YAAY,EACV,UAAe,QAAQ,iBAAiB,GACxC,SAAc,QAAQ,gBAAgB,GACtC,eAAoB,QAAQ,eAAe,KAAK,MAChD,UAAe,QAAQ,mBAAmB,KAAK,MAC/C,GAAG,KAAI,IACU,CAAA,GAAE;AACnB,QAAI,WAAW,QAAW;AACxB,YAAM,IAAW,YACf,oLAAoL;;AAIxL,UAAM,UAAyB;MAC7B;MACA;MACA;MACA,GAAG;MACH,SAAS,WAAW;;AAGtB,QAAI,CAAC,QAAQ,2BAAgC,mBAAkB,GAAI;AACjE,YAAM,IAAW,YACf,obAAob;;AAIxb,UAAM;MACJ,SAAS,QAAQ;MACjB,SAAS,QAAQ,WAAW;MAC5B,WAAW,QAAQ;MACnB,YAAY,QAAQ;MACpB,OAAO,QAAQ;KAChB;AAQH,SAAA,cAA+B,IAAQC,aAAY,IAAI;AACvD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,QAAmB,IAAQC,OAAM,IAAI;AACrC,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,QAAmB,IAAQ,MAAM,IAAI;AACrC,SAAA,cAA+B,IAAQ,YAAY,IAAI;AACvD,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,UAAuB,IAAQ,QAAQ,IAAI;AAjBzC,SAAK,WAAW;AAEhB,SAAK,SAAS;AACd,SAAK,eAAe;AACpB,SAAK,UAAU;EACjB;EAcmB,eAAY;AAC7B,WAAO,KAAK,SAAS;EACvB;EAEmB,eAAe,MAA8B;AAC9D,WAAO;MACL,GAAG,MAAM,eAAe,IAAI;MAC5B,uBAAuB,KAAK;MAC5B,kBAAkB,KAAK;MACvB,GAAG,KAAK,SAAS;;EAErB;EAEmB,YAAY,MAA8B;AAC3D,WAAO,EAAE,eAAe,UAAU,KAAK,MAAM,GAAE;EACjD;;;AAEO,OAAA,SAAS;AAET,OAAA,cAAqB;AACrB,OAAA,WAAkB;AAClB,OAAA,qBAA4B;AAC5B,OAAA,4BAAmC;AACnC,OAAA,oBAA2B;AAC3B,OAAA,gBAAuB;AACvB,OAAA,gBAAuB;AACvB,OAAA,iBAAwB;AACxB,OAAA,kBAAyB;AACzB,OAAA,sBAA6B;AAC7B,OAAA,sBAA6B;AAC7B,OAAA,wBAA+B;AAC/B,OAAA,2BAAkC;AAElC,OAAA,SAAiB;AACjB,OAAA,eAAuB;AAGzB,IAAM,EACX,aAAAC,cACA,UAAAC,WACA,oBAAAC,qBACA,2BAAAC,4BACA,mBAAAC,oBACA,eAAAC,gBACA,eAAAC,gBACA,gBAAAC,iBACA,iBAAAC,kBACA,qBAAAC,sBACA,qBAAAC,sBACA,uBAAAC,wBACA,0BAAAC,0BAAwB,IACtB;AAEE,IAAQC,UAAiB;AACzB,IAAQC,gBAAuB;CAErC,SAAiBC,SAAM;AAGP,EAAAA,QAAA,OAAkB;AAGlB,EAAAA,QAAA,aAAwB;AAIxB,EAAAA,QAAA,cAAkBjB;AAQlB,EAAAiB,QAAA,OAAW;AA0BX,EAAAA,QAAA,aAAiB;AAKjB,EAAAA,QAAA,QAAYhB;AAIZ,EAAAgB,QAAA,kBAAsB;AAItB,EAAAA,QAAA,SAAa;AAOb,EAAAA,QAAA,QAAY;AAEZ,EAAAA,QAAA,cAAkB;AAKlB,EAAAA,QAAA,SAAa;AAGb,EAAAA,QAAA,aAAiB;AAEjB,EAAAA,QAAA,aAAiB;AAEjB,EAAAA,QAAA,OAAW;AAEX,EAAAA,QAAA,UAAc;AAId,EAAAA,QAAA,cAAkB;AAOlC,GA3FiB,WAAA,SAAM,CAAA,EAAA;AA8HjB,IAAO,cAAP,cAA2B,OAAM;;;;;;;;;;;;;;;;;;EAqBrC,YAAY,EACV,UAAe,QAAQ,iBAAiB,GACxC,SAAc,QAAQ,sBAAsB,GAC5C,aAAkB,QAAQ,oBAAoB,GAC9C,UACA,YACA,sBACA,yBACA,GAAG,KAAI,IACe,CAAA,GAAE;AACxB,QAAI,CAAC,YAAY;AACf,YAAM,IAAW,YACf,8MAA8M;;AAIlN,QAAI,OAAO,yBAAyB,YAAY;AAC9C,gCAA0B;;AAG5B,QAAI,CAAC,wBAAwB,CAAC,QAAQ;AACpC,YAAM,IAAW,YACf,sIAAsI;;AAI1I,QAAI,wBAAwB,QAAQ;AAClC,YAAM,IAAW,YACf,6GAA6G;;AAKjH,eAAA,SAAW;AAEX,SAAK,eAAe,EAAE,GAAG,KAAK,cAAc,eAAe,WAAU;AAErE,QAAI,CAAC,SAAS;AACZ,UAAI,CAAC,UAAU;AACb,mBAAW,QAAQ,IAAI,uBAAuB;;AAGhD,UAAI,CAAC,UAAU;AACb,cAAM,IAAW,YACf,gHAAgH;;AAIpH,gBAAU,GAAG,QAAQ;WAChB;AACL,UAAI,UAAU;AACZ,cAAM,IAAW,YAAY,6CAA6C;;;AAI9E,UAAM;MACJ;MACA;MACA,GAAG;MACH,GAAI,4BAA4B,SAAY,EAAE,wBAAuB,IAAK,CAAA;KAC3E;AA9EH,SAAA,aAAqB;AAgFnB,SAAK,wBAAwB;AAC7B,SAAK,aAAa;AAClB,SAAK,cAAc;EACrB;EAES,aAAa,SAA0C;AAK9D,QAAI,uBAAuB,IAAI,QAAQ,IAAI,KAAK,QAAQ,WAAW,UAAU,QAAQ,SAAS,QAAW;AACvG,UAAI,CAAM,MAAM,QAAQ,IAAI,GAAG;AAC7B,cAAM,IAAI,MAAM,uCAAuC;;AAEzD,YAAM,QAAQ,KAAK,eAAe,QAAQ,KAAK,OAAO;AACtD,aAAO,QAAQ,KAAK,OAAO;AAC3B,UAAI,UAAU,UAAa,CAAC,KAAK,QAAQ,SAAS,cAAc,GAAG;AACjE,gBAAQ,OAAO,gBAAgB,KAAK,GAAG,QAAQ,IAAI;;;AAGvD,WAAO,MAAM,aAAa,OAAO;EACnC;EAEQ,MAAM,mBAAgB;AAC5B,QAAI,OAAO,KAAK,0BAA0B,YAAY;AACpD,YAAM,QAAQ,MAAM,KAAK,sBAAqB;AAC9C,UAAI,CAAC,SAAS,OAAO,UAAU,UAAU;AACvC,cAAM,IAAW,YACf,+EAA+E,KAAK,EAAE;;AAG1F,aAAO;;AAET,WAAO;EACT;EAEmB,YAAY,MAA8B;AAC3D,WAAO,CAAA;EACT;EAEmB,MAAM,eAAe,MAAuC;AAC7E,QAAI,KAAK,UAAU,eAAe,KAAK,KAAK,UAAU,SAAS,GAAG;AAChE,aAAO,MAAM,eAAe,IAAI;;AAElC,UAAM,QAAQ,MAAM,KAAK,iBAAgB;AACzC,SAAK,YAAL,KAAK,UAAY,CAAA;AACjB,QAAI,OAAO;AACT,WAAK,QAAQ,eAAe,IAAI,UAAU,KAAK;eACtC,KAAK,WAAW,kBAAkB;AAC3C,WAAK,QAAQ,SAAS,IAAI,KAAK;WAC1B;AACL,YAAM,IAAW,YAAY,uBAAuB;;AAEtD,WAAO,MAAM,eAAe,IAAI;EAClC;;AAGF,IAAM,yBAAyB,oBAAI,IAAI;EACrC;EACA;EACA;EACA;EACA;EACA;EACA;CACD;AAED,IAAM,mBAAmB;AAIzB,IAAA,iBAAe;","names":["str","debug","deprecate","inspect","_a","queueMicrotask","streamBrandCheckException","defaultControllerBrandCheckException","DOMException","ReadableStream","Request","Response","Headers","Blob","File","kind","FormData","_FormData_setEntry","str","isFunction","kind","__classPrivateFieldGet","_FormDataEncoder_getFieldHeader","fileFromPath","KeepAliveAgent","getMultipartRequestOptions","AbortControllerPolyfill","FormData","self","str","isFileLike","File","opts","Page","retryMessage","__classPrivateFieldSet","__classPrivateFieldGet","Completions","Chat","Speech","Transcriptions","Translations","Audio","Batches","Assistants","__classPrivateFieldSet","__classPrivateFieldGet","content","_AbstractChatCompletionRunner_getFinalMessage","_AbstractChatCompletionRunner_getFinalFunctionCall","_AbstractChatCompletionRunner_getFinalFunctionCallResult","_AbstractChatCompletionRunner_calculateTotalUsage","_AbstractChatCompletionRunner_validateParams","_AbstractChatCompletionRunner_stringifyFunctionCallResult","__classPrivateFieldGet","_ChatCompletionStream_beginRequest","__classPrivateFieldSet","_ChatCompletionStream_addChunk","_ChatCompletionStream_endRequest","_ChatCompletionStream_accumulateChatCompletion","content","rest","_a","index","chunk","id","Completions","Chat","Completions","__classPrivateFieldSet","__classPrivateFieldGet","chunk","__classPrivateFieldGet","__classPrivateFieldSet","_AssistantStream_endRequest","_AssistantStream_handleMessage","_AssistantStream_handleRunStep","_AssistantStream_handleEvent","_AssistantStream_accumulateRunStep","_AssistantStream_accumulateMessage","_AssistantStream_accumulateContent","_AssistantStream_handleRun","Messages","Steps","Runs","Threads","Files","FileBatches","VectorStores","Chat","Beta","Completions","Embeddings","Files","Checkpoints","Jobs","FineTuning","Images","Models","Moderations","Completions","Files","OpenAIError","APIError","APIConnectionError","APIConnectionTimeoutError","APIUserAbortError","NotFoundError","ConflictError","RateLimitError","BadRequestError","AuthenticationError","InternalServerError","PermissionDeniedError","UnprocessableEntityError","toFile","fileFromPath","OpenAI"]}